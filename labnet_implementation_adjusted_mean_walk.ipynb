{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4701eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LABNET import Neuron, Net, Lab, Teacher,compare_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e88d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db84284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_weights(model, perturbation_amount):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            weights = layer.get_weights()\n",
    "            perturbations = [np.random.uniform(-perturbation_amount, perturbation_amount, w.shape) for w in weights]\n",
    "            perturbed_weights = [w + perturbation for w, perturbation in zip(weights, perturbations)]\n",
    "            layer.set_weights(perturbed_weights)\n",
    "\n",
    "# Example usage:\n",
    "# Save the perturbed weights\n",
    "#perturbation_amount = 0.1\n",
    "#perturb_weights(model, perturbation_amount)\n",
    "#save_weights(model, 'perturbed_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894aab1",
   "metadata": {},
   "source": [
    "\n",
    "## Adding a few hyperparameters ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab368e9a",
   "metadata": {},
   "source": [
    "first, instead of storing gradients we store standard deviations.  we will need a default to start.  \n",
    "then there is kappa.  this may move as we go lower, or whatever, but kappa is the number of samples.  \n",
    "then there is a percentage of neurons to sample at each kappa iteration.  min value here should be only one neuron, and the max should be all.  this could be randomly determined maybe?.  \n",
    "so, lets say you are doing the min, one neuron per kappa iteration.  \n",
    "you look up that neurons standard deviation (which i think i use gradients instead)\n",
    "and you sample using the standard deviation for that neuron, and the weight value as the mean.  get kappa losses that each correspond to a sampled weight.  you have kappa loss weight pairs for that neuron.  pick the lowest loss, set the weight to that sampled value, and set the standard deviation to whatever that selected weight is from the previous one.  so, if the sampled value is outside the 1 sd bound, it is going to search a wider area, if it is less, it will search a smaller one.  if it doesn't sample one that is better than the current value, it gets multiplied by some fixed number greater than 1.  so, to get to the GLOBAL minima, those values all go big, and it can search over huge areas and won't find anything smaller.  so you could see how often it selects a better value, that should reduce as more iterations happen.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551dbc7",
   "metadata": {},
   "source": [
    "![Alt text](normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d0323",
   "metadata": {},
   "source": [
    "theory i guess:gradient explosion or collapse is a spectrum.  first, is it normally distributed? i think its distribution is a function of the architecture, the depth and the number of neurons.  depth contribution makes the most sense.  you need all the deep layers to compound to get either issue.  as you get deeper, the risk of catastrophic gradient deviation increases, or, if we think about training lots of neural networks, or just the same neural network multiple times, it likely does that in some distribution.  so, we should either see the earliest layers train first if the gradient explodes, or the latter layers to train first (if vanish or collapse).   however, it looks like it does one or the other and runs into a minima. a decent minima even.  what would that mean.  it means on the loss landscape there may be lots of really decent places for the weights to end up, even if it doesn't match the ideal (controlled generated) weights.  \n",
    "WHAT IF SOME INDIVIDUAL VALUES INSIDE WEIGHT MATRICES (i need a name for not a neuron, but an individual weight inside that tensor)\n",
    "\n",
    "so, look at lots of em, see if there is evidence for that.  \n",
    "\n",
    "then, is there a way to cut the compounding during the backward pass.  what if each layer only takes into account the next weight layer, doesnt' back propagate all the way back.  does that make it so each neuron can pull its weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4402d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_graph(numbers\n",
    "                    ,window_size = 1\n",
    "                    ,plot_size = (10,6)\n",
    "                    ,x_range = (None, None)\n",
    "                    ,y_range = (None, None)\n",
    "                   ):\n",
    "    \n",
    "    if window_size <= 0 or window_size > len(numbers):\n",
    "        raise ValueError(\"Invalid window size\")\n",
    "    \n",
    "    running_sum = sum(numbers[:window_size])\n",
    "    averages = [running_sum / window_size]\n",
    "\n",
    "    for i in range(window_size, len(numbers)):\n",
    "        running_sum += numbers[i] - numbers[i - window_size]\n",
    "        averages.append(running_sum / window_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = range(1, len(averages) + 1)  \n",
    "    y = averages  # y-axis values\n",
    "    plt.figure(figsize=plot_size)\n",
    "    plt.plot(x, y)  # Plotting the line graph\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "\n",
    "    if x_range[0] is not None and x_range[1] is not None:\n",
    "        plt.xlim(x_range[0], x_range[1])\n",
    "    if y_range[0] is not None and y_range[1] is not None:\n",
    "        plt.ylim(y_range[0], y_range[1])\n",
    "    \n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d76df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aebd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = 1000 #number of samples to generate\n",
    "layer_sizes = [8, 7,7,4]  # Inputs: 4, Hidden layers: [8, 8], Outputs: 3\n",
    "neural_network = Teacher(layer_sizes)\n",
    "#initialize_weights_uniform(neural_network,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fc55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.generate_data(\n",
    "    n\n",
    "    ,'normal'\n",
    "    , m =0.0\n",
    "    , std=1.0\n",
    "    , gen_lr = 0.01\n",
    "    , gen_epochs = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f8b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a function of the Teacher obj, i think save all the generate settings then just pass number of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d81bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0713, -0.0676, -0.1541, -0.1669], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model(neural_network.inputs[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae2e479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_layer.weight',\n",
       "              tensor([[ 0.7026,  0.7156, -0.7016,  0.0741, -0.4138, -0.9347, -0.2580, -0.7119],\n",
       "                      [ 0.0168,  0.1846,  0.5701, -0.5974,  0.0442,  0.5620, -0.0871,  0.3856],\n",
       "                      [ 0.0997, -0.6229, -0.7029, -0.2000,  0.6007, -0.4877, -0.1692,  0.0826],\n",
       "                      [-0.3770,  0.0998, -0.0791, -0.7296, -0.0873, -0.0796,  0.2827,  0.1841],\n",
       "                      [ 0.8441,  0.1043,  0.4925,  0.8100,  0.8047,  0.0262,  0.1161,  0.0528],\n",
       "                      [ 0.0134, -0.3911,  0.5322, -0.0254,  0.3071, -0.4745, -0.2734,  0.5770],\n",
       "                      [ 0.1167, -0.7758,  0.5492, -0.3896,  0.6946,  0.3533,  0.0440,  0.6140]])),\n",
       "             ('input_layer.bias',\n",
       "              tensor([ 0.7513, -0.8571, -0.8545,  0.8060,  0.6966,  0.5434, -0.5750])),\n",
       "             ('hidden_layer_2.weight',\n",
       "              tensor([[-0.3051,  0.5045,  0.1039, -1.0518,  0.0547,  0.3349,  0.2785],\n",
       "                      [-0.4017, -0.4449, -0.5076, -0.3446, -0.9126,  0.1474,  0.0734],\n",
       "                      [-0.7787, -0.6574, -0.9400,  0.2858,  0.2908,  0.3891, -0.4330],\n",
       "                      [-0.3700, -0.4257, -0.7560, -0.4692,  0.1701,  0.6887, -1.0025],\n",
       "                      [-0.8724, -0.8676, -0.9723,  0.6989,  0.2811, -0.5053,  0.0411],\n",
       "                      [-0.6274, -0.5249,  0.7925,  0.8412,  0.0105, -0.3213, -0.7966],\n",
       "                      [-0.3993,  0.2923, -0.3389,  0.6671, -0.6252,  0.3574, -0.3153]])),\n",
       "             ('hidden_layer_2.bias',\n",
       "              tensor([ 0.6406,  0.2153, -0.6605, -0.9513, -0.8559,  0.5686, -0.5437])),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-0.0736,  0.4923,  0.0534,  0.9775,  0.4826, -0.0628, -0.2330],\n",
       "                      [-0.0234, -0.5802,  0.4165,  0.3436,  0.2523,  0.1801, -0.1339],\n",
       "                      [-0.0402,  0.3988,  0.5265,  0.6732, -0.5261,  0.1927, -0.0442],\n",
       "                      [ 0.0940,  0.8016,  0.1193,  0.2699,  0.3416,  0.2305, -0.2571]])),\n",
       "             ('output_layer.bias',\n",
       "              tensor([ 0.0713, -0.0676, -0.1541, -0.1669]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model.state_dict()\n",
    "#torch.save(neural_network.model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b2ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.hidden_1 = nn.Linear(8, 7) ##make these all variables duh\n",
    "        self.hidden_2 = nn.Linear(7,7)\n",
    "        #self.hidden_3 = nn.Linear(7,7)\n",
    "        #self.hidden_4 = nn.Linear(7,7)\n",
    "        #self.hidden_5 = nn.Linear(7,7)\n",
    "        self.output = nn.Linear(7, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden_1(x))\n",
    "        x = self.relu(self.hidden_2(x))\n",
    "        #x = self.relu(self.hidden_3(x))\n",
    "        #x = self.relu(self.hidden_4(x))\n",
    "        #x = self.relu(self.hidden_5(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8807a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (hidden_1): Linear(in_features=8, out_features=7, bias=True)\n",
      "  (hidden_2): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (output): Linear(in_features=7, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mymodel = MyModel()\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221b9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_state_dict_keys_by_order(model, reference_model):\n",
    "    model_keys = list(model.state_dict().keys())\n",
    "    reference_keys = list(reference_model.state_dict().keys())\n",
    "    name_mapping = dict(zip(model_keys, reference_keys))\n",
    "    \n",
    "    new_state_dict = OrderedDict()\n",
    "    for key in model.state_dict():\n",
    "        new_key = name_mapping[key]\n",
    "        new_state_dict[new_key] = model.state_dict()[key]\n",
    "    return new_state_dict\n",
    "\n",
    "def perturb_weights(model, std_dev):\n",
    "    for param in model.parameters():\n",
    "        noise = np.random.normal(loc=0.0, scale=std_dev, size=param.data.shape)\n",
    "        param.data.add_(torch.from_numpy(noise))\n",
    "        \n",
    "def scale_weights(model, scaling_factor):\n",
    "    for param in model.parameters():\n",
    "        param.data.mul_(scaling_factor)\n",
    "        \n",
    "def calculate_validation_loss(model, validation_inputs, validation_outputs, loss_function):\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        #validation_inputs = validation_inputs.to(device)  # Move inputs to the appropriate device (e.g., GPU)\n",
    "        #validation_outputs = validation_outputs.to(device)  # Move targets to the appropriate device\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(validation_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, validation_outputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        average_loss = loss.item()\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    return average_loss\n",
    "\n",
    "def val_histogram(data_list, bins=10, title=\"val_hist\", xlabel=\"Values\", ylabel=\"Frequency\"):\n",
    "\n",
    "    plt.hist(data_list, bins=bins, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663c7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ef270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_this = rename_state_dict_keys_by_order( neural_network.model,mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5cd09b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.load_state_dict(load_this)\n",
    "#mymodel.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4372c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden_1.weight',\n",
       "              tensor([[-0.1647, -0.1673,  0.2949, -0.2737,  0.2855,  0.3507, -0.0802, -0.1861],\n",
       "                      [-0.3187, -0.2612, -0.0059,  0.2561,  0.1603, -0.1228,  0.0762, -0.3175],\n",
       "                      [-0.1942, -0.1733, -0.2720, -0.2753,  0.1550,  0.1839, -0.0243, -0.1965],\n",
       "                      [-0.0715,  0.1051,  0.0022, -0.3359, -0.0690, -0.0396,  0.3426, -0.0017],\n",
       "                      [ 0.1893,  0.2319, -0.0313,  0.2959,  0.0143, -0.1880,  0.0896, -0.2713],\n",
       "                      [ 0.1133, -0.0914,  0.0529, -0.2714,  0.0465, -0.2810,  0.1417, -0.2604],\n",
       "                      [-0.2664,  0.1117, -0.3038, -0.1646,  0.2478,  0.0091,  0.2848,  0.3001]])),\n",
       "             ('hidden_1.bias',\n",
       "              tensor([-0.0733, -0.2016, -0.1474,  0.1037,  0.3468,  0.2430, -0.1674])),\n",
       "             ('hidden_2.weight',\n",
       "              tensor([[ 0.2372,  0.0678, -0.0488, -0.2598, -0.2813,  0.0155, -0.2646],\n",
       "                      [ 0.1521,  0.0793, -0.1471, -0.0295,  0.3660,  0.2254,  0.3357],\n",
       "                      [-0.3695, -0.2211, -0.2185, -0.1731,  0.0816,  0.0957, -0.1754],\n",
       "                      [ 0.1767, -0.2370,  0.1621, -0.3352,  0.3629,  0.1594,  0.1502],\n",
       "                      [-0.0931, -0.1070, -0.2562,  0.3354,  0.1057,  0.3482, -0.1162],\n",
       "                      [-0.0599,  0.2990, -0.2208, -0.0962,  0.0472, -0.2665,  0.2458],\n",
       "                      [-0.1906, -0.0852, -0.3432, -0.3114, -0.2479, -0.1612,  0.1104]])),\n",
       "             ('hidden_2.bias',\n",
       "              tensor([-0.2704,  0.2270,  0.2907,  0.0987,  0.2102,  0.0497,  0.2353])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.2219, -0.2169, -0.1725,  0.2705, -0.0985,  0.2579,  0.0243],\n",
       "                      [-0.0068, -0.3479,  0.1686, -0.3211,  0.1389,  0.2475, -0.0471],\n",
       "                      [ 0.1899,  0.1314, -0.2860,  0.3101,  0.3250, -0.3367, -0.3205],\n",
       "                      [ 0.1232, -0.1058,  0.1288,  0.3713, -0.0202,  0.0993,  0.1362]])),\n",
       "             ('output.bias', tensor([ 0.3010, -0.0620, -0.3259, -0.1613]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##STARTING with the right answuers gives some close to zero row_comp:3.5974587e-08,0.0,0.0; 0.0,2.9802322e-08,1.4901161e-08\n",
    "#interesting that you get a zero, and then a close to zero.  \n",
    "#perturb_weights(mymodel, std_dev = 0.005) # converges\n",
    "#perturb_weights(mymodel, std_dev = 0.009) # converges\n",
    "#perturb_weights(mymodel, std_dev = 0.05) doesn't converge\n",
    "#perturb_weights(mymodel, std_dev = 0.01) #converges\n",
    "#perturb_weights(mymodel, std_dev = 0.01) #not converging well, even with lower lr, 0.003. 1t 0.001\n",
    "\n",
    "\n",
    "# scale_weights(mymodel, scaling_factor = 1.1) ## converges, weights cross.  \n",
    "#scale_weights(mymodel, scaling_factor = 1.5) ## good validation, non zero row comapre still..\n",
    "\n",
    "#scale_weights(mymodel, scaling_factor = 2) ## good validation, row compare stays pretty close to the same...\n",
    "## scale_weights(mymodel, scaling_factor = 1.05) row compare barely improves!!\n",
    "mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d012ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.618734\n",
      "8.593932\n",
      "3.5118556\n"
     ]
    }
   ],
   "source": [
    "test_list = list(zip([row for row in neural_network.model.parameters() if len(row.shape) > 1],\n",
    "                     [row for row in mymodel.parameters() if len(row.shape) > 1]))\n",
    "\n",
    "for i in test_list:\n",
    "    #this first line will print out the row similarity matrix.\n",
    "    #print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[0])\n",
    "    print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e19f7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomStochasticOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, kappa, std_init=1):\n",
    "        super(CustomStochasticOptimizer, self).__init__(params, {})\n",
    "        self.kappa = kappa\n",
    "        self.kappa_iter = kappa #this works with the way the code is written in step.\n",
    "        self.param_shapes = [p.data.shape for group in self.param_groups for p in group['params']]\n",
    "        #print(self.param_shapes)\n",
    "        self.param_idx = None\n",
    "        self.neuron_idx = [] ##this dim will change, biases have one, matrices 2, bla bla\n",
    "        self.current_std = 1.0\n",
    "        self.current_mean = 0.0\n",
    "        self.kappa_memory = [] #will hold tuples, kappa quantity\n",
    "        # Set the gradients for all model parameters to std_init\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                p.grad = torch.zeros_like(p.data) + std_init\n",
    "                #print(p.grad)\n",
    "\n",
    "    def get_nested_data(self, data, indices):\n",
    "        def _get_nested_data(self,data, indices):\n",
    "            if len(indices) == 1:\n",
    "                return data[indices[0]]\n",
    "            else:\n",
    "                next_index = indices[0]\n",
    "                remaining_indices = indices[1:]\n",
    "                next_data = data[next_index]\n",
    "                return _get_nested_data(self,next_data, remaining_indices)\n",
    "    \n",
    "        return _get_nested_data(self,data, indices)\n",
    "    \n",
    "    def set_nested_data(data, indices, new_value):\n",
    "        def _set_nested_data(data, indices, new_value):\n",
    "            if len(indices) == 1:\n",
    "                data[indices[0]] = new_value\n",
    "            else:\n",
    "                next_index = indices[0]\n",
    "                remaining_indices = indices[1:]\n",
    "                next_data = data[next_index]\n",
    "                _set_nested_data(next_data, remaining_indices, new_value)\n",
    "\n",
    "        _set_nested_data(data, indices, new_value)\n",
    "    #def i need a set function similar to get_nested_data that takes param index, neuron idx, and sets the weight and the std\n",
    "    ## might be a good idea to calculate the new std as well.\n",
    "    ##future: hyper parameters to indicate like, a max and min std?\n",
    "    #change kappa based on the value of the std??\n",
    "    ##thats interesting.  if the std gets bigger we sample more? its less sure of being in a good place of LL so look more for that neuron?\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        \n",
    "        if self.kappa_iter < self.kappa:\n",
    "            self.kappa_iter += 1\n",
    "            param_group = self.param_groups\n",
    "            #print(self.kappa_memory)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            self.kappa_iter = 1\n",
    "            print(len(self.kappa_memory))  ##this only hits when kappa mem is full!\n",
    "            ##set the previous stuff here before resampling.  \n",
    "            \n",
    "            if len(self.kappa_memory) == self.kappa: ##this is just to skip the initial case.\n",
    "                \n",
    "                min_tuple = min(self.kappa_memory, key=lambda x: x[1])\n",
    "                new_weight = min_tuple[0]\n",
    "                print(self.kappa_memory)\n",
    "                print(new_weight)\n",
    "            \n",
    "            self.kappa_memory = []  ###how do i get the first weight as the first entry.  \n",
    "            self.param_idx = random.randint(1,len(self.param_shapes)-1)\n",
    "            \n",
    "            ##get a new neuron \n",
    "            this_param_shape = self.param_shapes[self.param_idx]\n",
    "            self.neuron_idx = [random.randint(1,i)-1 for i in this_param_shape]\n",
    "            #print(self.param_idx)\n",
    "            #print(self.neuron_idx)\n",
    "            #self.param_groups[0]['params'] ##this is the raw parameter.  groups will fuck stuff up just fyi\n",
    "            #print(self.param_groups[0]['params'][self.param_idx]) #this gets the param\n",
    "            \n",
    "            #print(self.get_nested_data(self.param_groups[0]['params'][self.param_idx], self.neuron_idx)) #mean\n",
    "            self.current_mean = self.get_nested_data(self.param_groups[0]['params'][self.param_idx], self.neuron_idx)\n",
    "            #print(self.current_mean)\n",
    "            #print(self.get_nested_data(self.param_groups[0]['params'][self.param_idx].grad, self.neuron_idx)) #std!!!\n",
    "            \n",
    "            \n",
    "            self.current_std = self.get_nested_data(self.param_groups[0]['params'][self.param_idx].grad, self.neuron_idx)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('reset')\n",
    "          \n",
    "        #sampling here.  \n",
    "        test_weight = torch.normal(mean=float(self.current_mean), std=float(self.current_std), size=(1,)) \n",
    "        print(self.current_mean, self.current_std, self.param_idx,self.neuron_idx, test_weight)\n",
    "        \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        #print(loss)\n",
    "        self.kappa_memory.append((float(test_weight),float(loss))) \n",
    "        \"\"\"\n",
    "        # Randomly choose one parameter group (neuron's parameter) for optimization\n",
    "        param_group = self.param_groups[torch.randint(len(self.param_groups), (1,)).item()]\n",
    "        print(self.param_groups)\n",
    "        for p in param_group['params']: ##this loops through parameters, not individual neurons.\n",
    "            if p.grad is None:  ##this should never be none.  In fact, i need an initial value.  1 maybe?\n",
    "                print(p.data)\n",
    "                continue\n",
    "\n",
    "            # Get the current parameter value and gradient\n",
    "            param_data = p.data\n",
    "            \n",
    "            std = torch.abs(p.grad.data)   ##this is the std, and i set this at the end.\n",
    "\n",
    "            # Store the original parameter value and compute the initial weight\n",
    "            # i don't think i need both.  lets see\n",
    "            original_param_data = param_data.clone()\n",
    "            initial_weight = param_data.clone()\n",
    "\n",
    "            # Sample kappa times with a normal distribution using gradient as std_dev and initial weight as mean\n",
    "            \n",
    "            \n",
    "            samples = torch.normal(mean=initial_weight, std=std, size=(self.kappa, *param_data.shape))\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            best_sample = None\n",
    "            new_std = 1 #this should have an init value. \n",
    "\n",
    "            for sample in samples:  #This iterates over kappa!!\n",
    "                # Update the parameter with the sampled value\n",
    "                p.data = sample\n",
    "\n",
    "                # Calculate the loss for the sampled value\n",
    "                sample_loss = closure()\n",
    "            \n",
    "            sample_loss = closure\n",
    "                # Check if the sampled value leads to a lower loss\n",
    "            if sample_loss < best_loss:\n",
    "                best_loss = sample_loss\n",
    "                best_sample = sample\n",
    "                new_std = torch.abs(best_sample - initial_weight) #i think\n",
    "\n",
    "            # Update the parameter with the best sampled value\n",
    "            p.data = best_sample\n",
    "            p.grad.data.fill_(new_std) \n",
    "            \"\"\"\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ba85702",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(mymodel.parameters(), lr=0.001) #decay schedule??\n",
    "optimizer = CustomStochasticOptimizer(mymodel.parameters(),kappa=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5377e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = neural_network.inputs\n",
    "output_data = neural_network.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19fcd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "reset\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-1.5457])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.4577])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.4233])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.6576])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([1.4381])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.1120])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.2788])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.9229])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.0179])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.7877])\n",
      "10\n",
      "[(-1.5457370281219482, 0.01736924797296524), (0.4577217102050781, 0.08161139488220215), (-0.4232642948627472, 0.032784391194581985), (-0.6576036810874939, 0.07916299253702164), (1.4381392002105713, 0.05403865873813629), (0.11197636276483536, 0.06783467531204224), (-0.2788485288619995, 0.00470398273319006), (-0.9229081273078918, 0.19008882343769073), (-0.017949506640434265, 0.02758277952671051), (0.7876955270767212, 0.05744777247309685)]\n",
      "-0.2788485288619995\n",
      "reset\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-0.3494])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-0.6992])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-0.4368])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-2.3813])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-0.7317])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([0.3153])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([0.0524])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([1.3643])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-0.3231])\n",
      "tensor(0.3713, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 3] tensor([-0.6002])\n",
      "10\n",
      "[(-0.34940388798713684, 0.06590558588504791), (-0.6991925239562988, 0.04223465546965599), (-0.4368162751197815, 0.1210419312119484), (-2.38132381439209, 0.03978199139237404), (-0.7317386269569397, 0.08471551537513733), (0.3153397738933563, 0.022586112841963768), (0.05243970453739166, 0.1362861841917038), (1.364305019378662, 0.06865203380584717), (-0.32313644886016846, 0.03966816887259483), (-0.600152850151062, 0.031918808817863464)]\n",
      "0.3153397738933563\n",
      "reset\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([-0.2843])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([0.3118])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([0.1322])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([0.4181])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([0.3112])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([-0.4612])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([0.9036])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([-0.5599])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([-0.0949])\n",
      "tensor(-0.1058, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 1] tensor([-0.5354])\n",
      "10\n",
      "[(-0.28425323963165283, 0.020488103851675987), (0.3118211627006531, 0.014872937463223934), (0.1322222799062729, 0.052922144532203674), (0.41806352138519287, 0.12378916889429092), (0.3111792802810669, 0.012789527885615826), (-0.4612295925617218, 0.08042585104703903), (0.9035601615905762, 0.051983244717121124), (-0.5598560571670532, 0.15659131109714508), (-0.09489808976650238, 0.08030745387077332), (-0.5353751182556152, 0.01708163321018219)]\n",
      "0.3111792802810669\n",
      "reset\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([-0.7011])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.4088])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([-0.1014])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([-0.9503])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.8604])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.6609])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.1420])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.3524])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.0291])\n",
      "tensor(0.0243, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 6] tensor([0.5807])\n",
      "10\n",
      "[(-0.7010983824729919, 0.15706923604011536), (0.4088383615016937, 0.3139459788799286), (-0.10141925513744354, 0.024460872635245323), (-0.9503398537635803, 0.04086613655090332), (0.8603833913803101, 0.04423689842224121), (0.6609422564506531, 0.06742893159389496), (0.14203298091888428, 0.032807860523462296), (0.35236936807632446, 0.03400341048836708), (0.029131758958101273, 0.01552592683583498), (0.5807375907897949, 0.0361052080988884)]\n",
      "0.029131758958101273\n",
      "reset\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.9282])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.3454])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.3369])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([1.5301])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.2469])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.3914])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.4387])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-1.0160])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.4472])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.5998])\n",
      "10\n",
      "[(-0.9281823039054871, 0.056061651557683945), (-0.3454408049583435, 0.018441516906023026), (0.33685392141342163, 0.032952480018138885), (1.5300747156143188, 0.013822603039443493), (0.24686694145202637, 0.07906242460012436), (-0.39141780138015747, 0.02385292388498783), (-0.43867871165275574, 0.17454755306243896), (-1.016034483909607, 0.025958875194191933), (0.44724172353744507, 0.0832529067993164), (-0.5998005270957947, 0.011372661218047142)]\n",
      "-0.5998005270957947\n",
      "reset\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.4141])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.0891])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.7919])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.2945])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.0799])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.2558])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([2.2065])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.8679])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.0114])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.6907])\n",
      "10\n",
      "[(1.4140945672988892, 0.03412478417158127), (-0.08914050459861755, 0.0664200633764267), (-0.7918972969055176, 0.08450952917337418), (-0.2944915294647217, 0.1108061894774437), (0.07992733269929886, 0.08603274822235107), (1.255826473236084, 0.04238474741578102), (2.2064647674560547, 0.016356365755200386), (0.8679386377334595, 0.03635726496577263), (1.0113941431045532, 0.033602818846702576), (-0.6907308101654053, 0.12648434937000275)]\n",
      "2.2064647674560547\n",
      "reset\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.4016])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.0602])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.1216])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.7703])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.0925])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.8465])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.5682])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.4521])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([1.5401])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.6391])\n",
      "10\n",
      "[(-1.401608943939209, 0.013276162557303905), (-0.060223039239645004, 0.07677000761032104), (-1.1216330528259277, 0.014270452782511711), (0.7703096866607666, 0.025803301483392715), (-1.0925105810165405, 0.02179735340178013), (-1.8464857339859009, 0.022844476625323296), (0.5681742429733276, 0.016624407842755318), (0.4521370530128479, 0.017302092164754868), (1.5400514602661133, 0.03494475781917572), (0.6391006112098694, 0.06733173877000809)]\n",
      "-1.401608943939209\n",
      "reset\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.1589])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.2731])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.3380])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.7064])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([1.0223])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.5638])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-1.6142])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([1.0225])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.2402])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.9434])\n",
      "10\n",
      "[(0.1588544100522995, 0.052704475820064545), (-0.27305424213409424, 0.037465695291757584), (-0.33796587586402893, 0.029719077050685883), (-0.706352710723877, 0.02253105863928795), (1.0223283767700195, 0.022817034274339676), (-0.5638010501861572, 0.026122648268938065), (-1.6142302751541138, 0.019291255623102188), (1.022526741027832, 0.03478170558810234), (-0.24024175107479095, 0.09605684876441956), (-0.9433544874191284, 0.07442057877779007)]\n",
      "-1.6142302751541138\n",
      "reset\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.9880])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.4389])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.8079])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([1.0018])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.7001])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-1.1679])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([0.6077])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.3428])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.6258])\n",
      "tensor(-0.1674, grad_fn=<SelectBackward0>) tensor(1.) 1 [6] tensor([-0.9533])\n",
      "10\n",
      "[(0.9879889488220215, 0.03134015202522278), (0.4389092028141022, 0.022625084966421127), (0.807886004447937, 0.020631251856684685), (1.0018131732940674, 0.012309026904404163), (0.7000567317008972, 0.0915466770529747), (-1.167874813079834, 0.02388933300971985), (0.6077333092689514, 0.04378731548786163), (-0.342790812253952, 0.04195820540189743), (-0.6258327960968018, 0.018086623400449753), (-0.9532780647277832, 0.0335405208170414)]\n",
      "1.0018131732940674\n",
      "reset\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.1593])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.3760])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.5780])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.9297])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.1329])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.2543])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.8101])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.5062])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.5969])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.0348])\n",
      "10\n",
      "[(-1.1592963933944702, 0.033415067940950394), (0.3760383129119873, 0.08675508946180344), (-1.5780175924301147, 0.06605386734008789), (0.9296677708625793, 0.07853155583143234), (0.13289779424667358, 0.2290532886981964), (-1.2542798519134521, 0.028617385774850845), (-0.8100777864456177, 0.05589811131358147), (-0.5062215924263, 0.04435444623231888), (0.5969038605690002, 0.09908314049243927), (-0.03477926552295685, 0.04713907092809677)]\n",
      "-1.2542798519134521\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.3919])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.1868])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.1551])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.6495])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.7827])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.8032])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.6252])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.8391])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.8755])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.1963])\n",
      "10\n",
      "[(0.39193296432495117, 0.14366768300533295), (1.1867972612380981, 0.07467824220657349), (0.15509265661239624, 0.04010111466050148), (1.6494946479797363, 0.0640522763133049), (0.7826942801475525, 0.08283179253339767), (0.8031995892524719, 0.02517937496304512), (0.6252242922782898, 0.033615294843912125), (0.8391400575637817, 0.04254327341914177), (-0.875546932220459, 0.05380861461162567), (-0.19634923338890076, 0.11186866462230682)]\n",
      "0.8031995892524719\n",
      "reset\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.1989])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.5568])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.6574])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.1985])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.3905])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([1.0291])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.7413])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.5002])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.0222])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.2882])\n",
      "10\n",
      "[(0.19892410933971405, 0.03586828336119652), (-0.5567930340766907, 0.029992472380399704), (-1.6573954820632935, 0.038657259196043015), (-0.19845184683799744, 0.02299461141228676), (-1.3904743194580078, 0.013210397213697433), (1.0290923118591309, 0.04073157161474228), (0.7412785291671753, 0.04129662364721298), (-1.5002119541168213, 0.15703579783439636), (-1.022178053855896, 0.06505150347948074), (-0.2882436513900757, 0.12014459818601608)]\n",
      "-1.3904743194580078\n",
      "reset\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-1.9942])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-0.5106])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([0.3267])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-1.2147])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-1.1211])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-0.0126])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-0.2691])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([0.1211])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-0.1000])\n",
      "tensor(-0.0985, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 4] tensor([-0.4889])\n",
      "10\n",
      "[(-1.9942010641098022, 0.033260978758335114), (-0.5106468200683594, 0.020725391805171967), (0.3266734480857849, 0.063380166888237), (-1.2147055864334106, 0.38156774640083313), (-1.1211286783218384, 0.08815576881170273), (-0.012551183812320232, 0.31466925144195557), (-0.2691494822502136, 0.04658035933971405), (0.12108473479747772, 0.03628792241215706), (-0.09997093677520752, 0.07598292082548141), (-0.4888933002948761, 0.027518754824995995)]\n",
      "-0.5106468200683594\n",
      "reset\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([0.2271])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([0.7238])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([1.7929])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([-0.1319])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([-1.1443])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([-0.7073])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([1.0798])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([0.7758])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([1.0278])\n",
      "tensor(0.0993, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 5] tensor([-0.0074])\n",
      "10\n",
      "[(0.22710289061069489, 0.05640065297484398), (0.7238402366638184, 0.1179262325167656), (1.7929459810256958, 0.13589364290237427), (-0.13194912672042847, 0.028045235201716423), (-1.1442897319793701, 0.06917879730463028), (-0.7072964310646057, 0.011420507915318012), (1.0798003673553467, 0.011115911416709423), (0.7758308053016663, 0.03877571225166321), (1.027767539024353, 0.03679195046424866), (-0.007379022892564535, 0.09653416275978088)]\n",
      "1.0798003673553467\n",
      "reset\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.2158])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.3754])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.2128])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.3437])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-2.6696])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.3593])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-2.2464])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-2.2940])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-1.2635])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-1.2843])\n",
      "10\n",
      "[(0.2158041149377823, 0.015350565314292908), (1.3754279613494873, 0.031840335577726364), (-0.212760791182518, 0.051148176193237305), (0.34367600083351135, 0.09214553236961365), (-2.6696279048919678, 0.025965165346860886), (1.359326720237732, 0.035968828946352005), (-2.2463674545288086, 0.03667997568845749), (-2.294002056121826, 0.020620770752429962), (-1.2634620666503906, 0.021459421142935753), (-1.2843197584152222, 0.08056145906448364)]\n",
      "0.2158041149377823\n",
      "reset\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([-1.8605])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([0.3965])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([-0.5322])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([-1.2761])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([0.1372])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([-0.5118])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([0.4342])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([-1.7273])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([2.4272])\n",
      "tensor(0.1362, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 6] tensor([-0.9979])\n",
      "10\n",
      "[(-1.8604575395584106, 0.034375373274087906), (0.39653095602989197, 0.021272674202919006), (-0.5322257876396179, 0.015366669744253159), (-1.2760757207870483, 0.22079657018184662), (0.13716904819011688, 0.13018256425857544), (-0.511837899684906, 0.02796488255262375), (0.4342406392097473, 0.0261748768389225), (-1.7273043394088745, 0.04044817015528679), (2.4271907806396484, 0.07077451795339584), (-0.9979376792907715, 0.030476219952106476)]\n",
      "-0.5322257876396179\n",
      "reset\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.0513])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([1.7495])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.9916])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-1.1910])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.3669])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-1.1513])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.1423])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.7742])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([1.0359])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.3762])\n",
      "10\n",
      "[(-0.05132514238357544, 0.045838579535484314), (1.7495088577270508, 0.058105628937482834), (0.9915685653686523, 0.1348792463541031), (-1.190984845161438, 0.013825468719005585), (-0.36691272258758545, 0.015433774329721928), (-1.1512789726257324, 0.020162900909781456), (-0.14225298166275024, 0.08036710321903229), (-0.7741501331329346, 0.04697801172733307), (1.0359361171722412, 0.02269953303039074), (0.37617990374565125, 0.0348762646317482)]\n",
      "-1.190984845161438\n",
      "reset\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([0.3332])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([1.2679])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([0.9845])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([-0.6903])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([-0.5405])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([0.9612])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([0.4718])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([-0.4279])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([0.1103])\n",
      "tensor(-0.1731, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 3] tensor([-1.3443])\n",
      "10\n",
      "[(0.3331751227378845, 0.03154390677809715), (1.267905354499817, 0.04792226105928421), (0.9845436215400696, 0.03585555776953697), (-0.6902763247489929, 0.05622917413711548), (-0.5405359268188477, 0.050140056759119034), (0.961199939250946, 0.14093974232673645), (0.4717867076396942, 0.012544848956167698), (-0.4278804063796997, 0.051752131432294846), (0.11030234396457672, 0.015837110579013824), (-1.3443282842636108, 0.04632629081606865)]\n",
      "0.4717867076396942\n",
      "reset\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-1.2299])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-1.4779])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.3006])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.2953])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-0.4534])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([1.1328])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-0.0698])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-0.3247])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([1.1165])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.4312])\n",
      "10\n",
      "[(-1.2298998832702637, 0.18679991364479065), (-1.4778809547424316, 0.07159369438886642), (0.30060258507728577, 0.036447424441576004), (0.29527196288108826, 0.013026613742113113), (-0.4533994495868683, 0.016427017748355865), (1.1328076124191284, 0.0763072595000267), (-0.0697660744190216, 0.04462180286645889), (-0.32470834255218506, 0.10902731120586395), (1.1164671182632446, 0.10423169285058975), (0.43118762969970703, 0.13096210360527039)]\n",
      "0.29527196288108826\n",
      "reset\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.1128])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.5331])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.9641])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([2.6765])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.2783])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([1.2901])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.7456])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([-0.3791])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.5311])\n",
      "tensor(-0.3114, grad_fn=<SelectBackward0>) tensor(1.) 2 [6, 3] tensor([0.0645])\n",
      "10\n",
      "[(0.1128460168838501, 0.17693093419075012), (0.5330524444580078, 0.02091269940137863), (0.9640662670135498, 0.05168352648615837), (2.6764914989471436, 0.012505056336522102), (0.2783496379852295, 0.02562643215060234), (1.2900524139404297, 0.03198948875069618), (0.7455553412437439, 0.0241202712059021), (-0.37907809019088745, 0.2381969839334488), (0.5311466455459595, 0.013911619782447815), (0.06450825184583664, 0.03461015596985817)]\n",
      "2.6764914989471436\n",
      "reset\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.1968])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([1.1414])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.8700])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-1.4547])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.8365])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([1.3062])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.1883])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-1.3454])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([1.0386])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.0362])\n",
      "10\n",
      "[(-0.1968095600605011, 0.049034230411052704), (1.1414133310317993, 0.13426300883293152), (0.8699992895126343, 0.13765870034694672), (-1.4546672105789185, 0.15562306344509125), (0.836543619632721, 0.0336475633084774), (1.3062442541122437, 0.053330279886722565), (-0.18828579783439636, 0.011750992387533188), (-1.3453996181488037, 0.033698856830596924), (1.0386176109313965, 0.31047719717025757), (0.03622495383024216, 0.03197117894887924)]\n",
      "-0.18828579783439636\n",
      "reset\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.4676])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.1025])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.8297])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-1.1204])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.4161])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.3185])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.0325])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.9111])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-1.3523])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-1.2428])\n",
      "10\n",
      "[(1.4676406383514404, 0.02363763377070427), (-0.10254652798175812, 0.06497232615947723), (-0.8297043442726135, 0.027942407876253128), (-1.1203522682189941, 0.1851358711719513), (0.4161059558391571, 0.03416351601481438), (0.3185187578201294, 0.03002764843404293), (0.03249584138393402, 0.03100312128663063), (-0.9110780358314514, 0.1253816783428192), (-1.3522543907165527, 0.03755810484290123), (-1.2428065538406372, 0.0620112419128418)]\n",
      "1.4676406383514404\n",
      "reset\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([1.4574])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-1.7304])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.5572])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([1.4903])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.4561])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.7406])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.2537])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.1495])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-1.2497])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.2471])\n",
      "10\n",
      "[(1.4574213027954102, 0.059044718742370605), (-1.7304441928863525, 0.02477921172976494), (-0.5571757555007935, 0.03256908431649208), (1.4903398752212524, 0.04765962436795235), (-0.45608237385749817, 0.026259973645210266), (-0.7406219244003296, 0.026225149631500244), (0.25371915102005005, 0.020585566759109497), (0.14952747523784637, 0.013122615404427052), (-1.249717354774475, 0.22200429439544678), (0.24707484245300293, 0.19053375720977783)]\n",
      "0.14952747523784637\n",
      "reset\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.1859])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.1095])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([1.6122])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([2.7228])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-0.2580])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([2.5317])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.1592])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.2248])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([-0.4656])\n",
      "tensor(0.1899, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 0] tensor([0.2768])\n",
      "10\n",
      "[(0.1859455406665802, 0.038089998066425323), (0.10947204381227493, 0.01859625242650509), (1.6121975183486938, 0.021317217499017715), (2.7227540016174316, 0.016206594184041023), (-0.25801682472229004, 0.03236899897456169), (2.531719446182251, 0.006159212440252304), (0.15915779769420624, 0.04254131764173508), (0.22475823760032654, 0.0851922407746315), (-0.4655612111091614, 0.037556275725364685), (0.27675628662109375, 0.019085979089140892)]\n",
      "2.531719446182251\n",
      "reset\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.0875])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([-0.0278])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.5628])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.5274])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([1.2382])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([1.2372])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([-0.4213])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.2733])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([-1.2952])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.9931])\n",
      "10\n",
      "[(0.08748944103717804, 0.11178013682365417), (-0.027799934148788452, 0.050020989030599594), (0.562832236289978, 0.05581889674067497), (0.5274338126182556, 0.04084017127752304), (1.2382124662399292, 0.12645822763442993), (1.2372390031814575, 0.04353909194469452), (-0.42125093936920166, 0.014338390901684761), (0.2732901871204376, 0.04975803568959236), (-1.2952126264572144, 0.08994029462337494), (0.9931411147117615, 0.04489991441369057)]\n",
      "-0.42125093936920166\n",
      "reset\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.8173])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.8139])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([0.2180])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.9377])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([0.6326])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([1.3908])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.4853])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([1.5858])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([0.4114])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([0.1865])\n",
      "10\n",
      "[(-0.8172762989997864, 0.06006678193807602), (-0.8139237761497498, 0.11690124869346619), (0.21798114478588104, 0.06484339386224747), (-0.937669575214386, 0.047186192125082016), (0.6326466798782349, 0.07707256823778152), (1.3907833099365234, 0.03251573443412781), (-0.48526331782341003, 0.04058884456753731), (1.5858181715011597, 0.02066628821194172), (0.4113616347312927, 0.09747657924890518), (0.18653900921344757, 0.05760324001312256)]\n",
      "1.5858181715011597\n",
      "reset\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([1.4322])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.6573])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([2.1695])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([-0.7517])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([-0.4635])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([-0.8502])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([-0.8211])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.6775])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([-1.1110])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.5735])\n",
      "10\n",
      "[(1.4322482347488403, 0.04134407639503479), (0.6573165059089661, 0.015706872567534447), (2.16951322555542, 0.022113699465990067), (-0.7516965866088867, 0.06847842037677765), (-0.4634803831577301, 0.040071532130241394), (-0.8502388596534729, 0.08443722128868103), (-0.8210936188697815, 0.02937912568449974), (0.6775317192077637, 0.005912270396947861), (-1.1109917163848877, 0.012389298528432846), (0.5734623074531555, 0.2050175964832306)]\n",
      "0.6775317192077637\n",
      "reset\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-0.3772])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-1.9276])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.3934])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([1.0927])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([1.1394])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([1.1899])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.5391])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.1503])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-1.3111])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([1.6589])\n",
      "10\n",
      "[(-0.37716278433799744, 0.01773560419678688), (-1.9276057481765747, 0.015210429206490517), (0.39344924688339233, 0.05389279127120972), (1.0927001237869263, 0.04501744359731674), (1.1393954753875732, 0.019629284739494324), (1.1898736953735352, 0.0461137518286705), (0.5390755534172058, 0.061533257365226746), (0.1503261923789978, 0.021143877878785133), (-1.3111209869384766, 0.01780916377902031), (1.6588670015335083, 0.09062207490205765)]\n",
      "-1.9276057481765747\n",
      "reset\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.5499])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.5095])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.3502])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.1697])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.3892])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([3.2382])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.4244])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.0672])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.1581])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([2.2881])\n",
      "10\n",
      "[(-0.5498747229576111, 0.0963815301656723), (0.5094938278198242, 0.039819277822971344), (1.3502227067947388, 0.012098375707864761), (1.169692873954773, 0.14922082424163818), (0.38924217224121094, 0.014487896114587784), (3.238208293914795, 0.02747195027768612), (0.42441830039024353, 0.05977117270231247), (0.06721722334623337, 0.01847769506275654), (-0.15806429088115692, 0.06295850872993469), (2.2881031036376953, 0.042883191257715225)]\n",
      "1.3502227067947388\n",
      "reset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.2448])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([1.4552])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.9081])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.2734])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.5406])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.0763])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.7592])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-1.1686])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.3775])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.3109])\n",
      "10\n",
      "[(0.24480894207954407, 0.07324863225221634), (1.4552104473114014, 0.07862161844968796), (0.9080649614334106, 0.028442304581403732), (0.2733953297138214, 0.02497493103146553), (0.5406153798103333, 0.009564707055687904), (-0.07632602006196976, 0.020587999373674393), (0.7591517567634583, 0.10468537360429764), (-1.1686012744903564, 0.01804416812956333), (-0.37749239802360535, 0.11672527343034744), (0.3108731210231781, 0.026158474385738373)]\n",
      "0.5406153798103333\n",
      "reset\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-1.2590])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-0.6469])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-0.9362])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([0.1527])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-0.5718])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-0.1968])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-1.5484])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-1.1499])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([-0.4951])\n",
      "tensor(-0.3479, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 1] tensor([1.1178])\n",
      "10\n",
      "[(-1.2589534521102905, 0.06450039893388748), (-0.6468905210494995, 0.03427639603614807), (-0.9362027049064636, 0.03493828698992729), (0.15267062187194824, 0.02610928937792778), (-0.571835458278656, 0.01608683168888092), (-0.19684678316116333, 0.03565872088074684), (-1.5483729839324951, 0.09446072578430176), (-1.1498628854751587, 0.06979861110448837), (-0.4951336085796356, 0.03570220619440079), (1.1177953481674194, 0.07417943328619003)]\n",
      "-0.571835458278656\n",
      "reset\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([0.2916])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([-0.2932])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([0.1989])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([-0.4612])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([0.9890])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([-0.5968])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([-0.0908])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([1.0233])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([0.8841])\n",
      "tensor(0.1686, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 2] tensor([-0.3602])\n",
      "10\n",
      "[(0.29162079095840454, 0.007274614181369543), (-0.29317405819892883, 0.061514973640441895), (0.19886241853237152, 0.1446438729763031), (-0.4611642062664032, 0.02666783332824707), (0.9889519214630127, 0.06155429035425186), (-0.5967543125152588, 0.04487580806016922), (-0.09080938994884491, 0.0319201685488224), (1.0233365297317505, 0.04956734925508499), (0.8841349482536316, 0.006720345932990313), (-0.36022844910621643, 0.08565990626811981)]\n",
      "0.8841349482536316\n",
      "reset\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([-0.1692])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([-1.1971])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([-0.8829])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([-0.1448])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([0.0365])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([0.8386])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([1.0121])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([0.1906])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([-0.2519])\n",
      "tensor(-0.0068, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 0] tensor([0.4013])\n",
      "10\n",
      "[(-0.16916614770889282, 0.026035448536276817), (-1.197141170501709, 0.036785464733839035), (-0.8828636407852173, 0.07177739590406418), (-0.14481045305728912, 0.02758941985666752), (0.036470115184783936, 0.048404354602098465), (0.8385672569274902, 0.02258252166211605), (1.0120712518692017, 0.012930285185575485), (0.19062599539756775, 0.018618160858750343), (-0.25192558765411377, 0.02040541172027588), (0.4012892246246338, 0.06745176017284393)]\n",
      "1.0120712518692017\n",
      "reset\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-1.4057])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([0.4749])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.6839])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-1.3829])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-1.4987])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.6367])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.7293])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([0.5020])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-1.7218])\n",
      "tensor(-0.3695, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 0] tensor([-0.9006])\n",
      "10\n",
      "[(-1.405705451965332, 0.0125843221321702), (0.47488558292388916, 0.06700144708156586), (-0.6838821768760681, 0.06902443617582321), (-1.382875919342041, 0.04067119210958481), (-1.4987272024154663, 0.0946105420589447), (-0.6367253661155701, 0.016718029975891113), (-0.7293415665626526, 0.051239434629678726), (0.5020122528076172, 0.04201668128371239), (-1.7217506170272827, 0.05717487633228302), (-0.9006130695343018, 0.018271688371896744)]\n",
      "-1.405705451965332\n",
      "reset\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([-0.2816])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([0.4985])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([-0.4671])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([-1.4544])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([-0.0285])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([0.2080])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([0.7196])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([0.5800])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([0.0657])\n",
      "tensor(0.2102, grad_fn=<SelectBackward0>) tensor(1.) 3 [4] tensor([-0.0713])\n",
      "10\n",
      "[(-0.28164657950401306, 0.02853350155055523), (0.4984579086303711, 0.02133829891681671), (-0.4671165645122528, 0.04059802368283272), (-1.4544196128845215, 0.028889603912830353), (-0.028535455465316772, 0.010581436567008495), (0.20801183581352234, 0.08033882081508636), (0.7195557355880737, 0.04369569197297096), (0.5799532532691956, 0.04800831526517868), (0.06573626399040222, 0.16933245956897736), (-0.0712909996509552, 0.023245861753821373)]\n",
      "-0.028535455465316772\n",
      "reset\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([2.3327])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-1.2062])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.0116])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.2024])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.2547])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.1212])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.4208])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.5506])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.1924])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.0627])\n",
      "10\n",
      "[(2.3326735496520996, 0.12820512056350708), (-1.2061976194381714, 0.018780190497636795), (-0.011608785018324852, 0.053579628467559814), (0.2024488002061844, 0.019890090450644493), (-0.2547360956668854, 0.1331615447998047), (-0.121213398873806, 0.06896279007196426), (-0.4208162724971771, 0.06072350963950157), (0.5505825877189636, 0.040832772850990295), (0.19237352907657623, 0.07627195119857788), (-0.06270933896303177, 0.04087420552968979)]\n",
      "-1.2061976194381714\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.2904])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.7638])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.3073])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.6433])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.8297])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.9932])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.1664])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.9676])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.3793])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.6031])\n",
      "10\n",
      "[(0.2903818190097809, 0.0028155737090855837), (0.7638127207756042, 0.06935793906450272), (0.30730047821998596, 0.01974194496870041), (1.6432950496673584, 0.023466678336262703), (0.8297154307365417, 0.06833645701408386), (0.9931967258453369, 0.12315438687801361), (0.16641487181186676, 0.09534666687250137), (0.967642605304718, 0.0068543897941708565), (-0.3793279826641083, 0.026003092527389526), (0.603059709072113, 0.025184066966176033)]\n",
      "0.2903818190097809\n",
      "reset\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.8624])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.0937])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.6713])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.3996])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.8838])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.0561])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.2384])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.1936])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.8909])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-2.0934])\n",
      "10\n",
      "[(0.8624045252799988, 0.013087491504848003), (-0.09368237107992172, 0.019602911546826363), (0.6712937355041504, 0.10123445838689804), (-1.3995774984359741, 0.28316402435302734), (0.8837812542915344, 0.02748061902821064), (0.056114617735147476, 0.09880687296390533), (0.23841170966625214, 0.03377702832221985), (0.19364526867866516, 0.027154337614774704), (-1.8909324407577515, 0.03083416074514389), (-2.093416690826416, 0.032031621783971786)]\n",
      "0.8624045252799988\n",
      "reset\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.4228])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-0.4435])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([1.2565])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-0.0218])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-0.0233])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.8921])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.5748])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([-0.6777])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.0637])\n",
      "tensor(0.1314, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 1] tensor([0.2181])\n",
      "10\n",
      "[(0.42282313108444214, 0.005493815056979656), (-0.4435144364833832, 0.16960419714450836), (1.2565062046051025, 0.10610737651586533), (-0.02178746461868286, 0.08871406316757202), (-0.023327678442001343, 0.09113907068967819), (0.8920854926109314, 0.01599097065627575), (0.5747518539428711, 0.025752002373337746), (-0.6777161955833435, 0.01730523630976677), (0.06372036784887314, 0.06048879399895668), (0.21805544197559357, 0.12543079257011414)]\n",
      "0.42282313108444214\n",
      "reset\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.4364])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.2642])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.2107])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.6939])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.1996])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-1.0327])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([1.0681])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.6784])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-1.1141])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-1.6066])\n",
      "10\n",
      "[(0.4364384114742279, 0.1099238321185112), (-0.26420387625694275, 0.012432806193828583), (0.21067258715629578, 0.05055123567581177), (0.6939476132392883, 0.039351463317871094), (-0.1996292620897293, 0.03603316843509674), (-1.0326687097549438, 0.06713253259658813), (1.0681045055389404, 0.025545241311192513), (0.6784360408782959, 0.04524929076433182), (-1.1141279935836792, 0.009556476958096027), (-1.6065738201141357, 0.028323721140623093)]\n",
      "-1.1141279935836792\n",
      "reset\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.1341])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.2553])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.1778])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.6106])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([1.7799])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.5796])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.2660])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.2558])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.5690])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([2.1525])\n",
      "10\n",
      "[(-0.13408808410167694, 0.013003440573811531), (-0.25534939765930176, 0.031811609864234924), (-0.17782162129878998, 0.1251945197582245), (0.6106439828872681, 0.12130683660507202), (1.779933214187622, 0.03290971741080284), (-0.5795615911483765, 0.08753237873315811), (0.2659651041030884, 0.0808166116476059), (-0.2557627856731415, 0.07314718514680862), (-0.5689976811408997, 0.0542108491063118), (2.1525003910064697, 0.05117062106728554)]\n",
      "-0.13408808410167694\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.2082])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.5093])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.5250])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.7883])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.3432])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.0498])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.3323])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.1575])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.2532])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.0346])\n",
      "10\n",
      "[(0.2082393914461136, 0.027750946581363678), (0.5092528462409973, 0.036195214837789536), (1.5249537229537964, 0.07859775424003601), (-0.7883104681968689, 0.008398310281336308), (-0.3432171642780304, 0.025152703747153282), (-0.04982488229870796, 0.05173929035663605), (1.3322770595550537, 0.09204882383346558), (-0.15754763782024384, 0.07156755775213242), (1.253220796585083, 0.00571381626650691), (1.0346170663833618, 0.2786714434623718)]\n",
      "1.253220796585083\n",
      "reset\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([-0.6261])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.6196])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([1.0413])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.9608])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([1.2510])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.1605])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([1.1121])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([-0.9928])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.5362])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.5725])\n",
      "10\n",
      "[(-0.6261321306228638, 0.040727078914642334), (0.6195664405822754, 0.027444446459412575), (1.0413413047790527, 0.08946694433689117), (0.9607632756233215, 0.014655410312116146), (1.2510185241699219, 0.1380223035812378), (0.16048367321491241, 0.06884292513132095), (1.112148404121399, 0.04337552934885025), (-0.9928470849990845, 0.03273296728730202), (0.5362045168876648, 0.06929607689380646), (0.5725368857383728, 0.3302379250526428)]\n",
      "0.9607632756233215\n",
      "reset\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.7833])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.0327])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([1.1630])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.3971])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.3330])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([1.7999])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.0540])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.6542])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.2063])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.3775])\n",
      "10\n",
      "[(-0.7833219170570374, 0.07108217477798462), (-0.03273874148726463, 0.0792875736951828), (1.1630264520645142, 0.10094084590673447), (0.39708569645881653, 0.011971970088779926), (-0.3330424129962921, 0.06507883965969086), (1.7998545169830322, 0.10383576154708862), (0.05398649722337723, 0.014024440199136734), (0.6541635394096375, 0.06121652200818062), (-0.2062535285949707, 0.018116585910320282), (-1.3775075674057007, 0.024277213960886)]\n",
      "0.39708569645881653\n",
      "reset\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-1.0437])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.8106])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.0332])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.5919])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.8248])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.3747])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.0979])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.9752])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.0067])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.1366])\n",
      "10\n",
      "[(-1.0437147617340088, 0.0206069964915514), (0.8105575442314148, 0.059394873678684235), (-0.03318076580762863, 0.14494949579238892), (0.5919075012207031, 0.048889655619859695), (0.8248295783996582, 0.019448406994342804), (0.3746674656867981, 0.025018539279699326), (0.09785816818475723, 0.021209746599197388), (0.975241482257843, 0.06689199805259705), (0.00666585098952055, 0.053143538534641266), (-0.1366381198167801, 0.015346071682870388)]\n",
      "-0.1366381198167801\n",
      "reset\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.0881])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.5635])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.3547])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.5657])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.9747])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([1.0250])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.3908])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([1.3056])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.4095])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.4484])\n",
      "10\n",
      "[(-0.08814013004302979, 0.03902386873960495), (-0.5635073781013489, 0.013675343245267868), (-0.3546651005744934, 0.04707322642207146), (-0.5657069683074951, 0.09916887432336807), (-0.9746925830841064, 0.04950485751032829), (1.02501380443573, 0.02325124479830265), (0.39083558320999146, 0.06640053540468216), (1.3055579662322998, 0.04040665552020073), (-0.4095037877559662, 0.03166823834180832), (-0.44838017225265503, 0.04930802807211876)]\n",
      "-0.5635073781013489\n",
      "reset\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.1450])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-2.3578])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.1532])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.5200])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.2996])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.8290])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([2.2614])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.5312])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-2.4569])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.0773])\n",
      "10\n",
      "[(-1.1449676752090454, 0.055534813553094864), (-2.357819080352783, 0.10957688838243484), (0.15320530533790588, 0.01956343464553356), (-0.5200286507606506, 0.0184172336012125), (-0.29957666993141174, 0.01721750758588314), (-0.8289567232131958, 0.06083428114652634), (2.2614312171936035, 0.04994027689099312), (0.5311779975891113, 0.06891954690217972), (-2.4568662643432617, 0.03637804836034775), (-1.0772775411605835, 0.11514593660831451)]\n",
      "-0.29957666993141174\n",
      "reset\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([-0.7402])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([1.6468])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([1.5072])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([0.6375])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([-0.1939])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([0.9448])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([0.9894])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([0.5531])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([0.7373])\n",
      "tensor(0.1232, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 0] tensor([1.2078])\n",
      "10\n",
      "[(-0.7402459979057312, 0.024103764444589615), (1.646821141242981, 0.0756191834807396), (1.5072482824325562, 0.03308679535984993), (0.6375487446784973, 0.15268395841121674), (-0.19391876459121704, 0.09765219688415527), (0.9447536468505859, 0.029962170869112015), (0.9893602132797241, 0.014944967813789845), (0.5531358122825623, 0.005034915637224913), (0.7372538447380066, 0.10281211882829666), (1.2077521085739136, 0.029774818569421768)]\n",
      "0.5531358122825623\n",
      "reset\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([0.0516])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-2.0671])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-0.3696])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-0.5166])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-1.1581])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([0.6183])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-0.7452])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-1.2541])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([1.2751])\n",
      "tensor(-0.0471, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 6] tensor([-1.7952])\n",
      "10\n",
      "[(0.051579151302576065, 0.04462812468409538), (-2.067112684249878, 0.12549161911010742), (-0.3695733845233917, 0.014535314403474331), (-0.5165783166885376, 0.0410175658762455), (-1.158079743385315, 0.18866832554340363), (0.6182538866996765, 0.043385546654462814), (-0.7451887130737305, 0.017337042838335037), (-1.2540937662124634, 0.0282510407269001), (1.2751195430755615, 0.025700777769088745), (-1.7952008247375488, 0.1325579732656479)]\n",
      "-0.3695733845233917\n",
      "reset\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.5104])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([1.6195])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([0.1920])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.4056])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.3815])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.1905])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([1.5906])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.6158])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-1.3859])\n",
      "tensor(-0.2016, grad_fn=<SelectBackward0>) tensor(1.) 1 [1] tensor([-0.2507])\n",
      "10\n",
      "[(-0.5104214549064636, 0.02642754465341568), (1.6194761991500854, 0.09812407195568085), (0.1919984370470047, 0.030288666486740112), (-1.4055536985397339, 0.03529233857989311), (-0.3814876079559326, 0.03999103978276253), (-1.1905330419540405, 0.05559558421373367), (1.590598225593567, 0.009037339128553867), (-0.6157796382904053, 0.06623915582895279), (-1.3859424591064453, 0.06127847358584404), (-0.25071606040000916, 0.02842818945646286)]\n",
      "1.590598225593567\n",
      "reset\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([1.4479])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([1.2475])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([0.3020])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([0.1971])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([-0.7543])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([-1.3415])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([-0.4971])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([1.0128])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([-0.2064])\n",
      "tensor(0.1767, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 0] tensor([0.3715])\n",
      "10\n",
      "[(1.4478529691696167, 0.025147097185254097), (1.2475192546844482, 0.044674139469861984), (0.3020201325416565, 0.04950337111949921), (0.1970549374818802, 0.015896212309598923), (-0.7543403506278992, 0.02027842216193676), (-1.3415327072143555, 0.021594995632767677), (-0.497103750705719, 0.06086772680282593), (1.012839674949646, 0.02278122678399086), (-0.20637136697769165, 0.02232692949473858), (0.3714940547943115, 0.022740555927157402)]\n",
      "0.1970549374818802\n",
      "reset\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([0.0705])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([-0.0713])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([1.0582])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([0.9317])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([-0.0708])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([-0.8503])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([0.4793])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([-0.5488])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([0.0388])\n",
      "tensor(0.2270, grad_fn=<SelectBackward0>) tensor(1.) 3 [1] tensor([-0.9022])\n",
      "10\n",
      "[(0.07051527500152588, 0.09177244454622269), (-0.07126840949058533, 0.023123804479837418), (1.0581860542297363, 0.022926416248083115), (0.9317219853401184, 0.043177857995033264), (-0.07077455520629883, 0.05566447600722313), (-0.8503156304359436, 0.06251222640275955), (0.479328989982605, 0.14756739139556885), (-0.5487858653068542, 0.04245269298553467), (0.0388157032430172, 0.12526601552963257), (-0.9021865129470825, 0.021617982536554337)]\n",
      "-0.9021865129470825\n",
      "reset\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([0.5926])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([-1.0091])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([0.4138])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([-0.7280])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([1.8787])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([0.6964])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([-0.4071])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([-0.3246])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([-0.4172])\n",
      "tensor(0.1389, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 4] tensor([-0.7346])\n",
      "10\n",
      "[(0.5926101803779602, 0.015587384812533855), (-1.009127140045166, 0.13007111847400665), (0.4137604236602783, 0.02173333242535591), (-0.7280279397964478, 0.06923579424619675), (1.8787001371383667, 0.035831473767757416), (0.6964281797409058, 0.02592993527650833), (-0.4071061611175537, 0.03273868188261986), (-0.3245861232280731, 0.0346885547041893), (-0.4172057509422302, 0.04635268449783325), (-0.7345872521400452, 0.03590112552046776)]\n",
      "0.5926101803779602\n",
      "reset\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.5070])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.3409])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.4839])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.5262])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.7447])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([0.9378])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-1.2686])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.6553])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.3485])\n",
      "tensor(-0.0733, grad_fn=<SelectBackward0>) tensor(1.) 1 [0] tensor([-0.0497])\n",
      "10\n",
      "[(-0.5069677829742432, 0.02959337830543518), (-0.34085866808891296, 0.01581687480211258), (-0.48385587334632874, 0.06570123136043549), (-0.5262205600738525, 0.04364790767431259), (-0.7446671724319458, 0.018658161163330078), (0.9377714395523071, 0.12300429493188858), (-1.2686032056808472, 0.10439760982990265), (-0.6552762985229492, 0.06851598620414734), (-0.3485006093978882, 0.06157706677913666), (-0.04965297877788544, 0.24559880793094635)]\n",
      "-0.34085866808891296\n",
      "reset\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.5377])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([2.4670])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.4171])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.2057])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.6942])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.9568])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.0776])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-2.9616])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.1543])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.8263])\n",
      "10\n",
      "[(-0.5376848578453064, 0.1918555051088333), (2.466991424560547, 0.018723465502262115), (-0.41706785559654236, 0.12822267413139343), (1.2056641578674316, 0.009037396870553493), (-0.6942165493965149, 0.01634681224822998), (-0.9567744731903076, 0.020441582426428795), (0.07756362110376358, 0.028302470222115517), (-2.9616074562072754, 0.05322616174817085), (0.15426059067249298, 0.04325869306921959), (-0.8263071775436401, 0.09187769144773483)]\n",
      "1.2056641578674316\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.8436])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.5092])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.1840])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.6283])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.5145])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.0545])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.6576])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.9787])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.5512])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.3171])\n",
      "10\n",
      "[(1.8436170816421509, 0.48791974782943726), (1.5091606378555298, 0.0547667033970356), (-0.1840367466211319, 0.020529238507151604), (0.6282528638839722, 0.008645676076412201), (-0.5145312547683716, 0.07318127155303955), (-0.05453011393547058, 0.059305477887392044), (0.6575831770896912, 0.022227581590414047), (0.9786989092826843, 0.053410448133945465), (1.5512453317642212, 0.046831946820020676), (0.3170647919178009, 0.022460514679551125)]\n",
      "0.6282528638839722\n",
      "reset\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([1.5287])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.9810])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.0968])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-2.3828])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.6819])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.2280])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.0118])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([1.3492])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([1.0045])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.0829])\n",
      "10\n",
      "[(1.5287220478057861, 0.011094851419329643), (-0.9809866547584534, 0.12069522589445114), (-0.0967857763171196, 0.03575274348258972), (-2.382829427719116, 0.2324155569076538), (-0.6818669438362122, 0.03876509144902229), (-1.2279794216156006, 0.033785901963710785), (-0.011819952167570591, 0.017519835382699966), (1.3491500616073608, 0.039882633835077286), (1.0044605731964111, 0.039910152554512024), (0.08289238810539246, 0.03943711891770363)]\n",
      "1.5287220478057861\n",
      "reset\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([0.3782])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([0.7298])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([-0.8602])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([0.6837])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([0.5766])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([-0.7768])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([-0.5493])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([0.6360])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([-0.9569])\n",
      "tensor(0.2579, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 5] tensor([-0.5531])\n",
      "10\n",
      "[(0.37821123003959656, 0.025675145909190178), (0.7298481464385986, 0.06976588070392609), (-0.8602188229560852, 0.03071950376033783), (0.6836696267127991, 0.024846378713846207), (0.5765954256057739, 0.02291707880795002), (-0.7768467664718628, 0.020028475672006607), (-0.54930579662323, 0.02324756607413292), (0.6360004544258118, 0.07667115330696106), (-0.9569341540336609, 0.03016073629260063), (-0.5530734062194824, 0.07025734335184097)]\n",
      "-0.7768467664718628\n",
      "reset\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-0.5098])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([0.8005])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-0.4788])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-0.0070])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-1.0441])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([1.1601])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([0.8121])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-0.0304])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-1.0004])\n",
      "tensor(0.1037, grad_fn=<SelectBackward0>) tensor(1.) 1 [3] tensor([-0.3375])\n",
      "10\n",
      "[(-0.5097723603248596, 0.03499056398868561), (0.8004568815231323, 0.0663410872220993), (-0.47880685329437256, 0.06778301298618317), (-0.006982353515923023, 0.07944973558187485), (-1.0441105365753174, 0.05302324891090393), (1.1601145267486572, 0.04054604470729828), (0.8120713233947754, 0.046909283846616745), (-0.030396493151783943, 0.03302270919084549), (-1.0004469156265259, 0.019614409655332565), (-0.3374691605567932, 0.040646787732839584)]\n",
      "-1.0004469156265259\n",
      "reset\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.1752])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.2557])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.3295])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.3247])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.8072])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.4208])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.5410])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-2.2804])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.3779])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.6027])\n",
      "10\n",
      "[(1.1752338409423828, 0.15507441759109497), (1.2556811571121216, 0.10770243406295776), (1.3295300006866455, 0.024571552872657776), (-0.32469338178634644, 0.037935804575681686), (0.8072429895401001, 0.026191556826233864), (0.4208444058895111, 0.0712805911898613), (1.5409883260726929, 0.04181037098169327), (-2.2804043292999268, 0.03710875287652016), (-0.37789982557296753, 0.3867550790309906), (-0.60267573595047, 0.06257994472980499)]\n",
      "1.3295300006866455\n",
      "reset\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.1970])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.2017])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.1025])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.2236])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.0761])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.7013])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.0669])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.3342])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-2.3032])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.8095])\n",
      "10\n",
      "[(-0.19702908396720886, 0.014573629014194012), (0.20174485445022583, 0.02445233426988125), (-1.1024693250656128, 0.012928621843457222), (-0.2236226201057434, 0.03147166594862938), (-0.07608143240213394, 0.1905887871980667), (-0.701301097869873, 0.3973984122276306), (0.06688997894525528, 0.04123209789395332), (0.3341558575630188, 0.03426378592848778), (-2.3031904697418213, 0.04557293653488159), (-1.8094568252563477, 0.0171230249106884)]\n",
      "-1.1024693250656128\n",
      "reset\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-1.2366])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([2.2633])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.1547])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.5704])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.6639])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.5360])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.3509])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.2572])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.0959])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.7176])\n",
      "10\n",
      "[(-1.2365528345108032, 0.04453857243061066), (2.2632534503936768, 0.006795301102101803), (0.15470613539218903, 0.02997581474483013), (0.5703820586204529, 0.05438699945807457), (1.6639257669448853, 0.050096362829208374), (-0.5360387563705444, 0.02965758554637432), (0.350861519575119, 0.04100347310304642), (0.25718367099761963, 0.018448343500494957), (0.09590169787406921, 0.01601535826921463), (0.717631459236145, 0.020943958312273026)]\n",
      "2.2632534503936768\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([2.0097])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.5919])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.2913])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.5462])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.8882])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.3966])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.1039])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.0033])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([2.4526])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.5261])\n",
      "10\n",
      "[(2.009716272354126, 0.024590492248535156), (-0.5918700098991394, 0.05038199573755264), (0.2912674844264984, 0.029485464096069336), (0.5461905002593994, 0.13397391140460968), (0.888188362121582, 0.06724861264228821), (0.3966190814971924, 0.14275558292865753), (-0.10390758514404297, 0.06085486710071564), (-0.0033498702105134726, 0.06297667324542999), (2.452599287033081, 0.11841122806072235), (0.5260631442070007, 0.04722865670919418)]\n",
      "2.009716272354126\n",
      "reset\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.8583])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.0184])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.1772])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.4908])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.8458])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.7418])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-1.3273])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.4490])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.3504])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.0423])\n",
      "10\n",
      "[(0.8582819104194641, 0.061835188418626785), (-0.018352553248405457, 0.14669635891914368), (-0.17718592286109924, 0.037702180445194244), (-0.4908338785171509, 0.052825842052698135), (-0.8458264470100403, 0.03965647891163826), (0.7417641878128052, 0.0358259491622448), (-1.327344298362732, 0.020703865215182304), (0.4489748179912567, 0.08952397108078003), (0.35036563873291016, 0.017698494717478752), (-0.042306527495384216, 0.01565910503268242)]\n",
      "-0.042306527495384216\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.2568])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.9525])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([2.1846])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.1448])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.4717])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.6364])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.1622])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([1.0924])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.5777])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.7158])\n",
      "10\n",
      "[(-0.2567613422870636, 0.01783568784594536), (0.9524852633476257, 0.012964406050741673), (2.1846120357513428, 0.023691780865192413), (-0.14475402235984802, 0.059048380702733994), (0.47173893451690674, 0.032231155782938004), (0.6363949179649353, 0.037852708250284195), (0.16220736503601074, 0.14569123089313507), (1.0923622846603394, 0.12270492315292358), (0.5777028203010559, 0.03576793521642685), (-0.715774416923523, 0.01934743858873844)]\n",
      "0.9524852633476257\n",
      "reset\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([0.6838])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([-2.0312])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([-0.4128])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([0.4456])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([-1.9843])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([1.1409])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([-0.1221])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([1.1511])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([-0.8086])\n",
      "tensor(-0.2370, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 1] tensor([-0.9440])\n",
      "10\n",
      "[(0.6837660670280457, 0.06896175444126129), (-2.031219244003296, 0.03707762062549591), (-0.4128037989139557, 0.09247209876775742), (0.4455902874469757, 0.028215980157256126), (-1.984311819076538, 0.017306432127952576), (1.1409351825714111, 0.31135693192481995), (-0.12212803959846497, 0.02486157976090908), (1.151111364364624, 0.061081383377313614), (-0.8085677027702332, 0.01998326927423477), (-0.9439808130264282, 0.08920402824878693)]\n",
      "-1.984311819076538\n",
      "reset\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.2198])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.0537])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([1.3808])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.2898])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.2588])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.9930])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.2804])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.9697])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.0554])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-2.8031])\n",
      "10\n",
      "[(-0.21976596117019653, 0.06669163703918457), (-1.0537141561508179, 0.053001757711172104), (1.3808342218399048, 0.03301068767905235), (0.2898027300834656, 0.017088238149881363), (-0.25876644253730774, 0.018889661878347397), (0.9929519295692444, 0.051080282777547836), (-1.280391812324524, 0.04087882488965988), (-0.9696710705757141, 0.05528382211923599), (-0.055443793535232544, 0.12307971715927124), (-2.8030569553375244, 0.07511609047651291)]\n",
      "0.2898027300834656\n",
      "reset\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-0.8570])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-1.1960])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-1.2874])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-0.3506])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-1.1530])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-1.0570])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-0.7347])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-0.3446])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([0.5083])\n",
      "tensor(-0.2860, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 2] tensor([-0.9052])\n",
      "10\n",
      "[(-0.8569895029067993, 0.048497024923563004), (-1.1959683895111084, 0.12322122603654861), (-1.2874404191970825, 0.037626199424266815), (-0.3506326973438263, 0.03233187273144722), (-1.1530338525772095, 0.002191422274336219), (-1.0569508075714111, 0.005607515573501587), (-0.7347281575202942, 0.03189898654818535), (-0.3446120023727417, 0.02818812057375908), (0.5083379149436951, 0.0330723412334919), (-0.9052141904830933, 0.027606435120105743)]\n",
      "-1.1530338525772095\n",
      "reset\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.7907])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([1.3229])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-1.4030])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.7968])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.1382])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.1471])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.3993])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.4587])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.1276])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-1.5934])\n",
      "10\n",
      "[(0.7906653881072998, 0.10287618637084961), (1.3229061365127563, 0.057417526841163635), (-1.4029747247695923, 0.020115889608860016), (-0.7967944145202637, 0.14081473648548126), (-0.1382298618555069, 0.03566545248031616), (-0.14706973731517792, 0.014343264512717724), (-0.39929360151290894, 0.057946160435676575), (-0.458673357963562, 0.047130048274993896), (0.1275501698255539, 0.015807900577783585), (-1.5934017896652222, 0.010959294624626637)]\n",
      "-1.5934017896652222\n",
      "reset\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.7174])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-1.4477])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([1.6606])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-1.3655])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.9100])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([1.8115])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.7080])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.3395])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([-0.2351])\n",
      "tensor(-0.2562, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 2] tensor([0.1507])\n",
      "10\n",
      "[(0.7173614501953125, 0.11765434592962265), (-1.447684407234192, 0.0697566568851471), (1.6605678796768188, 0.059651944786310196), (-1.365505576133728, 0.08186003565788269), (-0.9100341796875, 0.10118407756090164), (1.8114922046661377, 0.0678146630525589), (0.7079630494117737, 0.02470366656780243), (-0.3394661247730255, 0.02388799749314785), (-0.23508141934871674, 0.017011819407343864), (0.15069854259490967, 0.05693257972598076)]\n",
      "-0.23508141934871674\n",
      "reset\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-1.3067])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.6653])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.4051])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.0391])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.0041])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([3.7994])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.8339])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.3776])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.3229])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.3909])\n",
      "10\n",
      "[(-1.3067059516906738, 0.03473237156867981), (0.6652916073799133, 0.008207499049603939), (-0.405072420835495, 0.01584944687783718), (-0.039053160697221756, 0.015639111399650574), (-0.004067118279635906, 0.04513925313949585), (3.799351215362549, 0.015458617359399796), (0.8338509798049927, 0.03893493115901947), (0.3776421546936035, 0.011619305238127708), (0.3229201138019562, 0.16847646236419678), (1.390885829925537, 0.02725313976407051)]\n",
      "0.6652916073799133\n",
      "reset\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([1.6609])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([0.0538])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([-1.9640])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([2.0137])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([-0.7774])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([-0.5351])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([-0.8692])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([0.2774])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([-0.0134])\n",
      "tensor(-0.1725, grad_fn=<SelectBackward0>) tensor(1.) 4 [0, 2] tensor([-1.1635])\n",
      "10\n",
      "[(1.6608549356460571, 0.02214735373854637), (0.05381454899907112, 0.0804625153541565), (-1.9640023708343506, 0.02075979672372341), (2.013721466064453, 0.07885009050369263), (-0.7773802876472473, 0.0315416119992733), (-0.535087525844574, 0.05708707123994827), (-0.8692150115966797, 0.01340738870203495), (0.27737975120544434, 0.023540038615465164), (-0.01344112679362297, 0.04151513800024986), (-1.1634536981582642, 0.02251940779387951)]\n",
      "-0.8692150115966797\n",
      "reset\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.0936])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.2452])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.3653])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.2105])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.1024])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.3011])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-1.1083])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.6105])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.5674])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.6821])\n",
      "10\n",
      "[(-0.0935794860124588, 0.01751806028187275), (-0.24521957337856293, 0.024766305461525917), (-0.3653329014778137, 0.1507994532585144), (1.2105196714401245, 0.00823537539690733), (0.10236195474863052, 0.02021302469074726), (1.3010599613189697, 0.018729165196418762), (-1.1082611083984375, 0.04086325317621231), (0.6105154156684875, 0.026191536337137222), (1.5673784017562866, 0.021773532032966614), (-0.6820970177650452, 0.04128206893801689)]\n",
      "1.2105196714401245\n",
      "reset\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.5331])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([2.3521])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.0249])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.4576])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.0592])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.8341])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.6715])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.1436])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.2019])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-1.5794])\n",
      "10\n",
      "[(-0.5331066250801086, 0.02543277107179165), (2.3520541191101074, 0.03874281793832779), (1.0248991250991821, 0.0979941338300705), (0.45758867263793945, 0.04012339562177658), (0.05915667489171028, 0.011138814501464367), (0.8340665102005005, 0.04046204686164856), (-0.6715290546417236, 0.07398585975170135), (1.1436079740524292, 0.02593705616891384), (0.2019193023443222, 0.09845249354839325), (-1.5794236660003662, 0.017859118059277534)]\n",
      "0.05915667489171028\n",
      "reset\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([1.6594])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-1.3434])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.7787])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-0.2556])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-0.4332])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.7809])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-1.1553])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([1.9799])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.9230])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-0.9006])\n",
      "10\n",
      "[(1.6594111919403076, 0.05982460454106331), (-1.3434287309646606, 0.03218648210167885), (0.7787412405014038, 0.022366033867001534), (-0.25560101866722107, 0.017097340896725655), (-0.43316447734832764, 0.08968085050582886), (0.7809106707572937, 0.0586371086537838), (-1.1553412675857544, 0.032149992883205414), (1.9798997640609741, 0.015965469181537628), (0.9230065941810608, 0.034981295466423035), (-0.9005813598632812, 0.06491503864526749)]\n",
      "1.9798997640609741\n",
      "reset\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.5288])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.2307])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.6775])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.9856])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.0104])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([1.1888])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.1015])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.5480])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.0515])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.1148])\n",
      "10\n",
      "[(0.5287509560585022, 0.04126451537013054), (0.23071396350860596, 0.055426716804504395), (0.6775067448616028, 0.016446266323328018), (0.9856396317481995, 0.02454051934182644), (0.01039979886263609, 0.04528513178229332), (1.1888493299484253, 0.07866592705249786), (0.10148801654577255, 0.01477041095495224), (0.5479560494422913, 0.011171141639351845), (0.05147838592529297, 0.028724899515509605), (0.11475110799074173, 0.0499335378408432)]\n",
      "0.5479560494422913\n",
      "reset\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([-0.6790])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([0.1103])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([-0.4644])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([-1.5834])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([0.1699])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([0.7755])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([-1.8632])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([-0.3855])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([0.8724])\n",
      "tensor(0.2254, grad_fn=<SelectBackward0>) tensor(1.) 2 [1, 5] tensor([-0.0501])\n",
      "10\n",
      "[(-0.6790282726287842, 0.05150879919528961), (0.1102813258767128, 0.044607795774936676), (-0.4644210636615753, 0.05671411380171776), (-1.5833979845046997, 0.051759954541921616), (0.16987484693527222, 0.01706063561141491), (0.7754544615745544, 0.05773541331291199), (-1.8632258176803589, 0.06442627310752869), (-0.38546034693717957, 0.0549929216504097), (0.8724181056022644, 0.06267857551574707), (-0.05008421093225479, 0.15621960163116455)]\n",
      "0.16987484693527222\n",
      "reset\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.8334])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.3181])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.9554])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.2031])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.5274])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.3015])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.1017])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.6197])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([1.4168])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.0644])\n",
      "10\n",
      "[(-0.8334242701530457, 0.080985426902771), (1.3181487321853638, 0.03438108414411545), (0.9553698897361755, 0.08054458349943161), (1.2031207084655762, 0.026299554854631424), (0.5273587107658386, 0.12461841851472855), (-0.30149760842323303, 0.013946848921477795), (1.1016900539398193, 0.02727435901761055), (1.6197181940078735, 0.026641760021448135), (1.4168291091918945, 0.04470672458410263), (-0.064427450299263, 0.06977616250514984)]\n",
      "-0.30149760842323303\n",
      "reset\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([-2.1036])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.9073])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([2.0240])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([1.1192])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([1.8686])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([-0.2130])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([1.7883])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([1.4983])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([0.3446])\n",
      "tensor(0.1057, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 4] tensor([-1.1219])\n",
      "10\n",
      "[(-2.103572368621826, 0.039086632430553436), (0.9072573781013489, 0.07415885478258133), (2.0240418910980225, 0.022848118096590042), (1.1191576719284058, 0.053842734545469284), (1.8686271905899048, 0.08451098948717117), (-0.21300826966762543, 0.028220636770129204), (1.7882694005966187, 0.14051172137260437), (1.4983304738998413, 0.211356520652771), (0.34463614225387573, 0.045348748564720154), (-1.121875286102295, 0.03279902786016464)]\n",
      "2.0240418910980225\n",
      "reset\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.3056])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-0.2328])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.5445])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.4833])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.9438])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([-0.5603])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.0215])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.4461])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.6200])\n",
      "tensor(0.3468, grad_fn=<SelectBackward0>) tensor(1.) 1 [4] tensor([0.1060])\n",
      "10\n",
      "[(0.30559366941452026, 0.05724324658513069), (-0.2327783703804016, 0.08575433492660522), (0.5445230603218079, 0.05000411346554756), (0.4833325147628784, 0.046483807265758514), (0.9438478350639343, 0.040325768291950226), (-0.5602961182594299, 0.01217398140579462), (0.0215486828237772, 0.02281995303928852), (0.4461219012737274, 0.01783745177090168), (0.6200070977210999, 0.01612398400902748), (0.10599607974290848, 0.029773835092782974)]\n",
      "-0.5602961182594299\n",
      "reset\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([1.1735])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([1.2544])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([-0.4821])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([0.5267])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([0.7559])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([-0.6970])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([1.6020])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([1.1668])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([0.9171])\n",
      "tensor(0.2475, grad_fn=<SelectBackward0>) tensor(1.) 4 [1, 5] tensor([-0.1629])\n",
      "10\n",
      "[(1.1734975576400757, 0.08170576393604279), (1.254433274269104, 0.026687799021601677), (-0.4821494519710541, 0.0496244914829731), (0.52667635679245, 0.08326676487922668), (0.7559027075767517, 0.04942870885133743), (-0.6969920992851257, 0.007127424702048302), (1.6020371913909912, 0.06399156898260117), (1.1667901277542114, 0.08171326667070389), (0.9170539975166321, 0.029168784618377686), (-0.16291005909442902, 0.019240502268075943)]\n",
      "-0.6969920992851257\n",
      "reset\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([1.3237])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.9224])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.0357])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-1.3099])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.0080])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-3.1709])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.5419])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.9153])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([-0.5693])\n",
      "tensor(-0.3259, grad_fn=<SelectBackward0>) tensor(1.) 5 [2] tensor([0.0797])\n",
      "10\n",
      "[(1.323749303817749, 0.05996581166982651), (-1.922446846961975, 0.01458854228258133), (-1.0356544256210327, 0.058381907641887665), (-1.3099300861358643, 0.07715995609760284), (0.007950267754495144, 0.035007674247026443), (-3.170881509780884, 0.2744484543800354), (0.5419235825538635, 0.11712990701198578), (-0.9152941107749939, 0.08206864446401596), (-0.5692554116249084, 0.08463293313980103), (0.07974229753017426, 0.03078674152493477)]\n",
      "-1.922446846961975\n",
      "reset\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([0.3670])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([-0.8387])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([0.5724])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([-1.2050])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([-0.2047])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([-0.5097])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([-1.1993])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([2.3592])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([-0.2942])\n",
      "tensor(-0.0488, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 2] tensor([0.0550])\n",
      "10\n",
      "[(0.3669837415218353, 0.08408638834953308), (-0.8386874794960022, 0.01932590827345848), (0.5724321603775024, 0.032039836049079895), (-1.2050001621246338, 0.1591978371143341), (-0.20472294092178345, 0.0894731804728508), (-0.5096859931945801, 0.02103923074901104), (-1.1993135213851929, 0.07472888380289078), (2.3592276573181152, 0.06250300258398056), (-0.2942260801792145, 0.055348094552755356), (0.054954711347818375, 0.07243961095809937)]\n",
      "-0.8386874794960022\n",
      "reset\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.3428])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.4418])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-2.5231])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.2435])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.5347])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.1339])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.3708])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([-0.3683])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.0367])\n",
      "tensor(0.2353, grad_fn=<SelectBackward0>) tensor(1.) 3 [6] tensor([0.4570])\n",
      "10\n",
      "[(0.34283721446990967, 0.0649472177028656), (0.44175392389297485, 0.05704387649893761), (-2.5231077671051025, 0.06568116694688797), (-0.24345412850379944, 0.031545497477054596), (-0.5346535444259644, 0.3019203543663025), (-0.13385014235973358, 0.04612354561686516), (0.3707500994205475, 0.11682595312595367), (-0.3683021664619446, 0.03065694496035576), (0.0366738997399807, 0.097863107919693), (0.4570285975933075, 0.048775218427181244)]\n",
      "-0.3683021664619446\n",
      "reset\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.6840])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.8269])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.3786])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([0.5375])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.1420])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([2.1083])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-2.3152])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.0857])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-2.3534])\n",
      "tensor(-0.1613, grad_fn=<SelectBackward0>) tensor(1.) 5 [3] tensor([-0.5231])\n",
      "10\n",
      "[(0.6840165257453918, 0.05925498902797699), (-0.826889157295227, 0.027357103303074837), (-0.3786192238330841, 0.07894724607467651), (0.5374683737754822, 0.1235719621181488), (-0.14198802411556244, 0.02106366865336895), (2.108342170715332, 0.15453384816646576), (-2.3151893615722656, 0.008173732087016106), (-0.08569630980491638, 0.04014907777309418), (-2.3533895015716553, 0.04102648049592972), (-0.5231193900108337, 0.07169768214225769)]\n",
      "-2.3151893615722656\n",
      "reset\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.4303])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-3.6502])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.8138])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-1.3466])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.2331])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.2924])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([1.7610])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.4180])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([-0.4843])\n",
      "tensor(-0.2813, grad_fn=<SelectBackward0>) tensor(1.) 2 [0, 4] tensor([0.2235])\n",
      "10\n",
      "[(0.43033137917518616, 0.02492567151784897), (-3.6501715183258057, 0.04385045915842056), (-0.8138068914413452, 0.19352199137210846), (-1.3465555906295776, 0.015566745772957802), (1.2331393957138062, 0.29367321729660034), (-0.2923508882522583, 0.04280756786465645), (1.760961651802063, 0.094919852912426), (0.41804826259613037, 0.0847688838839531), (-0.4842628240585327, 0.018125995993614197), (0.22351381182670593, 0.06627212464809418)]\n",
      "-1.3465555906295776\n",
      "reset\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([-1.0496])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([-0.8133])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([0.4686])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([0.9839])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([0.3681])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([-0.8872])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([-1.6083])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([1.1427])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([1.2272])\n",
      "tensor(0.1502, grad_fn=<SelectBackward0>) tensor(1.) 2 [3, 6] tensor([0.6787])\n",
      "10\n",
      "[(-1.0495702028274536, 0.05331536382436752), (-0.8132961988449097, 0.03306357562541962), (0.46862471103668213, 0.035108838230371475), (0.9838958382606506, 0.08546132594347), (0.36812785267829895, 0.016031255945563316), (-0.8872007727622986, 0.020328938961029053), (-1.6082592010498047, 0.16821978986263275), (1.142733097076416, 0.10374093055725098), (1.2271778583526611, 0.03481171280145645), (0.6786726713180542, 0.037463679909706116)]\n",
      "0.36812785267829895\n",
      "reset\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([0.7785])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-0.3261])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-0.1320])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([0.7749])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-1.7430])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([1.4668])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-1.2797])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([1.1248])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-1.5090])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-0.0736])\n",
      "10\n",
      "[(0.7784567475318909, 0.10937938094139099), (-0.3261393904685974, 0.017460525035858154), (-0.13199062645435333, 0.01965075172483921), (0.7749419808387756, 0.06279680877923965), (-1.743006944656372, 0.02645973116159439), (1.466805338859558, 0.023545296862721443), (-1.2797056436538696, 0.15980315208435059), (1.1247684955596924, 0.0536813959479332), (-1.5090258121490479, 0.025727568194270134), (-0.07363231480121613, 0.07855018228292465)]\n",
      "-0.3261393904685974\n",
      "reset\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.8583])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.9546])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([1.3166])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.6822])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.3957])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.2339])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-1.4941])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([-0.1988])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.6258])\n",
      "tensor(0.0497, grad_fn=<SelectBackward0>) tensor(1.) 3 [5] tensor([0.0892])\n",
      "10\n",
      "[(0.8583033680915833, 0.06324034184217453), (-0.9546225070953369, 0.04051423445343971), (1.3165504932403564, 0.016126463189721107), (0.6822101473808289, 0.04680301249027252), (0.39568838477134705, 0.02308851107954979), (0.23386098444461823, 0.014976547099649906), (-1.4941110610961914, 0.020184041932225227), (-0.19882996380329132, 0.05791871249675751), (0.6258248686790466, 0.07216502726078033), (0.08915209025144577, 0.05648328363895416)]\n",
      "0.23386098444461823\n",
      "reset\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.0650])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.7590])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.7077])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.9807])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.7073])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([1.6267])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.1191])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.1840])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([-0.0082])\n",
      "tensor(0.3482, grad_fn=<SelectBackward0>) tensor(1.) 2 [4, 5] tensor([0.1358])\n",
      "10\n",
      "[(-0.06500296294689178, 0.0668322816491127), (0.7589528560638428, 0.019667483866214752), (0.7077407836914062, 0.019502218812704086), (0.9806820154190063, 0.14412158727645874), (-0.7073454856872559, 0.06572241336107254), (1.6267178058624268, 0.014453502371907234), (-0.11909270286560059, 0.036477230489254), (0.18396367132663727, 0.04105678200721741), (-0.008159727789461613, 0.05169246345758438), (0.13578517735004425, 0.022328322753310204)]\n",
      "1.6267178058624268\n",
      "reset\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.9955])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([2.0271])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.0043])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.0042])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.2064])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.8565])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.8487])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.0014])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([0.7909])\n",
      "tensor(0.0987, grad_fn=<SelectBackward0>) tensor(1.) 3 [3] tensor([-0.6887])\n",
      "10\n",
      "[(-0.9954774379730225, 0.06776260584592819), (2.0270836353302, 0.057694368064403534), (-0.004298996180295944, 0.07470353692770004), (0.00415651872754097, 0.12413763999938965), (0.20644055306911469, 0.02592487260699272), (-0.8565324544906616, 0.008391214534640312), (-0.848728597164154, 0.06189081817865372), (0.0013691476779058576, 0.11166638880968094), (0.790898323059082, 0.0787036269903183), (-0.6886633038520813, 0.009835963137447834)]\n",
      "-0.8565324544906616\n",
      "reset\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.9566])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.4266])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.9184])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.4815])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.0388])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.4399])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([1.2782])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([2.0895])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([-0.4878])\n",
      "tensor(0.3010, grad_fn=<SelectBackward0>) tensor(1.) 5 [0] tensor([0.3898])\n",
      "10\n",
      "[(-0.9565961360931396, 0.078431636095047), (1.4265925884246826, 0.006149863824248314), (-0.9184128046035767, 0.11672884970903397), (1.4815342426300049, 0.018169710412621498), (0.03875041753053665, 0.08723771572113037), (1.4399187564849854, 0.026105523109436035), (1.2781609296798706, 0.06534954160451889), (2.0894994735717773, 0.07616879791021347), (-0.4878268241882324, 0.03217749670147896), (0.3897610604763031, 0.015301587991416454)]\n",
      "1.4265925884246826\n",
      "reset\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.9897])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.7534])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([1.3447])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-1.0615])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-0.0213])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-0.1929])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-1.3153])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.3063])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.7704])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-1.5543])\n",
      "10\n",
      "[(0.9897232055664062, 0.023923180997371674), (0.7533823251724243, 0.0009923516772687435), (1.3446754217147827, 0.023840487003326416), (-1.061486840248108, 0.10750424861907959), (-0.02129966951906681, 0.18090608716011047), (-0.19294975697994232, 0.038063012063503265), (-1.3153194189071655, 0.04775115102529526), (0.30631163716316223, 0.044177111238241196), (0.7704177498817444, 0.11779634654521942), (-1.5542842149734497, 0.005277769174426794)]\n",
      "0.7533823251724243\n",
      "reset\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.4291])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.8104])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.9079])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.7172])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.2832])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([-1.4697])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([2.0622])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.2497])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.7670])\n",
      "tensor(-0.0620, grad_fn=<SelectBackward0>) tensor(1.) 5 [1] tensor([0.9026])\n",
      "10\n",
      "[(0.42908385396003723, 0.15107664465904236), (0.8103793263435364, 0.012054545804858208), (0.9078667163848877, 0.05298900604248047), (0.7172328233718872, 0.18221087753772736), (0.28322964906692505, 0.03175467252731323), (-1.4697445631027222, 0.01740877516567707), (2.062211036682129, 0.07879077643156052), (0.24968256056308746, 0.06355856359004974), (0.7669878602027893, 0.030200771987438202), (0.9025811553001404, 0.06282909959554672)]\n",
      "0.8103793263435364\n",
      "reset\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.0634])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.0799])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.1768])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.9418])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.1912])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.9775])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-0.3483])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([-1.2028])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.6745])\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(1.) 1 [2] tensor([0.3568])\n",
      "10\n",
      "[(0.06343246251344681, 0.010871155187487602), (0.07993949204683304, 0.018837856128811836), (-1.1767628192901611, 0.020952388644218445), (-0.9418426752090454, 0.09156498312950134), (0.19119825959205627, 0.13908709585666656), (-1.9774748086929321, 0.012100464664399624), (-0.3483389616012573, 0.04073943942785263), (-1.202845573425293, 0.012484212405979633), (0.6745340824127197, 0.03421619161963463), (0.3567689061164856, 0.11477521806955338)]\n",
      "0.06343246251344681\n",
      "reset\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([2.2610])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([1.3294])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.8328])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([1.1042])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-2.7393])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-0.4031])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.7659])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([0.1973])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-1.2276])\n",
      "tensor(-0.2211, grad_fn=<SelectBackward0>) tensor(1.) 2 [2, 1] tensor([-1.6161])\n",
      "10\n",
      "[(2.2610418796539307, 0.01720835641026497), (1.3294219970703125, 0.6771573424339294), (0.832830011844635, 0.08300861716270447), (1.104245901107788, 0.09823323041200638), (-2.739332914352417, 0.015232857316732407), (-0.4030560553073883, 0.09662394225597382), (0.7659258842468262, 0.016668418422341347), (0.19731487333774567, 0.01589682511985302), (-1.2275570631027222, 0.09551535546779633), (-1.616092562675476, 0.04112091287970543)]\n",
      "-2.739332914352417\n",
      "reset\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([-0.5821])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([0.5015])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([2.1607])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([-0.6359])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([0.0159])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([0.3134])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([-0.6177])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([-0.4464])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([-1.3575])\n",
      "tensor(-0.0202, grad_fn=<SelectBackward0>) tensor(1.) 4 [3, 4] tensor([-1.4490])\n",
      "10\n",
      "[(-0.5820589065551758, 0.018839364871382713), (0.5014796257019043, 0.039402224123477936), (2.1606976985931396, 0.01830601692199707), (-0.6359099745750427, 0.03388714790344238), (0.01594991236925125, 0.02528342232108116), (0.31337183713912964, 0.017384735867381096), (-0.6177129149436951, 0.02197817899286747), (-0.44639840722084045, 0.07487490028142929), (-1.3574835062026978, 0.04248272627592087), (-1.4490245580673218, 0.015198742970824242)]\n",
      "-1.4490245580673218\n",
      "reset\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([1.0332])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-0.2371])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-1.4048])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([0.0135])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-0.7455])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([1.0302])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([0.1069])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-1.2753])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-1.8155])\n",
      "tensor(-0.2704, grad_fn=<SelectBackward0>) tensor(1.) 3 [0] tensor([-0.1089])\n",
      "10\n",
      "[(1.0331676006317139, 0.13411037623882294), (-0.23712092638015747, 0.025001706555485725), (-1.4048452377319336, 0.5194370746612549), (0.013544589281082153, 0.12862220406532288), (-0.7455459833145142, 0.03129307180643082), (1.0302432775497437, 0.0307395551353693), (0.10685264319181442, 0.03913474828004837), (-1.2753188610076904, 0.010682683438062668), (-1.8155336380004883, 0.09072323143482208), (-0.10887379944324493, 0.038017865270376205)]\n",
      "-1.2753188610076904\n",
      "reset\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.8705])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.9656])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.1200])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.4616])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([0.9355])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([2.2375])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.5008])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.3567])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([-0.8936])\n",
      "tensor(0.2907, grad_fn=<SelectBackward0>) tensor(1.) 3 [2] tensor([1.5206])\n",
      "10\n",
      "[(0.8704712390899658, 0.032265737652778625), (-0.9656490683555603, 0.09659707546234131), (-0.11998506635427475, 0.16090479493141174), (1.4615821838378906, 0.02076851576566696), (0.9355171322822571, 0.013134639710187912), (2.237473249435425, 0.02145075611770153), (-0.5008236765861511, 0.03850647434592247), (-0.3566906750202179, 0.024356793612241745), (-0.8935517072677612, 0.019843008369207382), (1.5206495523452759, 0.4351222515106201)]\n",
      "0.9355171322822571\n",
      "reset\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.6441])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([1.5107])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([2.4976])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([1.4133])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([-0.3126])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.1247])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([0.7414])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([-0.1853])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([1.4563])\n",
      "tensor(0.3101, grad_fn=<SelectBackward0>) tensor(1.) 4 [2, 3] tensor([2.2758])\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "#samples = n\n",
    "samples = input_data.shape[0]\n",
    "#print(samples)\n",
    "num_epochs = 1\n",
    "\n",
    "lab = Lab(mymodel,num_epochs,samples)\n",
    "data = list(zip(input_data, output_data))\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    sample = 0\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    shuffled_inputs, shuffled_outputs = zip(*data)\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    for inputs, targets in zip(shuffled_inputs, shuffled_outputs):\n",
    "        \n",
    "        inputs = inputs.unsqueeze(0)  \n",
    "        targets = targets.unsqueeze(0)\n",
    "    \n",
    "        output = mymodel(inputs)\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        \n",
    "        optimizer.step(loss)\n",
    "        lab.record(mymodel,epoch,samples,sample)\n",
    "        #print or store loss if you wanna\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        \n",
    "        sample += 1\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6381e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.758879\n",
      "8.257727\n",
      "4.969883\n",
      "_______\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this will only work if the networks have the same architecture\n",
    "test_list = list(zip([row for row in neural_network.model.parameters() if len(row.shape) > 1],\n",
    "                     [row for row in mymodel.parameters() if len(row.shape) > 1]))\n",
    "\n",
    "for i in test_list:\n",
    "    #this first line will print out the row similarity matrix.\n",
    "    #print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[0])\n",
    "    print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[1])\n",
    "print('_______')  \n",
    "# VALIDATION\n",
    "iterations = 1000\n",
    "val_samples = 10\n",
    "m = 0.0\n",
    "std = 1.0\n",
    "\n",
    "val_list = []\n",
    "for _ in range(iterations):\n",
    "    val_inputs = torch.from_numpy(np.random.normal(m, std, (val_samples,layer_sizes[0])).astype(np.float32))\n",
    "    val_outputs = neural_network.model(val_inputs)\n",
    "    this_val_acc = calculate_validation_loss(mymodel, val_inputs, val_outputs, criterion)\n",
    "    val_list.append(this_val_acc)\n",
    "    \n",
    "val_histogram(val_list, bins=20, title=\"val_hist\", xlabel=\"Values\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f3c017f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAFNCAYAAABR3QEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiIUlEQVR4nO3deZxlZX3n8c93utmkRUCWhoYWNI2AG5oSicYVSWiMNhoTMS5onOmYiFt0hOAYNGYYyBgNZjRMB1EcDUjUDGBoCaLijjRu7IsYpeluVpFFZJHf/HEPsayprr7dde891D2f9+tVrzrnOU+d8yt4XhTf+zznnFQVkiRJkqTx95/aLkCSJEmSNBoGQEmSJEnqCAOgJEmSJHWEAVCSJEmSOsIAKEmSJEkdYQCUJEmSpI4wAEqS9BCW5JlJruyz73OSrB52TZKkucsAKEnqjCSV5DcequebTlV9taoeO4hzJflYkr8exLkkSXOTAVCSJEmSOsIAKEmac5Lsk+TLSW5LcmmSFzXtX07ynyf1e02SrzXbX2mav5/kziQve3DJZJKjk9yc5N+TvGLSz2/U+abUuGWSu5Ps0Oz/tyT3J9mm2f/rJH/XbG+R5H1JfpLkhiQnJtmqOfZryzqTPCXJd5PckeSfk3xq6qxekrcluTHJ2iSvbdqWA68A3tHUe9Ym/wuQJM1ZBkBJ0pySZDPgLODfgJ2ANwKfTDLjMsmqelaz+aSqWlBVn2r2FwI7AIuAw4EVGzrXBs734PFfABcCz26angX8GHjGpP3zm+3jgb2A/YDfaGr5y6nXTLI58C/Ax4DtgVOBF0/pthB4RHOO1wEfSrJdVa0APgn8TVPvCzf0O0qSxo8BUJI01xwALACOq6p7q+qLwOeAl8/inO+qqnuq6nzgX4E/HECd0At4z04yH3gi8MFmf0vgqcBXkwT4L8Bbq+rWqroDOBY4bJrzHQDMBz5YVfdV1WeBb0/pcx/wV83xs4E7gYHcQyhJmvvmt12AJEkbaVfguqp6YFLbj+nNeG2Kn1bVXVPOteumFjfF+cD7gacAFwPnAh+hF+Suqaqbk+wEPAy4qJcFAQgwb5rz7QpcX1U1qe26KX1uqar7J+3/nF5gliTJGUBJ0pyzBtg9yeS/YYuB64G76IWpBy3s43zbJdl6yrnWNNubcr7JvkFv9u3FwPlVdVlz/hfwq+WfNwN3A4+rqm2br0dU1XShbS2wKJOSIrD7RtRTG+4iSRpnBkBJ0lxzAb1g9o4kmyV5DvBC4DTge8BLkjyseT3D66b87A3Ao6c553uSbJ7kmcDvAf/ctG/q+QCoqp8DFwFv4FeB7xvAnzy438xk/iPwgWY2kCSLkvzuNKf8JvBL4Igk85MsA/Zf3/WnMWO9kqTxZwCUJM0pVXUv8CJgKb3Zsw8Dr66qK4APAPfSCzqn0HvoyWTvBk5pnh764H1+64Cf0pv1+yTw+uZcbOz5kixunrC5eFKf84HN+NW9eucDDwe+MqnPkcA1wLeS3A58gWnu22t+95fQC6K3Aa+kd//jPdP9s5rGR4B9m3r/b58/I0kaI/n12wgkSeqOZvbwE1W1W8ulbLIkFwAnVtVH265FkvTQ5wygJElzSJJnJ1nYLAE9nN7TRT/fdl2SpLnBp4BKkjS3PBY4nd6TPX8IvLSq1rZbkiRprnAJqCRJkiR1hEtAJUmSJKkjDICSJEmS1BFjeQ/gDjvsUHvssUfbZUiSJElSKy666KKbq2rHqe1jGQD32GMPVq1a1XYZkiRJktSKJD+ert0loJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR1hAJQkSZKkjjAASpIkSVJHGAAlSZIkqSMMgJIkSZLUEfPbLqAr1h17LPdcfkXbZUiSJEkaoC322ZuFRx/ddhl9cwZQkiRJkjrCGcARmUufCkiSJEkaT84ASpIkSVJHGAAlSZIkqSMMgJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR3hewBH5KPvPprb161puwxJkiRJA7TNwl157buPbbuMvjkDKEmSJEkd4QzgiMylTwUkSZIkjSdnACVJkiSpI1qdAUxyMHACMA84qaqOm3J8GfBe4AHgfuAtVfW1kRc6ALed9UPuXXNX22VIkiRJGqDNd92abV/4mLbL6FtrATDJPOBDwEHAauDCJGdW1WWTup0HnFlVleSJwOnA3qOvVpIkSZLmvjZnAPcHrqmqawGSnAYsA/4jAFbVnZP6bw3USCscoLn0qYAkSZKk8dTmPYCLgOsm7a9u2n5NkhcnuQL4V+CPR1SbJEmSJI2dNgNgpmn7/2b4qupfqmpv4FB69wNOf7JkeZJVSVbddNNNg6tSkiRJksZEmwFwNbD7pP3dgPW+Kb2qvgI8JskO6zm+oqomqmpixx13HGylkiRJkjQG2gyAFwJLkuyZZHPgMODMyR2S/EaSNNtPATYHbhl5pZIkSZI0Blp7CExV3Z/kCOAceq+BOLmqLk3y+ub4icDvA69Och9wN/CyqpqzD4KRJEmSpDZlHPPUxMRErVq1qu0yJEmSJKkVSS6qqomp7W0uAZUkSZIkjZABUJIkSZI6wgAoSZIkSR1hAJQkSZKkjjAASpIkSVJHGAAlSZIkqSMMgJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR1hAJQkSZKkjjAASpIkSVJHzG+7gK5YuXIl69ata7sMSZIkSQO0cOFCli5d2nYZfXMGUJIkSZI6whnAEZlLnwpIkiRJGk/OAEqSJElSRxgAJUmSJKkjDICSJEmS1BEGQEmSJEnqCAOgJEmSJHWEAVCSJEmSOsIAKEmSJEkdYQCUJEmSpI4wAEqSJElSR8xv8+JJDgZOAOYBJ1XVcVOOvwI4stm9E/jTqvr+aKscjHXHHss9l1/RdhmSJEmSBmiLffZm4dFHt11G31oLgEnmAR8CDgJWAxcmObOqLpvU7UfAs6vqp0mWAiuAp42+2tlb+6hv8fNHXdd2GZIkSZIG6GHcxsK2i9gIbc4A7g9cU1XXAiQ5DVgG/EcArKpvTOr/LWC3kVY4QFs/9ak8cOeCtsuQJEmSNEBbL9in7RI2SpsBcBEweUpsNTPP7r0OWDnUioZor73e1XYJkiRJkjquzQCYadpq2o7Jc+kFwN9e78mS5cBygMWLFw+iPkmSJEkaK20GwNXA7pP2dwPWTO2U5InAScDSqrplfSerqhX07hFkYmJi2iDZpvcd9y3uufkXbZchSZIkaYC22GFL3n7UAW2X0bc2XwNxIbAkyZ5JNgcOA86c3CHJYuCzwKuq6qoWapQkSZKksdHaDGBV3Z/kCOAceq+BOLmqLk3y+ub4icBfAo8EPpwE4P6qmmir5tmYS58KSJIkSRpPqXrIrZactYmJiVq1alXbZUiSJElSK5JcNN3kWZtLQCVJkiRJI2QAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjpiftsFdMXx3z6eK269ou0yJEmSJA3Q3tvvzZH7H9l2GX1zBlCSJEmSOsIZwBGZS58KSJIkSRpPzgBKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6oj5bRfQFV89/Spuvu7OtsuQJEmSNEA77L6AZ/7hXm2X0TdnACVJkiSpI1qdAUxyMHACMA84qaqOm3J8b+CjwFOAd1bV+0Zf5WDMpU8FJEmSJI2n1gJgknnAh4CDgNXAhUnOrKrLJnW7FXgTcOjoK5QkSZKk8dLmEtD9gWuq6tqquhc4DVg2uUNV3VhVFwL3tVGgJEmSJI2TNgPgIuC6SfurmzZJkiRJ0hC0GQAzTVtt8smS5UlWJVl10003zaIsSZIkSRpPbQbA1cDuk/Z3A9Zs6smqakVVTVTVxI477jjr4iRJkiRp3LT5FNALgSVJ9gSuBw4D/qjFeobqSx9bwY0/vrbtMiRJkiQN0E6PejTPfc3ytsvoW2sBsKruT3IEcA6910CcXFWXJnl9c/zEJAuBVcA2wANJ3gLsW1W3t1W3JEmSJM1Vqdrk2+4esiYmJmrVqlVtlyFJkiRJrUhyUVVNTG1v9UXwnbLyKFh3cdtVSJIkSRqkhU+Apce1XUXf2nwIjCRJkiRphPqeAUyydVXdNcxixtoc+lRAkiRJ0nja4AxgkqcnuQy4vNl/UpIPD70ySZIkSdJA9bME9APA7wK3AFTV94FnDbMoSZIkSdLg9XUPYFVdN6Xpl0OoRZIkSZI0RP3cA3hdkqcDlWRz4E00y0ElSZIkSXNHPzOArwfeACwCVgP7NfuSJEmSpDlkgzOAVXUz8IoR1CJJkiRJGqINBsAkHwVqantV/fFQKpIkSZIkDUU/9wB+btL2lsCLgTXDKUeSJEmSNCz9LAH9zOT9JKcCXxhaRWPqXVev5pI77267DEmSJEkD9PgFW/HeJbu1XUbf+noNxBRLgMWDLkSSJEmSNFz93AN4B717ANN8XwccOeS6xs5c+lRAkiRJ0njqZwnow0dRiCRJkiRpuNYbAJM8ZaYfrKrvDL4cSZIkSdKwzDQD+LczHCvgeQOuRZIkSZI0ROsNgFX13FEWIkmSJEkarn7eA0iSxwP70nsPIABV9fFhFSVJkiRJGrx+ngJ6DPAcegHwbGAp8DXAAChJkiRJc0g/7wF8KXAgsK6qXgs8CdhiqFVJkiRJkgaunwB4d1U9ANyfZBvgRuDRwy1LkiRJkjRo/dwDuCrJtsA/AhcBdwLfHmZRkiRJkqTBm+k9gP8L+Keq+rOm6cQknwe2qaofjKQ6SZIkSdLAzDQDeDXwt0l2AT4FnFpV3xtJVZIkSZKkgZvpPYAnACckeRRwGPDRJFsCpwKnVdVVs714koOBE4B5wElVddyU42mOHwL8HHhNVX1nttdtw3vOupTL1tzedhmSJEmSBmjfXbfhmBc+ru0y+rbBh8BU1Y+r6viqejLwR8CLgctne+Ek84AP0XutxL7Ay5PsO6XbUmBJ87Uc+IfZXleSJEmSuqqf9wBuBhxMbxbwQOB84D0DuPb+wDVVdW1zndOAZcBlk/osAz5eVQV8K8m2SXapqrUDuP5IzaVPBSRJkiSNp5keAnMQ8HLgBfSe+nkasLyq7hrQtRcB103aXw08rY8+i4A5FwBv+/uPc++t89ouQ5IkSdIAbb79L9n2ja9uu4y+zTQDeDTwT8Dbq+rWIVw707TVJvTpdUyW01smyuLFi2dX2RCsvf1utrp3y7bLkCRJkjRAt9z+C7Ztu4iNMNNDYJ475GuvBnaftL8bsGYT+gBQVSuAFQATExPThsQ2nf7E3/YhMJIkSdKY2XfXbTim7SI2Qj8vgh+WC4ElSfYErqd3j+EfTelzJnBEc3/g04CfzcX7/8B7ACVJkiS1r7UAWFX3JzkCOIfeayBOrqpLk7y+OX4icDa9V0BcQ+81EK9tq15JkiRJmuv6eQro8VV15IbaNkVVnU0v5E1uO3HSdgFvmO11JEmSJEl9vAcQOGiatqWDLkSSJEmSNFwzvQbiT4E/Ax6d5AeTDj0c+PqwC5MkSZIkDdZMS0D/CVgJ/A/gqEntdwzptRCSJEmSpCGa6TUQPwN+Brw8yTxg56b/giQLquonI6pRkiRJkjQA/TwE5gjg3cANwANNcwFPHF5ZkiRJkqRB6+c1EG8BHltVtwy5FkmSJEnSEPXzFNDr6C0FlSRJkiTNYTM9BfTPm81rgS8n+VfgngePV9X7h1ybJEmSJGmAZloC+vDm+0+ar82bL0mSJEnSHDTTU0DfM8pCJEmSJEnD1c9TQM+i99TPyX4GrAL+d1X9YhiFjZuvnn4VN193Z9tlSJIkSRqgHXZfwDP/cK+2y+hbP08BvRbYETi12X8ZvVdC7AX8I/Cq4ZQ2Xv753pP50SN+2HYZkiRJkgZoz3sfwzM5ru0y+tZPAHxyVT1r0v5ZSb5SVc9KcumwChs3i/bajjtuXdB2GZIkSZIGaNH227VdwkbpJwDumGRxVf0EIMliYIfm2L1Dq2zM7H/Zduzx453bLkOSJEnSAO30qO1g/7ar6F8/AfBtwNeS/BAIsCfwZ0m2Bk4ZZnGSJEmSpMFJ1dTnu0zTKdkC2JteALziof7gl4mJiVq1alXbZUiSJElSK5JcVFUTU9tnehH886rqi0leMuXQo5NQVZ8deJVj7F1Xr+aSO+9uuwxJkiRJA/T4BVvx3iW7tV1G32ZaAvps4IvAC6c5VoABUJIkSZLmkJleBH9M8/21oytnfM2lTwUkSZIkjaf/tKEOSXZO8pEkK5v9fZO8bvilSZIkSZIGaYMBEPgYcA6wa7N/FfCWIdUjSZIkSRqSfgLgDlV1OvAAQFXdD/xyqFVJkiRJkgaunwB4V5JH0nvwC0kOAH421KokSZIkSQPX74vgzwQek+TrwI7AS4dalSRJkiRp4GZ6D+BbgK8D36X3SojH0nsR/JVVdd9IqpMkSZIkDcxMS0B3A04AbgS+ALwCeBTw8NleNMn2Sc5NcnXzfbv19Ds5yY1JLpntNSVJkiSp69YbAKvq7VX1dGAhcDRwK/DHwCVJLpvldY8CzquqJcB5zf50PgYcPMtrSZIkSZLo7yEwWwHbAI9ovtYAF8zyusuAU5rtU4BDp+tUVV+hFzwlSZIkSbM00z2AK4DHAXfQC3zfAN5fVT8dwHV3rqq1AFW1NslOAzinJEmSJGkGMz0FdDGwBXA1cD2wGrit3xMn+QK95aNTvXMj6utbkuXAcoDFixcP4xKSJEmSNKetNwBW1cFJQm8W8On0Xgfx+CS3At+sqmNmOnFVPX99x5LckGSXZvZvF3oPmpmVqloBrACYmJio2Z5PkiRJksbNjPcAVs8lwNnASnqvhXgM8OZZXvdM4PBm+3DgjFmeT5IkSZK0ATPdA/gmejN/zwDuoxf+vgmcDFw8y+seB5ye5HXAT4A/aK65K3BSVR3S7J8KPAfYIclq4Jiq+sgsr92KlStXsm7durbLkCRJkjRACxcuZOnSpW2X0beZ7gHcA/g08NYHH9gyKFV1C3DgNO1rgEMm7b98kNeVJEmSpC6b6R7APx9lIeNuLn0qIEmSJGk8zTQDqAG67awfcu+au9ouQ5IkSdIAbb7r1mz7wse0XUbf+nkRvCRJkiRpDDgDOCJz6VMBSZIkSePJGUBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOaCUAJtk+yblJrm6+bzdNn92TfCnJ5UkuTfLmNmqVJEmSpHHR1gzgUcB5VbUEOK/Zn+p+4G1VtQ9wAPCGJPuOsEZJkiRJGittBcBlwCnN9inAoVM7VNXaqvpOs30HcDmwaFQFSpIkSdK4aSsA7lxVa6EX9ICdZuqcZA/gycAFwy9NkiRJksbT/GGdOMkXgIXTHHrnRp5nAfAZ4C1VdfsM/ZYDywEWL168MZeQJEmSpE4YWgCsquev71iSG5LsUlVrk+wC3LiefpvRC3+frKrPbuB6K4AVABMTE7XplUuSJEnSeGprCeiZwOHN9uHAGVM7JAnwEeDyqnr/CGuTJEmSpLHUVgA8DjgoydXAQc0+SXZNcnbT5xnAq4DnJfle83VIO+VKkiRJ0tw3tCWgM6mqW4ADp2lfAxzSbH8NyIhLkyRJkqSx1dYMoCRJkiRpxAyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpI1oJgEm2T3Jukqub79tN02fLJN9O8v0klyZ5Txu1SpIkSdK4aGsG8CjgvKpaApzX7E91D/C8qnoSsB9wcJIDRleiJEmSJI2XtgLgMuCUZvsU4NCpHarnzmZ3s+arRlKdJEmSJI2htgLgzlW1FqD5vtN0nZLMS/I94Ebg3Kq6YHQlSpIkSdJ4mT+sEyf5ArBwmkPv7PccVfVLYL8k2wL/kuTxVXXJeq63HFgOsHjx4o0vWJIkSZLG3NACYFU9f33HktyQZJeqWptkF3ozfDOd67YkXwYOBqYNgFW1AlgBMDEx4VJRSZIkSZqirSWgZwKHN9uHA2dM7ZBkx2bmjyRbAc8HrhhVgZIkSZI0btoKgMcBByW5Gjio2SfJrknObvrsAnwpyQ+AC+ndA/i5VqqVJEmSpDEwtCWgM6mqW4ADp2lfAxzSbP8AePKIS5MkSZKksdXWDKAkSZIkacQMgJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6opWngHbRumOP5Z7LfY2hJEmSNE622GdvFh59dNtl9M0ZQEmSJEnqCGcAR2QufSogSZIkaTw5AyhJkiRJHeEM4IhcddV7uePOy9suQ5IkSdIAPXzBPuy117vaLqNvzgBKkiRJUkc4Azgic+lTAUmSJEnjyRlASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR3hQ2BG5PhvH88Vt17RdhmSJEmSBmjv7ffmyP2PbLuMvjkDKEmSJEkd4QzgiMylTwUkSZIkjSdnACVJkiSpI5wBHJWVR8G6i9uuQpIkSdIgLXwCLD2u7Sr65gygJEmSJHWEM4CjMoc+FZAkSZI0npwBlCRJkqSOMABKkiRJUke0EgCTbJ/k3CRXN9+3m6HvvCTfTfK5UdYoSZIkSeOmrRnAo4DzqmoJcF6zvz5vBi4fSVWSJEmSNMbaCoDLgFOa7VOAQ6frlGQ34AXASaMpS5IkSZLGV1sBcOeqWgvQfN9pPf3+DngH8MCI6pIkSZKksTW010Ak+QKwcJpD7+zz538PuLGqLkrynD76LweWAyxevLj/QiVJkiSpI4YWAKvq+es7luSGJLtU1dokuwA3TtPtGcCLkhwCbAlsk+QTVfXK9VxvBbACYGJiomb/G0iSJEnSeGlrCeiZwOHN9uHAGVM7VNVfVNVuVbUHcBjwxfWFP0mSJEnShrUVAI8DDkpyNXBQs0+SXZOc3VJNkiRJkjTWhrYEdCZVdQtw4DTta4BDpmn/MvDloRcmSZIkSWMsVeN3u1ySm4Aft13HNHYAbm67CI0tx5eGyfGlYXOMaZgcXxqmh+r4elRV7Ti1cSwD4ENVklVVNdF2HRpPji8Nk+NLw+YY0zA5vjRMc218tXUPoCRJkiRpxAyAkiRJktQRBsDRWtF2ARprji8Nk+NLw+YY0zA5vjRMc2p8eQ+gJEmSJHWEM4CSJEmS1BEGwBFIcnCSK5Nck+SotuvR3JNk9yRfSnJ5kkuTvLlp3z7JuUmubr5vN+ln/qIZc1cm+d32qtdckWReku8m+Vyz7/jSwCTZNsmnk1zR/LfstxxjGpQkb23+Pl6S5NQkWzq+NBtJTk5yY5JLJrVt9JhK8ptJLm6OfTBJRv27TGUAHLIk84APAUuBfYGXJ9m33ao0B90PvK2q9gEOAN7QjKOjgPOqaglwXrNPc+ww4HHAwcCHm7EozeTNwOWT9h1fGqQTgM9X1d7Ak+iNNceYZi3JIuBNwERVPR6YR2/8OL40Gx+jNz4m25Qx9Q/AcmBJ8zX1nCNnABy+/YFrquraqroXOA1Y1nJNmmOqam1VfafZvoPe/zgtojeWTmm6nQIc2mwvA06rqnuq6kfANfTGojStJLsBLwBOmtTs+NJAJNkGeBbwEYCqureqbsMxpsGZD2yVZD7wMGANji/NQlV9Bbh1SvNGjakkuwDbVNU3q/fglY9P+pnWGACHbxFw3aT91U2btEmS7AE8GbgA2Lmq1kIvJAI7Nd0cd9pYfwe8A3hgUpvjS4PyaOAm4KPNMuOTkmyNY0wDUFXXA+8DfgKsBX5WVf+G40uDt7FjalGzPbW9VQbA4Ztuna+PXtUmSbIA+Azwlqq6faau07Q57jStJL8H3FhVF/X7I9O0Ob40k/nAU4B/qKonA3fRLJ1aD8eY+tbch7UM2BPYFdg6yStn+pFp2hxfmo31jamH5FgzAA7famD3Sfu70VuWIG2UJJvRC3+frKrPNs03NMsLaL7f2LQ77rQxngG8KMm/01um/rwkn8DxpcFZDayuqgua/U/TC4SOMQ3C84EfVdVNVXUf8Fng6Ti+NHgbO6ZWN9tT21tlABy+C4ElSfZMsjm9G0TPbLkmzTHNE6M+AlxeVe+fdOhM4PBm+3DgjEnthyXZIsme9G46/vao6tXcUlV/UVW7VdUe9P4b9cWqeiWOLw1IVa0Drkvy2KbpQOAyHGMajJ8AByR5WPP38kB698o7vjRoGzWmmmWidyQ5oBmbr570M62Z33YB466q7k9yBHAOvadSnVxVl7ZcluaeZwCvAi5O8r2m7WjgOOD0JK+j9wfwDwCq6tIkp9P7H6z7gTdU1S9HXrXmOseXBumNwCebD0OvBV5L74Nox5hmpaouSPJp4Dv0xst3gRXAAhxf2kRJTgWeA+yQZDVwDJv2d/FP6T1RdCtgZfPVqvQeSCNJkiRJGncuAZUkSZKkjjAASpIkSVJHGAAlSZIkqSMMgJIkSZLUEQZASZIkSeoIA6AkqVOSPDLJ95qvdUmub7bvTPLhIVzvsUm+3Fzj8iQrmvb9khwy6OtJkjQT3wMoSeqUqroF2A8gybuBO6vqfUO85AeBD1TVGc01n9C07wdMAGcP8dqSJP0aZwAlSQKSPCfJ55rtdyc5Jcm/Jfn3JC9J8jdJLk7y+SSbNf1+M8n5SS5Kck6SXaY59S7A6gd3quri5mXofwW8rJkZfFmSrZOcnOTCJN9Nsqy5xmuSnNFc98okxwz/n4YkaVwZACVJmt5jgBcAy4BPAF+qqicAdwMvaELg3wMvrarfBE4G/vs05/kA8MUkK5O8Ncm2VXUv8JfAp6pqv6r6FPBO4ItV9VTgucD/TLJ1c479gVfQmzX8gyQTQ/qdJUljziWgkiRNb2VV3ZfkYmAe8Pmm/WJgD+CxwOOBc5PQ9Fk79SRV9dEk5wAH0wuTf5LkSdNc73eAFyV5e7O/JbC42T63WbpKks8Cvw2smvVvKEnqHAOgJEnTuwegqh5Icl9VVdP+AL2/nwEurarf2tCJqmoNvRnCk5NcQi84ThXg96vqyl9rTJ4G1JS+U/clSeqLS0AlSdo0VwI7JvktgCSbJXnc1E5JDp50z+BC4JHA9cAdwMMndT0HeGOa6cQkT5507KAk2yfZCjgU+PoQfh9JUgcYACVJ2gTNfXwvBY5P8n3ge8DTp+n6O8AlTZ9zgP9aVeuALwH7PvgQGOC9wGbAD5pZwvdOOsfXgP/TXOMzVeXyT0nSJsmvVrRIkqSHmiSvASaq6oi2a5EkzX3OAEqSJElSRzgDKEmSJEkd4QygJEmSJHWEAVCSJEmSOsIAKEmSJEkdYQCUJEmSpI4wAEqSJElSRxgAJUmSJKkj/h+nOuLJU/g8MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##x_range = (99998,100000) to view final weights\n",
    "lab.graph(diff=0,graph_together = False, plot_size = (15,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac518f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_line_graph(losses,window_size = 1000, plot_size = (15,5)) #window_size is the moving average window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
