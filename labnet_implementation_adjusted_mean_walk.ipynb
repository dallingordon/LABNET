{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4701eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LABNET import Neuron, Net, Lab, Teacher,compare_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e88d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db84284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_weights(model, perturbation_amount):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            weights = layer.get_weights()\n",
    "            perturbations = [np.random.uniform(-perturbation_amount, perturbation_amount, w.shape) for w in weights]\n",
    "            perturbed_weights = [w + perturbation for w, perturbation in zip(weights, perturbations)]\n",
    "            layer.set_weights(perturbed_weights)\n",
    "\n",
    "# Example usage:\n",
    "# Save the perturbed weights\n",
    "#perturbation_amount = 0.1\n",
    "#perturb_weights(model, perturbation_amount)\n",
    "#save_weights(model, 'perturbed_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894aab1",
   "metadata": {},
   "source": [
    "\n",
    "## Adding a few hyperparameters ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab368e9a",
   "metadata": {},
   "source": [
    "first, instead of storing gradients we store standard deviations.  we will need a default to start.  \n",
    "then there is kappa.  this may move as we go lower, or whatever, but kappa is the number of samples.  \n",
    "then there is a percentage of neurons to sample at each kappa iteration.  min value here should be only one neuron, and the max should be all.  this could be randomly determined maybe?.  \n",
    "so, lets say you are doing the min, one neuron per kappa iteration.  \n",
    "you look up that neurons standard deviation (which i think i use gradients instead)\n",
    "and you sample using the standard deviation for that neuron, and the weight value as the mean.  get kappa losses that each correspond to a sampled weight.  you have kappa loss weight pairs for that neuron.  pick the lowest loss, set the weight to that sampled value, and set the standard deviation to whatever that selected weight is from the previous one.  so, if the sampled value is outside the 1 sd bound, it is going to search a wider area, if it is less, it will search a smaller one.  if it doesn't sample one that is better than the current value, it gets multiplied by some fixed number greater than 1.  so, to get to the GLOBAL minima, those values all go big, and it can search over huge areas and won't find anything smaller.  so you could see how often it selects a better value, that should reduce as more iterations happen.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551dbc7",
   "metadata": {},
   "source": [
    "![Alt text](normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d0323",
   "metadata": {},
   "source": [
    "theory i guess:gradient explosion or collapse is a spectrum.  first, is it normally distributed? i think its distribution is a function of the architecture, the depth and the number of neurons.  depth contribution makes the most sense.  you need all the deep layers to compound to get either issue.  as you get deeper, the risk of catastrophic gradient deviation increases, or, if we think about training lots of neural networks, or just the same neural network multiple times, it likely does that in some distribution.  so, we should either see the earliest layers train first if the gradient explodes, or the latter layers to train first (if vanish or collapse).   however, it looks like it does one or the other and runs into a minima. a decent minima even.  what would that mean.  it means on the loss landscape there may be lots of really decent places for the weights to end up, even if it doesn't match the ideal (controlled generated) weights.  \n",
    "WHAT IF SOME INDIVIDUAL VALUES INSIDE WEIGHT MATRICES (i need a name for not a neuron, but an individual weight inside that tensor)\n",
    "\n",
    "so, look at lots of em, see if there is evidence for that.  \n",
    "\n",
    "then, is there a way to cut the compounding during the backward pass.  what if each layer only takes into account the next weight layer, doesnt' back propagate all the way back.  does that make it so each neuron can pull its weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4402d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_graph(numbers\n",
    "                    ,window_size = 1\n",
    "                    ,plot_size = (10,6)\n",
    "                    ,x_range = (None, None)\n",
    "                    ,y_range = (None, None)\n",
    "                   ):\n",
    "    \n",
    "    if window_size <= 0 or window_size > len(numbers):\n",
    "        raise ValueError(\"Invalid window size\")\n",
    "    \n",
    "    running_sum = sum(numbers[:window_size])\n",
    "    averages = [running_sum / window_size]\n",
    "\n",
    "    for i in range(window_size, len(numbers)):\n",
    "        running_sum += numbers[i] - numbers[i - window_size]\n",
    "        averages.append(running_sum / window_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = range(1, len(averages) + 1)  \n",
    "    y = averages  # y-axis values\n",
    "    plt.figure(figsize=plot_size)\n",
    "    plt.plot(x, y)  # Plotting the line graph\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "\n",
    "    if x_range[0] is not None and x_range[1] is not None:\n",
    "        plt.xlim(x_range[0], x_range[1])\n",
    "    if y_range[0] is not None and y_range[1] is not None:\n",
    "        plt.ylim(y_range[0], y_range[1])\n",
    "    \n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d76df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aebd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = 1000 #number of samples to generate\n",
    "layer_sizes = [8, 7,7,4]  # Inputs: 4, Hidden layers: [8, 8], Outputs: 3\n",
    "neural_network = Teacher(layer_sizes)\n",
    "#initialize_weights_uniform(neural_network,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fc55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.generate_data(\n",
    "    n\n",
    "    ,'normal'\n",
    "    , m =0.0\n",
    "    , std=1.0\n",
    "    , gen_lr = 0.01\n",
    "    , gen_epochs = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f8b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a function of the Teacher obj, i think save all the generate settings then just pass number of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d81bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1848, -0.2762, -0.2811, -0.1622], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model(neural_network.inputs[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ae2e479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_layer.weight',\n",
       "              tensor([[-0.7011,  0.1749, -0.5618, -0.0645,  0.9568,  0.7232,  0.5544,  0.5727],\n",
       "                      [ 0.4512,  0.3648, -0.2851,  0.1132,  0.1501, -0.4473,  0.4789, -0.1069],\n",
       "                      [-0.2345, -0.6458, -0.8370, -0.1082,  0.8196, -0.1282,  0.8603,  0.8294],\n",
       "                      [-0.7586,  0.6262,  0.9121, -0.7624,  0.2323, -0.3913, -0.3772,  0.3668],\n",
       "                      [-0.2219,  0.4003,  0.5354,  0.1302, -0.6351,  0.1912,  0.4466,  0.0811],\n",
       "                      [ 0.8281,  0.8115, -0.7661, -0.6470, -0.3709, -0.1830,  1.0377, -0.0246],\n",
       "                      [ 0.0148, -0.9858,  0.4897,  0.9513,  0.8055, -0.0626, -0.0480,  1.0486]])),\n",
       "             ('input_layer.bias',\n",
       "              tensor([ 0.8510, -0.3999,  0.5978, -0.3366,  0.7421, -0.0765, -0.3042])),\n",
       "             ('hidden_layer_2.weight',\n",
       "              tensor([[-0.0347, -0.2045,  0.2552,  0.0291,  0.1150, -0.5726, -0.8038],\n",
       "                      [-0.3392,  0.5065,  0.2482, -0.3328,  0.1900,  0.0283,  0.0718],\n",
       "                      [-0.3242,  0.2352, -0.9087, -0.5896,  0.2786, -0.6206, -0.2576],\n",
       "                      [-0.9881, -0.9400,  0.6820,  0.2818, -0.5688,  0.5040, -0.9785],\n",
       "                      [-0.5433, -0.3413, -0.7421, -0.2602, -0.2816,  0.2443, -0.0555],\n",
       "                      [-0.8109, -0.0847, -0.9865,  0.1862,  0.0111,  0.2966,  0.4082],\n",
       "                      [ 0.3091,  0.3406, -0.2281, -0.5919, -0.5341, -0.2390, -0.1295]])),\n",
       "             ('hidden_layer_2.bias',\n",
       "              tensor([-0.0093, -1.2141, -0.3319,  0.6164, -0.0803, -0.7296, -0.1347])),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[ 0.4884, -0.1769, -0.4586,  0.0597, -0.4594, -0.0280, -0.6621],\n",
       "                      [ 0.5700, -0.5009, -0.9031,  0.2103,  0.1424,  0.6847, -0.3900],\n",
       "                      [-0.4264, -0.6589, -0.5908, -0.1510, -0.3445,  0.3288, -0.1919],\n",
       "                      [ 0.1115,  0.4867,  0.7007, -0.2063,  0.0872, -0.5009,  0.8755]])),\n",
       "             ('output_layer.bias',\n",
       "              tensor([-0.0231, -0.0897,  0.1101,  0.0019]))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model.state_dict()\n",
    "#torch.save(neural_network.model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b2ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.hidden_1 = nn.Linear(8, 7) ##make these all variables duh\n",
    "        self.hidden_2 = nn.Linear(7,7)\n",
    "        #self.hidden_3 = nn.Linear(7,7)\n",
    "        #self.hidden_4 = nn.Linear(7,7)\n",
    "        #self.hidden_5 = nn.Linear(7,7)\n",
    "        self.output = nn.Linear(7, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden_1(x))\n",
    "        x = self.relu(self.hidden_2(x))\n",
    "        #x = self.relu(self.hidden_3(x))\n",
    "        #x = self.relu(self.hidden_4(x))\n",
    "        #x = self.relu(self.hidden_5(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8807a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (hidden_1): Linear(in_features=8, out_features=7, bias=True)\n",
      "  (hidden_2): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (output): Linear(in_features=7, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mymodel = MyModel()\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221b9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_state_dict_keys_by_order(model, reference_model):\n",
    "    model_keys = list(model.state_dict().keys())\n",
    "    reference_keys = list(reference_model.state_dict().keys())\n",
    "    name_mapping = dict(zip(model_keys, reference_keys))\n",
    "    \n",
    "    new_state_dict = OrderedDict()\n",
    "    for key in model.state_dict():\n",
    "        new_key = name_mapping[key]\n",
    "        new_state_dict[new_key] = model.state_dict()[key]\n",
    "    return new_state_dict\n",
    "\n",
    "def perturb_weights(model, std_dev):\n",
    "    for param in model.parameters():\n",
    "        noise = np.random.normal(loc=0.0, scale=std_dev, size=param.data.shape)\n",
    "        param.data.add_(torch.from_numpy(noise))\n",
    "        \n",
    "def scale_weights(model, scaling_factor):\n",
    "    for param in model.parameters():\n",
    "        param.data.mul_(scaling_factor)\n",
    "        \n",
    "def calculate_validation_loss(model, validation_inputs, validation_outputs, loss_function):\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        #validation_inputs = validation_inputs.to(device)  # Move inputs to the appropriate device (e.g., GPU)\n",
    "        #validation_outputs = validation_outputs.to(device)  # Move targets to the appropriate device\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(validation_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, validation_outputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        average_loss = loss.item()\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    return average_loss\n",
    "\n",
    "def val_histogram(data_list, bins=10, title=\"val_hist\", xlabel=\"Values\", ylabel=\"Frequency\"):\n",
    "\n",
    "    plt.hist(data_list, bins=bins, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663c7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ef270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_this = rename_state_dict_keys_by_order( neural_network.model,mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5cd09b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.load_state_dict(load_this)\n",
    "#mymodel.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4372c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden_1.weight',\n",
       "              tensor([[-0.1620,  0.2905,  0.1362,  0.0204,  0.0602, -0.2522, -0.1890,  0.0824],\n",
       "                      [-0.1361, -0.2442, -0.0421, -0.1759,  0.2034, -0.1630, -0.0360,  0.2479],\n",
       "                      [-0.0280, -0.0840, -0.1826,  0.3035,  0.2811, -0.2750, -0.0148, -0.0139],\n",
       "                      [ 0.1508,  0.0672, -0.0836,  0.1622, -0.3040, -0.2846,  0.1118,  0.1047],\n",
       "                      [ 0.2432, -0.3190,  0.1491,  0.1946, -0.2611,  0.0464, -0.0306, -0.1020],\n",
       "                      [-0.1390, -0.0130, -0.2432, -0.0913,  0.0043,  0.1832, -0.1367,  0.0980],\n",
       "                      [-0.3256,  0.2014,  0.2965, -0.0182, -0.1334, -0.1282, -0.3250,  0.1510]])),\n",
       "             ('hidden_1.bias',\n",
       "              tensor([-0.1230,  0.1391, -0.1961, -0.0717,  0.2475,  0.2173,  0.0715])),\n",
       "             ('hidden_2.weight',\n",
       "              tensor([[ 0.0329, -0.0419, -0.0543, -0.0410, -0.0500,  0.2342,  0.0967],\n",
       "                      [ 0.0430, -0.3642,  0.1563, -0.1130, -0.0839,  0.1652,  0.2420],\n",
       "                      [ 0.1738,  0.2994,  0.1290, -0.1168,  0.1122, -0.0378, -0.3723],\n",
       "                      [ 0.1957,  0.2360,  0.2447,  0.3542,  0.2203, -0.2777,  0.3474],\n",
       "                      [-0.3288,  0.2569,  0.2465,  0.1078, -0.0449,  0.0938,  0.3385],\n",
       "                      [-0.3474, -0.0627, -0.3027,  0.2526,  0.1824, -0.2738,  0.2605],\n",
       "                      [ 0.0353, -0.2823, -0.1121,  0.1521, -0.3247,  0.2563, -0.3124]])),\n",
       "             ('hidden_2.bias',\n",
       "              tensor([-0.0270,  0.0460, -0.1218,  0.1584, -0.1596, -0.3754, -0.1777])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.3767,  0.0815, -0.2354,  0.0534, -0.2098, -0.3617,  0.3427],\n",
       "                      [ 0.0107, -0.2960, -0.1229, -0.3178,  0.3487, -0.1031, -0.1094],\n",
       "                      [-0.1376,  0.2674, -0.3239, -0.3108,  0.1326, -0.1202, -0.0285],\n",
       "                      [ 0.3653,  0.1739, -0.0983, -0.3656, -0.0359,  0.1229,  0.3732]])),\n",
       "             ('output.bias', tensor([ 0.0200, -0.1363,  0.3620, -0.1606]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##STARTING with the right answuers gives some close to zero row_comp:3.5974587e-08,0.0,0.0; 0.0,2.9802322e-08,1.4901161e-08\n",
    "#interesting that you get a zero, and then a close to zero.  \n",
    "#perturb_weights(mymodel, std_dev = 0.005) # converges\n",
    "#perturb_weights(mymodel, std_dev = 0.009) # converges\n",
    "#perturb_weights(mymodel, std_dev = 0.05) doesn't converge\n",
    "#perturb_weights(mymodel, std_dev = 0.01) #converges\n",
    "#perturb_weights(mymodel, std_dev = 0.01) #not converging well, even with lower lr, 0.003. 1t 0.001\n",
    "\n",
    "\n",
    "# scale_weights(mymodel, scaling_factor = 1.1) ## converges, weights cross.  \n",
    "#scale_weights(mymodel, scaling_factor = 1.5) ## good validation, non zero row comapre still..\n",
    "\n",
    "#scale_weights(mymodel, scaling_factor = 2) ## good validation, row compare stays pretty close to the same...\n",
    "## scale_weights(mymodel, scaling_factor = 1.05) row compare barely improves!!\n",
    "mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d012ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.513619\n",
      "6.509933\n",
      "5.541205\n"
     ]
    }
   ],
   "source": [
    "test_list = list(zip([row for row in neural_network.model.parameters() if len(row.shape) > 1],\n",
    "                     [row for row in mymodel.parameters() if len(row.shape) > 1]))\n",
    "\n",
    "for i in test_list:\n",
    "    #this first line will print out the row similarity matrix.\n",
    "    #print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[0])\n",
    "    print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e19f7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomStochasticOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, kappa, std_init=1):\n",
    "        super(CustomStochasticOptimizer, self).__init__(params, {})\n",
    "        self.kappa = kappa\n",
    "        self.kappa_iter = kappa #this works with the way the code is written in step.\n",
    "        self.param_shapes = [p.data.shape for group in self.param_groups for p in group['params']]\n",
    "        #print(self.param_shapes)\n",
    "        self.param_idx = None\n",
    "        self.neuron_idx = None\n",
    "        # Set the gradients for all model parameters to std_init\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                p.grad = torch.zeros_like(p.data) + std_init\n",
    "                print(p.grad)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \n",
    "        if self.kappa_iter < self.kappa:\n",
    "            self.kappa_iter += 1\n",
    "            param_group = self.param_groups\n",
    "            \n",
    "            #print(len([i for i in param_group])):\n",
    "                \n",
    "            #print()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            self.kappa_iter = 0\n",
    "            ##gets a new parameter randomly\n",
    "            param_shape = random.choice(self.param_shapes)\n",
    "            #and gets a random neuron\n",
    "            param_index = tuple(random.randint(0, dim - 1) for dim in param_shape)\n",
    "            print(param_shape,param_index)\n",
    "            print('reset')\n",
    "          \n",
    "        \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        print(loss)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Randomly choose one parameter group (neuron's parameter) for optimization\n",
    "        param_group = self.param_groups[torch.randint(len(self.param_groups), (1,)).item()]\n",
    "        print(self.param_groups)\n",
    "        for p in param_group['params']: ##this loops through parameters, not individual neurons.\n",
    "            if p.grad is None:  ##this should never be none.  In fact, i need an initial value.  1 maybe?\n",
    "                print(p.data)\n",
    "                continue\n",
    "\n",
    "            # Get the current parameter value and gradient\n",
    "            param_data = p.data\n",
    "            \n",
    "            std = torch.abs(p.grad.data)   ##this is the std, and i set this at the end.\n",
    "\n",
    "            # Store the original parameter value and compute the initial weight\n",
    "            # i don't think i need both.  lets see\n",
    "            original_param_data = param_data.clone()\n",
    "            initial_weight = param_data.clone()\n",
    "\n",
    "            # Sample kappa times with a normal distribution using gradient as std_dev and initial weight as mean\n",
    "            \n",
    "            \n",
    "            samples = torch.normal(mean=initial_weight, std=std, size=(self.kappa, *param_data.shape))\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            best_sample = None\n",
    "            new_std = 1 #this should have an init value. \n",
    "\n",
    "            for sample in samples:  #This iterates over kappa!!\n",
    "                # Update the parameter with the sampled value\n",
    "                p.data = sample\n",
    "\n",
    "                # Calculate the loss for the sampled value\n",
    "                sample_loss = closure()\n",
    "            \n",
    "            sample_loss = closure\n",
    "                # Check if the sampled value leads to a lower loss\n",
    "            if sample_loss < best_loss:\n",
    "                best_loss = sample_loss\n",
    "                best_sample = sample\n",
    "                new_std = torch.abs(best_sample - initial_weight) #i think\n",
    "\n",
    "            # Update the parameter with the best sampled value\n",
    "            p.data = best_sample\n",
    "            p.grad.data.fill_(new_std) \n",
    "            \"\"\"\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ba85702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(mymodel.parameters(), lr=0.001) #decay schedule??\n",
    "optimizer = CustomStochasticOptimizer(mymodel.parameters(),kappa=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5377e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = neural_network.inputs\n",
    "output_data = neural_network.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "19fcd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.2521, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2200, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 6)\n",
      "reset\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 6)\n",
      "reset\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 0)\n",
      "reset\n",
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1583, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 4)\n",
      "reset\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1531, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (1, 5)\n",
      "reset\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1862, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.2953, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1473, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.1676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1522, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4197, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 5)\n",
      "reset\n",
      "tensor(0.1760, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (3, 1)\n",
      "reset\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 3)\n",
      "reset\n",
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2673, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 6)\n",
      "reset\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 0)\n",
      "reset\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1297, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2135, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 6)\n",
      "reset\n",
      "tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 5)\n",
      "reset\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.1227, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1786, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (1, 0)\n",
      "reset\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1574, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1906, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 5)\n",
      "reset\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 2)\n",
      "reset\n",
      "tensor(0.1877, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 0)\n",
      "reset\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (0, 3)\n",
      "reset\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (6, 2)\n",
      "reset\n",
      "tensor(0.3345, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2060, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (0, 4)\n",
      "reset\n",
      "tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (0, 7)\n",
      "reset\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7458, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (6, 3)\n",
      "reset\n",
      "tensor(0.2050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 0)\n",
      "reset\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1299, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2122, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 2)\n",
      "reset\n",
      "tensor(0.1519, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2018, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 1)\n",
      "reset\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1363, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1685, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2817, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 1)\n",
      "reset\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1967, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (1, 6)\n",
      "reset\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3677, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 5)\n",
      "reset\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3257, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1394, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1758, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (4, 3)\n",
      "reset\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1905, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 5)\n",
      "reset\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1883, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 5)\n",
      "reset\n",
      "tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1686, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 3)\n",
      "reset\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2595, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2854, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1140, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1533, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1620, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 5)\n",
      "reset\n",
      "tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2021, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3083, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 5)\n",
      "reset\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1321, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 1)\n",
      "reset\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (4, 4)\n",
      "reset\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 3)\n",
      "reset\n",
      "tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1739, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 7)\n",
      "reset\n",
      "tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1571, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 2)\n",
      "reset\n",
      "tensor(0.1520, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1472, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1469, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1901, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1787, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 5)\n",
      "reset\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1326, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5227, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (1, 3)\n",
      "reset\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2150, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2869, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1393, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1233, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1628, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2539, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 5)\n",
      "reset\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3579, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (1, 4)\n",
      "reset\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1196, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1673, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1367, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 5)\n",
      "reset\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1209, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 4)\n",
      "reset\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 2)\n",
      "reset\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1671, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1905, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1571, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 2)\n",
      "reset\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2539, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (3, 0)\n",
      "reset\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1673, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2673, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 5)\n",
      "reset\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1520, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1620, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1533, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1685, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1883, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 3)\n",
      "reset\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (4, 4)\n",
      "reset\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1299, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 6)\n",
      "reset\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4197, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2595, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1363, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1583, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (4, 7)\n",
      "reset\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1671, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 0)\n",
      "reset\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1574, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2521, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1468, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 6)\n",
      "reset\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1394, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 4)\n",
      "reset\n",
      "tensor(0.1786, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2200, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 3)\n",
      "reset\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1209, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 5)\n",
      "reset\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2815, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (4, 2)\n",
      "reset\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2817, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (4, 1)\n",
      "reset\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 5)\n",
      "reset\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 6)\n",
      "reset\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1906, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (3, 3)\n",
      "reset\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1233, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1473, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3345, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1469, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1196, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (4, 3)\n",
      "reset\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1367, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2867, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.1597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3257, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2953, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1626, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 2)\n",
      "reset\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1531, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 6)\n",
      "reset\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 4)\n",
      "reset\n",
      "tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1686, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1393, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 6)\n",
      "reset\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1140, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2060, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1739, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (3, 2)\n",
      "reset\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1758, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1862, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 3)\n",
      "reset\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1297, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2021, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1321, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 4)\n",
      "reset\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3083, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 0)\n",
      "reset\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2135, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1522, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5227, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2150, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (3, 1)\n",
      "reset\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 2)\n",
      "reset\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1787, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1628, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (1, 2)\n",
      "reset\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1326, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (5, 5)\n",
      "reset\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 4)\n",
      "reset\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1519, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7]) (2, 6)\n",
      "reset\n",
      "tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 5)\n",
      "reset\n",
      "tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (4, 4)\n",
      "reset\n",
      "tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1760, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 1)\n",
      "reset\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (3, 0)\n",
      "reset\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 1)\n",
      "reset\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1472, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (3, 3)\n",
      "reset\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 6)\n",
      "reset\n",
      "tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3579, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (6, 5)\n",
      "reset\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1901, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3677, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.2018, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2122, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1227, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2854, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.3615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1877, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (3, 0)\n",
      "reset\n",
      "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (5, 7)\n",
      "reset\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1628, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 6)\n",
      "reset\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (3, 3)\n",
      "reset\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1472, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1571, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1862, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3579, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2539, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 6)\n",
      "reset\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1520, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4197, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0523, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1739, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 5)\n",
      "reset\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5227, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2200, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1673, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3493, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1901, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 0)\n",
      "reset\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 5)\n",
      "reset\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2595, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1367, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (2, 0)\n",
      "reset\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (5, 4)\n",
      "reset\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1883, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1685, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1326, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1787, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2060, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.2609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1469, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 5)\n",
      "reset\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1786, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2150, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (5, 2)\n",
      "reset\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 1)\n",
      "reset\n",
      "tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1394, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (3, 5)\n",
      "reset\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2122, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 1)\n",
      "reset\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2521, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 0)\n",
      "reset\n",
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (0,)\n",
      "reset\n",
      "tensor(0.3083, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2021, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (5, 7)\n",
      "reset\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1297, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1209, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1363, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (2, 2)\n",
      "reset\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (1, 2)\n",
      "reset\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1531, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1758, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2867, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (1,)\n",
      "reset\n",
      "tensor(0.1299, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1196, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (4, 3)\n",
      "reset\n",
      "tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2817, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3257, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1760, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2854, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1574, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (3, 4)\n",
      "reset\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 2)\n",
      "reset\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1686, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1519, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (6,)\n",
      "reset\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4327, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (2,)\n",
      "reset\n",
      "tensor(0.1710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2135, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (0, 0)\n",
      "reset\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1905, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3677, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (4, 3)\n",
      "reset\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (5,)\n",
      "reset\n",
      "tensor(0.1233, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1583, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1140, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (5, 3)\n",
      "reset\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (0, 3)\n",
      "reset\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (0, 1)\n",
      "reset\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1522, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (1, 2)\n",
      "reset\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2018, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (3,)\n",
      "reset\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (2,)\n",
      "reset\n",
      "tensor(0.1393, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1321, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (4,)\n",
      "reset\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1227, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2673, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4]) (1,)\n",
      "reset\n",
      "tensor(0.2953, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1671, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (6, 5)\n",
      "reset\n",
      "tensor(0.1468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 8]) (5, 0)\n",
      "reset\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1620, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1473, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (5, 5)\n",
      "reset\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (3,)\n",
      "reset\n",
      "tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([4, 7]) (2, 6)\n",
      "reset\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 2)\n",
      "reset\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1877, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7]) (0,)\n",
      "reset\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1906, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3345, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([7, 7]) (6, 2)\n",
      "reset\n",
      "tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1533, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "#samples = n\n",
    "samples = input_data.shape[0]\n",
    "#print(samples)\n",
    "num_epochs = 3\n",
    "\n",
    "lab = Lab(mymodel,num_epochs,samples)\n",
    "data = list(zip(input_data, output_data))\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    sample = 0\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    shuffled_inputs, shuffled_outputs = zip(*data)\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    for inputs, targets in zip(shuffled_inputs, shuffled_outputs):\n",
    "        \n",
    "        inputs = inputs.unsqueeze(0)  \n",
    "        targets = targets.unsqueeze(0)\n",
    "    \n",
    "        output = mymodel(inputs)\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        \n",
    "        optimizer.step(loss)\n",
    "        lab.record(mymodel,epoch,samples,sample)\n",
    "        #print or store loss if you wanna\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        \n",
    "        sample += 1\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6381e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.8800955\n",
      "7.209585\n",
      "4.2717648\n",
      "_______\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this will only work if the networks have the same architecture\n",
    "test_list = list(zip([row for row in neural_network.model.parameters() if len(row.shape) > 1],\n",
    "                     [row for row in mymodel.parameters() if len(row.shape) > 1]))\n",
    "\n",
    "for i in test_list:\n",
    "    #this first line will print out the row similarity matrix.\n",
    "    #print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[0])\n",
    "    print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[1])\n",
    "print('_______')  \n",
    "# VALIDATION\n",
    "iterations = 1000\n",
    "val_samples = 10\n",
    "m = 0.0\n",
    "std = 1.0\n",
    "\n",
    "val_list = []\n",
    "for _ in range(iterations):\n",
    "    val_inputs = torch.from_numpy(np.random.normal(m, std, (val_samples,layer_sizes[0])).astype(np.float32))\n",
    "    val_outputs = neural_network.model(val_inputs)\n",
    "    this_val_acc = calculate_validation_loss(mymodel, val_inputs, val_outputs, criterion)\n",
    "    val_list.append(this_val_acc)\n",
    "    \n",
    "val_histogram(val_list, bins=20, title=\"val_hist\", xlabel=\"Values\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f3c017f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##x_range = (99998,100000) to view final weights\n",
    "lab.graph(diff=0,graph_together = False, plot_size = (15,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac518f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_line_graph(losses,window_size = 1000, plot_size = (15,5)) #window_size is the moving average window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
