{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4701eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LABNET import Neuron, Net, Lab, Teacher,compare_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e88d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db84284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_weights(model, perturbation_amount):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            weights = layer.get_weights()\n",
    "            perturbations = [np.random.uniform(-perturbation_amount, perturbation_amount, w.shape) for w in weights]\n",
    "            perturbed_weights = [w + perturbation for w, perturbation in zip(weights, perturbations)]\n",
    "            layer.set_weights(perturbed_weights)\n",
    "\n",
    "# Example usage:\n",
    "# Save the perturbed weights\n",
    "#perturbation_amount = 0.1\n",
    "#perturb_weights(model, perturbation_amount)\n",
    "#save_weights(model, 'perturbed_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894aab1",
   "metadata": {},
   "source": [
    "\n",
    "## Adding a few hyperparameters ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab368e9a",
   "metadata": {},
   "source": [
    "first, instead of storing gradients we store standard deviations.  we will need a default to start.  \n",
    "then there is kappa.  this may move as we go lower, or whatever, but kappa is the number of samples.  \n",
    "then there is a percentage of neurons to sample at each kappa iteration.  min value here should be only one neuron, and the max should be all.  this could be randomly determined maybe?.  \n",
    "so, lets say you are doing the min, one neuron per kappa iteration.  \n",
    "you look up that neurons standard deviation (which i think i use gradients instead)\n",
    "and you sample using the standard deviation for that neuron, and the weight value as the mean.  get kappa losses that each correspond to a sampled weight.  you have kappa loss weight pairs for that neuron.  pick the lowest loss, set the weight to that sampled value, and set the standard deviation to whatever that selected weight is from the previous one.  so, if the sampled value is outside the 1 sd bound, it is going to search a wider area, if it is less, it will search a smaller one.  if it doesn't sample one that is better than the current value, it gets multiplied by some fixed number greater than 1.  so, to get to the GLOBAL minima, those values all go big, and it can search over huge areas and won't find anything smaller.  so you could see how often it selects a better value, that should reduce as more iterations happen.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551dbc7",
   "metadata": {},
   "source": [
    "![Alt text](normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d0323",
   "metadata": {},
   "source": [
    "theory i guess:gradient explosion or collapse is a spectrum.  first, is it normally distributed? i think its distribution is a function of the architecture, the depth and the number of neurons.  depth contribution makes the most sense.  you need all the deep layers to compound to get either issue.  as you get deeper, the risk of catastrophic gradient deviation increases, or, if we think about training lots of neural networks, or just the same neural network multiple times, it likely does that in some distribution.  so, we should either see the earliest layers train first if the gradient explodes, or the latter layers to train first (if vanish or collapse).   however, it looks like it does one or the other and runs into a minima. a decent minima even.  what would that mean.  it means on the loss landscape there may be lots of really decent places for the weights to end up, even if it doesn't match the ideal (controlled generated) weights.  \n",
    "WHAT IF SOME INDIVIDUAL VALUES INSIDE WEIGHT MATRICES (i need a name for not a neuron, but an individual weight inside that tensor)\n",
    "\n",
    "so, look at lots of em, see if there is evidence for that.  \n",
    "\n",
    "then, is there a way to cut the compounding during the backward pass.  what if each layer only takes into account the next weight layer, doesnt' back propagate all the way back.  does that make it so each neuron can pull its weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4402d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_graph(numbers\n",
    "                    ,window_size = 1\n",
    "                    ,plot_size = (10,6)\n",
    "                    ,x_range = (None, None)\n",
    "                    ,y_range = (None, None)\n",
    "                   ):\n",
    "    \n",
    "    if window_size <= 0 or window_size > len(numbers):\n",
    "        raise ValueError(\"Invalid window size\")\n",
    "    \n",
    "    running_sum = sum(numbers[:window_size])\n",
    "    averages = [running_sum / window_size]\n",
    "\n",
    "    for i in range(window_size, len(numbers)):\n",
    "        running_sum += numbers[i] - numbers[i - window_size]\n",
    "        averages.append(running_sum / window_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = range(1, len(averages) + 1)  \n",
    "    y = averages  # y-axis values\n",
    "    plt.figure(figsize=plot_size)\n",
    "    plt.plot(x, y)  # Plotting the line graph\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "\n",
    "    if x_range[0] is not None and x_range[1] is not None:\n",
    "        plt.xlim(x_range[0], x_range[1])\n",
    "    if y_range[0] is not None and y_range[1] is not None:\n",
    "        plt.ylim(y_range[0], y_range[1])\n",
    "    \n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d76df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aebd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = 1000 #number of samples to generate\n",
    "layer_sizes = [8, 7,7,4]  # Inputs: 4, Hidden layers: [8, 8], Outputs: 3\n",
    "neural_network = Teacher(layer_sizes)\n",
    "#initialize_weights_uniform(neural_network,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fc55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.generate_data(\n",
    "    n\n",
    "    ,'normal'\n",
    "    , m =0.0\n",
    "    , std=1.0\n",
    "    , gen_lr = 0.01\n",
    "    , gen_epochs = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f8b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a function of the Teacher obj, i think save all the generate settings then just pass number of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d81bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0282, -0.0551,  0.0385,  0.0443], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model(neural_network.inputs[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae2e479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_layer.weight',\n",
       "              tensor([[-0.8317, -0.6107, -0.1218,  0.7835,  0.2836,  0.5464,  0.4024,  0.1032],\n",
       "                      [-0.8218,  0.8080, -0.6262, -0.5921,  0.1051, -0.2812, -0.1026,  0.7911],\n",
       "                      [ 0.2141, -0.3966,  0.3791, -0.9193,  0.6866,  0.8488, -0.8279,  0.0039],\n",
       "                      [-0.4058,  0.9216,  0.7105, -0.8772, -0.2155,  1.0022, -0.2297, -0.7275],\n",
       "                      [ 0.0589,  0.1915, -0.2168, -0.4737,  0.5355,  0.5544, -0.3740,  0.3074],\n",
       "                      [-0.9271,  0.7221, -0.9206, -0.0639,  0.2503, -0.8302,  0.2518,  0.6903],\n",
       "                      [ 0.5289,  0.7302,  0.8981,  0.6241, -0.5272,  0.7404,  0.2079, -0.4932]])),\n",
       "             ('input_layer.bias',\n",
       "              tensor([ 0.8167,  0.6258, -0.0887, -0.7777, -0.5129,  0.2424, -0.8751])),\n",
       "             ('hidden_layer_2.weight',\n",
       "              tensor([[-0.0368,  0.0593, -0.8273,  0.3006,  0.5061, -0.9033, -1.0102],\n",
       "                      [-0.8206,  0.4237, -0.9049, -0.3434, -0.0422, -0.8903,  0.2098],\n",
       "                      [-0.7053, -0.5905,  0.0092, -0.4673, -0.0555, -0.9301, -0.0048],\n",
       "                      [ 0.5959, -0.4562,  0.6961,  0.2194,  0.8000, -0.9947, -0.1321],\n",
       "                      [ 0.2532,  0.2116, -0.4375, -0.8413,  0.7125, -0.1956,  0.3084],\n",
       "                      [-0.1041,  0.3876, -0.4467, -0.0989,  0.3625, -0.8932, -0.8880],\n",
       "                      [ 0.1788, -0.0767,  0.3754,  0.1693, -0.8201, -0.2046, -0.2368]])),\n",
       "             ('hidden_layer_2.bias',\n",
       "              tensor([ 0.2376,  0.2620,  0.0761,  0.0610, -0.9685,  0.1663, -0.4825])),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-0.3915, -0.4097,  0.6347,  0.0488,  0.3139,  0.0448, -0.6963],\n",
       "                      [ 0.7222,  0.5149, -0.2885, -0.0141,  0.8921,  0.4868, -0.2363],\n",
       "                      [ 0.7746, -0.1267,  0.9773,  0.0641,  0.5766, -0.1404, -0.4122],\n",
       "                      [-0.5748, -0.5768, -0.7165, -0.0227, -0.4642,  0.7018,  0.3541]])),\n",
       "             ('output_layer.bias',\n",
       "              tensor([-0.0305, -0.0382, -0.0388,  0.0716]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model.state_dict()\n",
    "#torch.save(neural_network.model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b2ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.hidden_1 = nn.Linear(8, 7) ##make these all variables duh\n",
    "        self.hidden_2 = nn.Linear(7,7)\n",
    "        #self.hidden_3 = nn.Linear(7,7)\n",
    "        #self.hidden_4 = nn.Linear(7,7)\n",
    "        #self.hidden_5 = nn.Linear(7,7)\n",
    "        self.output = nn.Linear(7, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden_1(x))\n",
    "        x = self.relu(self.hidden_2(x))\n",
    "        #x = self.relu(self.hidden_3(x))\n",
    "        #x = self.relu(self.hidden_4(x))\n",
    "        #x = self.relu(self.hidden_5(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8807a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (hidden_1): Linear(in_features=8, out_features=7, bias=True)\n",
      "  (hidden_2): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (output): Linear(in_features=7, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mymodel = MyModel()\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221b9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_state_dict_keys_by_order(model, reference_model):\n",
    "    model_keys = list(model.state_dict().keys())\n",
    "    reference_keys = list(reference_model.state_dict().keys())\n",
    "    name_mapping = dict(zip(model_keys, reference_keys))\n",
    "    \n",
    "    new_state_dict = OrderedDict()\n",
    "    for key in model.state_dict():\n",
    "        new_key = name_mapping[key]\n",
    "        new_state_dict[new_key] = model.state_dict()[key]\n",
    "    return new_state_dict\n",
    "\n",
    "def perturb_weights(model, std_dev):\n",
    "    for param in model.parameters():\n",
    "        noise = np.random.normal(loc=0.0, scale=std_dev, size=param.data.shape)\n",
    "        param.data.add_(torch.from_numpy(noise))\n",
    "        \n",
    "def scale_weights(model, scaling_factor):\n",
    "    for param in model.parameters():\n",
    "        param.data.mul_(scaling_factor)\n",
    "        \n",
    "def calculate_validation_loss(model, validation_inputs, validation_outputs, loss_function):\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        #validation_inputs = validation_inputs.to(device)  # Move inputs to the appropriate device (e.g., GPU)\n",
    "        #validation_outputs = validation_outputs.to(device)  # Move targets to the appropriate device\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(validation_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, validation_outputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        average_loss = loss.item()\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    return average_loss\n",
    "\n",
    "def val_histogram(data_list, bins=10, title=\"val_hist\", xlabel=\"Values\", ylabel=\"Frequency\"):\n",
    "\n",
    "    plt.hist(data_list, bins=bins, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663c7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ef270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_this = rename_state_dict_keys_by_order( neural_network.model,mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5cd09b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.load_state_dict(load_this)\n",
    "#mymodel.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e4372c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden_1.weight',\n",
       "              tensor([[ 0.1538,  0.0289,  0.0205,  0.1681,  0.0953, -0.0853, -0.2919, -0.3410],\n",
       "                      [-0.0999,  0.0705, -0.1988,  0.1934, -0.2703, -0.1747, -0.2190,  0.3141],\n",
       "                      [-0.1155, -0.1740,  0.2891, -0.3373,  0.1666,  0.1834,  0.2162, -0.0234],\n",
       "                      [ 0.0780, -0.1128,  0.2396,  0.2997, -0.2789,  0.1789,  0.0857, -0.2142],\n",
       "                      [-0.2227,  0.1100, -0.2214, -0.1928,  0.2069,  0.3440, -0.1860,  0.0428],\n",
       "                      [ 0.1045, -0.2811, -0.0734,  0.1148,  0.1613,  0.1522,  0.3517, -0.2074],\n",
       "                      [ 0.1342, -0.2854,  0.0689,  0.2554,  0.2261, -0.0514, -0.1717, -0.1760]])),\n",
       "             ('hidden_1.bias',\n",
       "              tensor([-0.1805,  0.1664,  0.1360, -0.0699,  0.0953, -0.2144,  0.0035])),\n",
       "             ('hidden_2.weight',\n",
       "              tensor([[ 0.1072, -0.1184, -0.0053,  0.1171,  0.3345, -0.2905, -0.1359],\n",
       "                      [-0.1284,  0.3751, -0.0143,  0.3225, -0.3324, -0.0088, -0.1230],\n",
       "                      [ 0.2219,  0.2493, -0.2578, -0.3298,  0.2550, -0.1249,  0.3696],\n",
       "                      [ 0.1039, -0.0584, -0.2887,  0.1797,  0.0641,  0.0893, -0.1502],\n",
       "                      [-0.1044, -0.0488,  0.3775, -0.3225,  0.3324, -0.0075, -0.2058],\n",
       "                      [ 0.1817,  0.3717, -0.2681, -0.0341,  0.1062, -0.0843, -0.1321],\n",
       "                      [-0.1719,  0.1655,  0.0524,  0.3415, -0.0177,  0.2260,  0.2365]])),\n",
       "             ('hidden_2.bias',\n",
       "              tensor([ 0.3484,  0.0890,  0.2982, -0.0274, -0.0601,  0.2178, -0.1785])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 0.1924, -0.3776,  0.1583,  0.2088, -0.0462, -0.0562, -0.1205],\n",
       "                      [ 0.3198,  0.2065, -0.0651,  0.0085,  0.0827, -0.3660,  0.3479],\n",
       "                      [ 0.1128,  0.3198,  0.3074, -0.1107, -0.3430,  0.0503, -0.0025],\n",
       "                      [ 0.0006, -0.0496, -0.3337,  0.1945,  0.0920, -0.0004,  0.2422]])),\n",
       "             ('output.bias', tensor([ 0.1671, -0.2947,  0.3128,  0.1573]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##STARTING with the right answuers gives some close to zero row_comp:3.5974587e-08,0.0,0.0; 0.0,2.9802322e-08,1.4901161e-08\n",
    "#interesting that you get a zero, and then a close to zero.  \n",
    "#perturb_weights(mymodel, std_dev = 0.005) # converges\n",
    "#perturb_weights(mymodel, std_dev = 0.009) # converges\n",
    "#perturb_weights(mymodel, std_dev = 0.05) doesn't converge\n",
    "#perturb_weights(mymodel, std_dev = 0.01) #converges\n",
    "#perturb_weights(mymodel, std_dev = 0.01) #not converging well, even with lower lr, 0.003. 1t 0.001\n",
    "\n",
    "\n",
    "# scale_weights(mymodel, scaling_factor = 1.1) ## converges, weights cross.  \n",
    "#scale_weights(mymodel, scaling_factor = 1.5) ## good validation, non zero row comapre still..\n",
    "\n",
    "#scale_weights(mymodel, scaling_factor = 2) ## good validation, row compare stays pretty close to the same...\n",
    "## scale_weights(mymodel, scaling_factor = 1.05) row compare barely improves!!\n",
    "mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d012ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.758879\n",
      "8.257727\n",
      "4.969883\n"
     ]
    }
   ],
   "source": [
    "test_list = list(zip([row for row in neural_network.model.parameters() if len(row.shape) > 1],\n",
    "                     [row for row in mymodel.parameters() if len(row.shape) > 1]))\n",
    "\n",
    "for i in test_list:\n",
    "    #this first line will print out the row similarity matrix.\n",
    "    #print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[0])\n",
    "    print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e19f7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomStochasticOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, kappa, std_init=1):\n",
    "        super(CustomStochasticOptimizer, self).__init__(params, {})\n",
    "        self.kappa = kappa\n",
    "        self.kappa_iter = kappa #this works with the way the code is written in step.\n",
    "        self.param_shapes = [p.data.shape for group in self.param_groups for p in group['params']]\n",
    "        #print(self.param_shapes)\n",
    "        self.param_idx = None\n",
    "        self.neuron_idx = [] ##this dim will change, biases have one, matrices 2, bla bla\n",
    "        \n",
    "        # Set the gradients for all model parameters to std_init\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                p.grad = torch.zeros_like(p.data) + std_init\n",
    "                #print(p.grad)\n",
    "\n",
    "    def get_nested_data(self,data, indices):\n",
    "        def _get_nested_data(self,data, indices):\n",
    "            if len(indices) == 1:\n",
    "                return data[indices[0]]\n",
    "            else:\n",
    "                next_index = indices[0]\n",
    "                remaining_indices = indices[1:]\n",
    "                next_data = data[next_index]\n",
    "                return _get_nested_data(self,next_data, remaining_indices)\n",
    "\n",
    "        return _get_nested_data(self,data, indices)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \n",
    "        if self.kappa_iter < self.kappa:\n",
    "            self.kappa_iter += 1\n",
    "            param_group = self.param_groups\n",
    "            #print(self.param_idx)\n",
    "            #print(len([i for i in param_group])):\n",
    "                \n",
    "            #print()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            self.kappa_iter = 0\n",
    "            self.param_idx = random.randint(1,len(self.param_shapes)-1)\n",
    "            \n",
    "            this_param_shape = self.param_shapes[self.param_idx]\n",
    "            self.neuron_idx = [random.randint(1,i)-1 for i in this_param_shape]\n",
    "            print(self.param_idx)\n",
    "            print(self.neuron_idx)\n",
    "            #self.param_groups[0]['params'] ##this is the raw parameter.  groups will fuck stuff up just fyi\n",
    "            #print(self.param_groups[0]['params'][self.param_idx]) #this gets the param\n",
    "            print('one_number')\n",
    "            print(self.get_nested_data(self.param_groups[0]['params'][self.param_idx], self.neuron_idx))\n",
    "            #i need to get\n",
    "            ################START HERE!!\n",
    "            \n",
    "            \n",
    "            print('reset')\n",
    "          \n",
    "        \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        print(loss)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Randomly choose one parameter group (neuron's parameter) for optimization\n",
    "        param_group = self.param_groups[torch.randint(len(self.param_groups), (1,)).item()]\n",
    "        print(self.param_groups)\n",
    "        for p in param_group['params']: ##this loops through parameters, not individual neurons.\n",
    "            if p.grad is None:  ##this should never be none.  In fact, i need an initial value.  1 maybe?\n",
    "                print(p.data)\n",
    "                continue\n",
    "\n",
    "            # Get the current parameter value and gradient\n",
    "            param_data = p.data\n",
    "            \n",
    "            std = torch.abs(p.grad.data)   ##this is the std, and i set this at the end.\n",
    "\n",
    "            # Store the original parameter value and compute the initial weight\n",
    "            # i don't think i need both.  lets see\n",
    "            original_param_data = param_data.clone()\n",
    "            initial_weight = param_data.clone()\n",
    "\n",
    "            # Sample kappa times with a normal distribution using gradient as std_dev and initial weight as mean\n",
    "            \n",
    "            \n",
    "            samples = torch.normal(mean=initial_weight, std=std, size=(self.kappa, *param_data.shape))\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            best_sample = None\n",
    "            new_std = 1 #this should have an init value. \n",
    "\n",
    "            for sample in samples:  #This iterates over kappa!!\n",
    "                # Update the parameter with the sampled value\n",
    "                p.data = sample\n",
    "\n",
    "                # Calculate the loss for the sampled value\n",
    "                sample_loss = closure()\n",
    "            \n",
    "            sample_loss = closure\n",
    "                # Check if the sampled value leads to a lower loss\n",
    "            if sample_loss < best_loss:\n",
    "                best_loss = sample_loss\n",
    "                best_sample = sample\n",
    "                new_std = torch.abs(best_sample - initial_weight) #i think\n",
    "\n",
    "            # Update the parameter with the best sampled value\n",
    "            p.data = best_sample\n",
    "            p.grad.data.fill_(new_std) \n",
    "            \"\"\"\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ba85702",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(mymodel.parameters(), lr=0.001) #decay schedule??\n",
    "optimizer = CustomStochasticOptimizer(mymodel.parameters(),kappa=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5377e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = neural_network.inputs\n",
    "output_data = neural_network.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19fcd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[3, 5]\n",
      "one_number\n",
      "tensor(-0.0004, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2758, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0705, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1481, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2119, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.3128, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[3]\n",
      "one_number\n",
      "tensor(-0.0699, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1685, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[0]\n",
      "one_number\n",
      "tensor(-0.1805, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1396, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2827, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.1360, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2179, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1284, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1668, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 4]\n",
      "one_number\n",
      "tensor(-0.3430, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[6, 0]\n",
      "one_number\n",
      "tensor(-0.1719, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3142, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2004, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[3, 1]\n",
      "one_number\n",
      "tensor(-0.0584, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2126, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1871, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[1, 2]\n",
      "one_number\n",
      "tensor(-0.0143, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1598, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 4]\n",
      "one_number\n",
      "tensor(-0.3430, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 0]\n",
      "one_number\n",
      "tensor(0.3198, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.3128, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1104, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1819, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1545, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1633, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1126, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[6]\n",
      "one_number\n",
      "tensor(0.0035, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2620, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1589, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[1, 5]\n",
      "one_number\n",
      "tensor(-0.0088, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1865, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1216, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[0]\n",
      "one_number\n",
      "tensor(-0.1805, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2255, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1342, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 1]\n",
      "one_number\n",
      "tensor(0.3198, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1169, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1592, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1882, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1512, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 1]\n",
      "one_number\n",
      "tensor(0.2065, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 1]\n",
      "one_number\n",
      "tensor(0.2065, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1761, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1506, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[3, 4]\n",
      "one_number\n",
      "tensor(0.0641, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1887, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[3, 1]\n",
      "one_number\n",
      "tensor(-0.0584, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2194, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[4]\n",
      "one_number\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2222, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1877, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1797, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[4]\n",
      "one_number\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1926, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[0, 6]\n",
      "one_number\n",
      "tensor(-0.1359, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1301, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.2982, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2076, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1165, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1979, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[4]\n",
      "one_number\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1189, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[0, 6]\n",
      "one_number\n",
      "tensor(-0.1205, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1288, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3739, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1183, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[3]\n",
      "one_number\n",
      "tensor(-0.0274, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1505, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1954, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1704, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1942, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[0, 0]\n",
      "one_number\n",
      "tensor(0.1924, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1320, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2128, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2180, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1217, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[0]\n",
      "one_number\n",
      "tensor(-0.1805, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1288, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2136, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1592, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[3]\n",
      "one_number\n",
      "tensor(0.1573, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2189, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[5]\n",
      "one_number\n",
      "tensor(0.2178, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1783, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1738, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1452, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[1, 3]\n",
      "one_number\n",
      "tensor(0.3225, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1596, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2085, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2014, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.1360, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2703, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1735, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[4]\n",
      "one_number\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1353, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1992, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1353, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1941, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[5]\n",
      "one_number\n",
      "tensor(0.2178, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1841, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1871, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1342, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1480, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1551, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[4]\n",
      "one_number\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1646, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1534, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 2]\n",
      "one_number\n",
      "tensor(0.3074, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1547, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1309, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2681, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[6]\n",
      "one_number\n",
      "tensor(0.0035, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2790, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1343, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1390, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1336, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.2982, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 5]\n",
      "one_number\n",
      "tensor(-0.3660, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2084, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2014, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[0]\n",
      "one_number\n",
      "tensor(0.3484, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1643, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[1]\n",
      "one_number\n",
      "tensor(-0.2947, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.3338, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1437, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2260, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[6, 2]\n",
      "one_number\n",
      "tensor(0.0524, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1320, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0958, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1659, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[5, 5]\n",
      "one_number\n",
      "tensor(-0.0843, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1862, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[2, 0]\n",
      "one_number\n",
      "tensor(0.2219, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1472, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 4]\n",
      "one_number\n",
      "tensor(-0.3430, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2261, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1623, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2469, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1698, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[3, 5]\n",
      "one_number\n",
      "tensor(0.0893, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2061, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1189, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[1, 5]\n",
      "one_number\n",
      "tensor(-0.0088, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 1]\n",
      "one_number\n",
      "tensor(0.2065, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1642, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1378, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2140, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[4, 5]\n",
      "one_number\n",
      "tensor(-0.0075, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1217, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1190, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[0]\n",
      "one_number\n",
      "tensor(-0.1805, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1450, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1350, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[3]\n",
      "one_number\n",
      "tensor(0.1573, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1386, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1793, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2785, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[1]\n",
      "one_number\n",
      "tensor(0.1664, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[1]\n",
      "one_number\n",
      "tensor(0.0890, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1455, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1557, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[5]\n",
      "one_number\n",
      "tensor(-0.2144, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[1]\n",
      "one_number\n",
      "tensor(-0.2947, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3521, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1465, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1782, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1682, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 1]\n",
      "one_number\n",
      "tensor(0.3198, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2422, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1691, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[5]\n",
      "one_number\n",
      "tensor(0.2178, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2189, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1863, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[3, 3]\n",
      "one_number\n",
      "tensor(0.1945, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1123, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1475, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4335, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1092, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1733, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1315, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[0, 0]\n",
      "one_number\n",
      "tensor(0.1072, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2666, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 2]\n",
      "one_number\n",
      "tensor(-0.0651, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2592, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[0, 4]\n",
      "one_number\n",
      "tensor(-0.0462, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1477, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2010, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[3, 4]\n",
      "one_number\n",
      "tensor(0.0920, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1782, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.3128, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1688, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[1]\n",
      "one_number\n",
      "tensor(0.1664, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1998, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.3128, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2177, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2278, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1555, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[4]\n",
      "one_number\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1538, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2522, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[2, 6]\n",
      "one_number\n",
      "tensor(-0.0025, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1906, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1901, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3487, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2059, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[0]\n",
      "one_number\n",
      "tensor(0.1671, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1574, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 2]\n",
      "one_number\n",
      "tensor(-0.0651, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1595, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2007, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[3, 3]\n",
      "one_number\n",
      "tensor(0.1945, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4590, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2564, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1874, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[6, 6]\n",
      "one_number\n",
      "tensor(0.2365, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1786, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1252, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.3128, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1596, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 6]\n",
      "one_number\n",
      "tensor(0.3479, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1615, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2120, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[0, 4]\n",
      "one_number\n",
      "tensor(0.3345, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1642, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2432, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2073, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1640, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1463, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[4]\n",
      "one_number\n",
      "tensor(0.0953, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2207, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.3128, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1890, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2110, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[6]\n",
      "one_number\n",
      "tensor(0.0035, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1391, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1797, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[0, 3]\n",
      "one_number\n",
      "tensor(0.2088, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1395, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.1360, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2587, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2115, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1509, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2075, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1811, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.1360, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1774, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2113, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "[2]\n",
      "one_number\n",
      "tensor(0.1360, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2178, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1921, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1992, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[0, 6]\n",
      "one_number\n",
      "tensor(-0.1205, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1483, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2854, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[3, 5]\n",
      "one_number\n",
      "tensor(-0.0004, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1467, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1464, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2116, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1135, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[0]\n",
      "one_number\n",
      "tensor(0.1671, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1761, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "[1, 0]\n",
      "one_number\n",
      "tensor(-0.1284, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1744, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2158, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2386, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1323, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[1]\n",
      "one_number\n",
      "tensor(-0.2947, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1679, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1896, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1963, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "[3]\n",
      "one_number\n",
      "tensor(-0.0274, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.2147, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2096, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1525, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1156, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[0]\n",
      "one_number\n",
      "tensor(0.1671, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1663, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3100, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "[1, 4]\n",
      "one_number\n",
      "tensor(0.0827, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1391, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "[1]\n",
      "one_number\n",
      "tensor(-0.2947, grad_fn=<SelectBackward0>)\n",
      "reset\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1537, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1533, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "#samples = n\n",
    "samples = input_data.shape[0]\n",
    "#print(samples)\n",
    "num_epochs = 1\n",
    "\n",
    "lab = Lab(mymodel,num_epochs,samples)\n",
    "data = list(zip(input_data, output_data))\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    sample = 0\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    shuffled_inputs, shuffled_outputs = zip(*data)\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    for inputs, targets in zip(shuffled_inputs, shuffled_outputs):\n",
    "        \n",
    "        inputs = inputs.unsqueeze(0)  \n",
    "        targets = targets.unsqueeze(0)\n",
    "    \n",
    "        output = mymodel(inputs)\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        \n",
    "        optimizer.step(loss)\n",
    "        lab.record(mymodel,epoch,samples,sample)\n",
    "        #print or store loss if you wanna\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        \n",
    "        sample += 1\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6381e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.758879\n",
      "8.257727\n",
      "4.969883\n",
      "_______\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this will only work if the networks have the same architecture\n",
    "test_list = list(zip([row for row in neural_network.model.parameters() if len(row.shape) > 1],\n",
    "                     [row for row in mymodel.parameters() if len(row.shape) > 1]))\n",
    "\n",
    "for i in test_list:\n",
    "    #this first line will print out the row similarity matrix.\n",
    "    #print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[0])\n",
    "    print(compare_rows(i[0].detach().numpy(),i[1].detach().numpy())[1])\n",
    "print('_______')  \n",
    "# VALIDATION\n",
    "iterations = 1000\n",
    "val_samples = 10\n",
    "m = 0.0\n",
    "std = 1.0\n",
    "\n",
    "val_list = []\n",
    "for _ in range(iterations):\n",
    "    val_inputs = torch.from_numpy(np.random.normal(m, std, (val_samples,layer_sizes[0])).astype(np.float32))\n",
    "    val_outputs = neural_network.model(val_inputs)\n",
    "    this_val_acc = calculate_validation_loss(mymodel, val_inputs, val_outputs, criterion)\n",
    "    val_list.append(this_val_acc)\n",
    "    \n",
    "val_histogram(val_list, bins=20, title=\"val_hist\", xlabel=\"Values\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f3c017f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAFNCAYAAABR3QEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdsklEQVR4nO3de7RuZV0v8O8vEC+oKYJy3YKGEpq39iHFe0qBZphaapbXcTikZJqWZOOoZXm0m+ZJo62hVCZ61I6oIHkr09TYqAkIKGHKdoMgCIJ5uMjv/PFOTst11l6svff7rte15uczxjvWnM983jl/y/EMtt/1PHPO6u4AAACw/v3QvAsAAABgdQiAAAAAIyEAAgAAjIQACAAAMBICIAAAwEgIgAAAACMhAAIAAIyEAAjAmlJV/15Vj16i/aFVdf4y33trVf3eMse7qn5kWnXujKp6RFVtWeb4CVX131ezJgDWBwEQgHWhu/+pu+857zq2pap+o6rOrqqrq+orVfUbO3qu7j62u185zfoAGIdd510AAIxEJXl6ki8kuXuSv6+qi7r75PmWBcCYmAEEYC26X1V9oaquqqp3VNWtFi+brKr7V9Vnhxm3dyS51cITDDNyF1fV1qp69qJjt6yqP6qqr1XVN4Yll7cejj2iqrZU1Yuq6tLhHM+6uYK7+w+6+7PdfUN3n5/kvUkevNx3quqlVfXNYdnr0xa0/7/lrFV1x6p6f1VdVlXfGrb3X9D3mVV14YKZx6ctdS0AxkEABGAt+oUkRyY5KMl9kjxz4cGq2i3J/07y10n2SPK/kjxxwfEjk7w4yRFJDk6y+J7C1yS5R5L7JfmRJPsledmC43sn+eGh/TlJ3lBVd1xp8VVVSR6a5Jxluu2dZM/hGs9Isqmqllri+kNJ3pLkrkk2JPlukj8brrN7ktcnOaq7b5fk8CSfX2mdAKw/AiAAa9Hru3trd1+R5H2ZBLWFHpjkFkle193Xd/e7kpyx4PgvJHlLd5/d3d9J8oqbDgzh7L8meWF3X9HdVyd5VZKnLPj+9Ul+dzj3qUmuSbI99x++Iv8Z3Jbz37v72u7+xyQfGOr+Pt19eXe/u7v/Y6j195M8fEGXG5Pcu6pu3d0Xd/dyoROAdU4ABGAtumTB9n8kue2i4/sm+Xp394K2ry46ftE2ju2V5DZJzqyqK6vqyiQfHNpvcnl333AzNSypqo7L5F7Ax3b3tct0/dYQThfWuO8S57tNVf1FVX21qr6d5ONJ7lBVuwzff3KSY5NcXFUfqKpDVlInAOuTAAjAenRxkv2G2bybbFh0/IBtHPtmJsso79Xddxg+P9zdKwp4yxnuNTw+yaO6e5uveRjccVjCubDGrUv0e1Ems48/0d23T/Kwmy6XJN19encfkWSfJOcledNO/AoArHECIADr0aeS3JDk+VW1a1U9IclhC46/M8kzq+rQqrpNkpffdKC7b8wkJL22qu6cJFW1X1X99M4UNDx85VVJjujuC1f4td+pqt2q6qFJfiaTexkXu10mgfXKqtojC36XqrpLVf3sECSvzWSp6vd25vcAYG0TAAFYd7r7uiRPyOThMN/KZBnkexYcPy3J65J8NMkFw8+FXjK0f3pYVvnhbN89fkv5vSR3SnJGVV0zfE646WBVnbPoCZ2XDLVvTfK2JMd293lLnPd1SW6dyczlpzNZrnqTH8pkhnBrkisyuTfwuTv5ewCwhtX33x4BAADAemUGEAAAYCQEQACYkmEZ5zVLfLx8HYAfCJaAAgAAjIQZQAAAgJHYdd4FzMKee+7ZBx544LzLAAAAmIszzzzzm9291+L2dRkADzzwwGzevHneZQAAAMxFVX11qXZLQAEAAEZCAAQAABgJARAAAGAkBEAAAICREAABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARmLXeRcwFr/zvnPyxa3fnncZAADAFB267+3z8sfda95lrJgZQAAAgJEwA7hK1tJfBQAAgPXJDCAAAMBICIAAAAAjIQACAACMhAAIAAAwEgIgAADASAiAAAAAIyEAAgAAjIQACAAAMBICIAAAwEgIgAAAACMhAAIAAIyEAAgAADASAiAAAMBICIAAAAAjIQACAACMhAAIAAAwEgIgAADASMw1AFbVkVV1flVdUFXHL3H86Kr6QlV9vqo2V9VD5lEnAADAerDrvC5cVbskeUOSI5JsSXJGVZ3S3V9c0O0jSU7p7q6q+yR5Z5JDVr9aAACAtW+eM4CHJbmguy/s7uuSnJzk6IUduvua7u5hd/ckHQAAAHbIPAPgfkkuWrC/ZWj7PlX1c1V1XpIPJHn2KtUGAACw7sxtCWiSWqLt/5vh6+6/S/J3VfWwJK9M8uglT1Z1TJJjkmTDhg1TLHM6XvMvr8l5V5w37zIAAIApOmSPQ/KSw14y7zJWbJ4zgFuSHLBgf/8kW7fVubs/nuTuVbXnNo5v6u6N3b1xr732mm6lAAAA68A8ZwDPSHJwVR2U5OtJnpLkFxd2qKofSfJvw0NgHpBktySXr3qlU7CW/ioAAACsT3MLgN19Q1Udl+T0JLskObG7z6mqY4fjJyR5YpKnV9X1Sb6b5MkLHgoDAADAdqj1mKc2btzYmzdvnncZAAAAc1FVZ3b3xsXtc30RPAAAAKtHAAQAABgJARAAAGAkBEAAAICREAABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARkIABAAAGAkBEAAAYCQEQAAAgJEQAAEAAEZCAAQAABgJARAAAGAkBEAAAICREAABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARkIABAAAGAkBEAAAYCQEQAAAgJEQAAEAAEZCAAQAABgJARAAAGAkBEAAAICREAABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARmLXeRcwFh9766Zc+tUL510GAAAwRXe+693yyGceM+8yVswMIAAAwEiYAVwla+mvAgAAwPpkBhAAAGAkBEAAAICRmGsArKojq+r8qrqgqo5f4vjTquoLw+efq+q+86gTAABgPZhbAKyqXZK8IclRSQ5N8tSqOnRRt68keXh33yfJK5NsWt0qAQAA1o95zgAeluSC7r6wu69LcnKSoxd26O5/7u5vDbufTrL/KtcIAACwbswzAO6X5KIF+1uGtm15TpLTZloRAADAOjbP10DUEm29ZMeqR2YSAB+yzZNVHZPkmCTZsGHDNOoDAABYV+Y5A7glyQEL9vdPsnVxp6q6T5I3Jzm6uy/f1sm6e1N3b+zujXvttdfUiwUAAFjr5hkAz0hycFUdVFW7JXlKklMWdqiqDUnek+SXu/tLc6gRAABg3ZjbEtDuvqGqjktyepJdkpzY3edU1bHD8ROSvCzJnZK8saqS5Ibu3jivmgEAANay6l7ytrs1bePGjb158+Z5lwEAADAXVXXmUpNnc30RPAAAAKtHAAQAABgJARAAAGAkBEAAAICREAABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARkIABAAAGAkBEAAAYCQEQAAAgJEQAAEAAEZCAAQAABgJARAAAGAkBEAAAICREAABAABGYsUBsKp2n2UhAAAAzNbNBsCqOryqvpjk3GH/vlX1xplXBgAAwFStZAbwtUl+OsnlSdLd/5rkYbMsCgAAgOlb0RLQ7r5oUdP3ZlALAAAAM7TrCvpcVFWHJ+mq2i3J8zMsBwUAAGDtWMkM4LFJnpdkvyRbktxv2AcAAGANudkZwO7+ZpKnrUItAAAAzNDNBsCqekuSXtze3c+eSUUAAADMxEruAXz/gu1bJfm5JFtnUw4AAACzspIloO9euF9Vb0/y4ZlVBAAAwEys6DUQixycZMO0CwEAAGC2VnIP4NWZ3ANYw89LkrxkxnUBAAAwZStZAnq71SgEAACA2dpmAKyqByz3xe7+7PTLAQAAYFaWmwH842WOdZKfnHItAAAAzNA2A2B3P3I1CwEAAGC2VvIewFTVvZMcmsl7AJMk3f1XsyoKAACA6VvJU0BfnuQRmQTAU5McleQTSQRAAACANWQl7wF8UpJHJbmku5+V5L5JbjnTqgAAAJi6lQTA73b3jUluqKrbJ7k0yd1mWxYAAADTtpJ7ADdX1R2SvCnJmUmuSfIvsywKAACA6dvmDGBV/VlVHd7dz+3uK7v7hCRHJHnGsBR0p1XVkVV1flVdUFXHL3H8kKr6VFVdW1UvnsY1AQAAxmq5GcAvJ/njqtonyTuSvL27Pz+tC1fVLknekEmo3JLkjKo6pbu/uKDbFUmen+Tx07ouAADAWG1zBrC7/7S7H5Tk4ZkEsbdU1blV9bKquscUrn1Ykgu6+8Luvi7JyUmOXlTDpd19RpLrp3A9AACAUbvZh8B091e7+zXdff8kv5jk55KcO4Vr75fkogX7W4Y2AAAAZuBmA2BV3aKqHldVb0tyWpIvJXniFK5dS7T1Dp+s6piq2lxVmy+77LKdKAsAAGB92uY9gFV1RJKnJnlsJk/9PDnJMd39nSlde0uSAxbs759k646erLs3JdmUJBs3btzhIAkAALBeLfcQmJcm+dskL+7uK2Zw7TOSHFxVByX5epKnZLLEFAAAgBnYZgDs7kfO8sLdfUNVHZfk9CS7JDmxu8+pqmOH4ydU1d5JNie5fZIbq+oFSQ7t7m/PsjYAAID1aCUvgp+Z7j41yamL2k5YsH1JJktD177Tjk8uOWveVQAAANO0948lR7163lWs2M0+BAYAAID14WZnAKvqNd39kptr42asob8KAAAA69NKZgCPWKLtqGkXAgAAwGwt9xqIX0ny3CR3q6ovLDh0uySfnHVhAAAATNdyS0D/NpMXv/+PJMcvaL96Rq+FAAAAYIaWew3EVUmuSvLUqtolyV2G/retqtt299dWqUYAAACmYCUPgTkuySuSfCPJjUNzJ7nP7MoCAABg2lbyHsAXJLlnd18+41oAAACYoZU8BfSiTJaCAgAAsIYt9xTQXx82L0zyD1X1gSTX3nS8u/9kxrUBAAAwRcstAb3d8PNrw2e34QMAAMAatNxTQH9nNQsBAABgtlbyFND3ZfLUz4WuSrI5yV909/+ZRWEAAABM10oeAnNhkmuSvGn4fDuTV0LcY9gHAABgDVjJayDu390PW7D/vqr6eHc/rKrOmVVhAAAATNdKZgD3qqoNN+0M23sOu9fNpCoAAACmbiUzgC9K8omq+rckleSgJM+tqt2TnDTL4gAAAJiemw2A3X1qVR2c5JBMAuB5Cx788roZ1gYAAMAULfci+J/s7o9W1RMWHbpbVaW73zPj2gAAAJii5WYAH57ko0ket8SxTiIAAgAArCHLvQj+5cPPZ61eOQAAAMzKzT4FtKruUlV/WVWnDfuHVtVzZl8aAAAA07SS10C8NcnpSfYd9r+U5AUzqgcAAIAZWUkA3LO735nkxiTp7huSfG+mVQEAADB1KwmA36mqO2Xy4JdU1QOTXDXTqgAAAJi6lb4I/pQkd6+qTybZK8mTZloVAAAAU7fcewBfkOSTST6XySsh7pnJi+DP7+7rV6U6AAAApma5JaD7J/nTJJcm+XCSpyW5a5LbrUJdAAAATNly7wF8cZJU1W5JNiY5PMmzk7ypqq7s7kNXp0QAAACmYSX3AN46ye2T/PDw2ZrkrFkWBQAAwPQtdw/gpiT3SnJ1ks8k+eckf9Ld31ql2gAAAJii5e4B3JDklkkuSfL1JFuSXLkKNQEAADADy90DeGRVVSazgIdn8jqIe1fVFUk+1d0vX6UaAQAAmIJl7wHs7k5ydlVdmcnL369K8jNJDksiAAIAAKwhy90D+PxMZv4enOT6TN4J+KkkJ8ZDYAAAANac5WYAD0zyriQv7O6LV6ccAAAAZmW5ewB/fTULAQAAYLaWewooAAAA68hcA2BVHVlV51fVBVV1/BLHq6pePxz/QlU9YB51AgAArAdzC4BVtUuSNyQ5KsmhSZ5aVYcu6nZUkoOHzzFJ/nxViwQAAFhH5jkDeFiSC7r7wu6+LsnJSY5e1OfoJH/VE59Ocoeq2me1CwUAAFgP5hkA90ty0YL9LUPb9vYBAABgBeYZAGuJtt6BPpOOVcdU1eaq2nzZZZftdHEAAADrzTwD4JYkByzY3z/J1h3okyTp7k3dvbG7N+61115TLRQAAGA9mGcAPCPJwVV1UFXtluQpSU5Z1OeUJE8fngb6wCRXeSk9AADAjtnmi+BnrbtvqKrjkpyeZJckJ3b3OVV17HD8hCSnJnlMkguS/EeSZ82rXgAAgLVubgEwSbr71ExC3sK2ExZsd5LnrXZdAAAA69FcXwQPAADA6hEAAQAARkIABAAAGAkBEAAAYCQEQAAAgJEQAAEAAEZCAAQAABiJub4HcEwuedWrcu255827DAAAYIpu+aOHZO+XvnTeZayYGUAAAICRMAO4StbSXwUAAID1yQwgAADASAiAAAAAIyEAAgAAjIQACAAAMBICIAAAwEgIgAAAACMhAAIAAIyEAAgAADASAiAAAMBICIAAAAAjIQACAACMhAAIAAAwErvOu4Cx+Kd3finfvOiaeZcBAABM0Z4H3DYP/YV7zLuMFTMDCAAAMBJmAFfJWvqrAAAAsD6ZAQQAABgJARAAAGAkBEAAAICREAABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARkIABAAAGAkBEAAAYCQEQAAAgJEQAAEAAEZCAAQAABiJuQTAqtqjqj5UVV8eft5xG/1OrKpLq+rs1a4RAABgvZnXDODxST7S3Qcn+ciwv5S3JjlytYoCAABYz+YVAI9OctKwfVKSxy/Vqbs/nuSKVaoJAABgXZtXALxLd1+cJMPPO8+pDgAAgNHYdVYnrqoPJ9l7iUO/PaPrHZPkmCTZsGHDLC4BAACwps0sAHb3o7d1rKq+UVX7dPfFVbVPkkuncL1NSTYlycaNG3tnzwcAALDezGsJ6ClJnjFsPyPJe+dUBwAAwGjMKwC+OskRVfXlJEcM+6mqfavq1Js6VdXbk3wqyT2raktVPWcu1QIAAKwDM1sCupzuvjzJo5Zo35rkMQv2n7qadQEAAKxn85oBBAAAYJUJgAAAACMhAAIAAIyEAAgAADASAiAAAMBICIAAAAAjIQACAACMhAAIAAAwEgIgAADASAiAAAAAIyEAAgAAjIQACAAAMBICIAAAwEgIgAAAACMhAAIAAIyEAAgAADASAiAAAMBICIAAAAAjIQACAACMhAAIAAAwEgIgAADASAiAAAAAIyEAAgAAjIQACAAAMBICIAAAwEgIgAAAACMhAAIAAIyEAAgAADASAiAAAMBICIAAAAAjseu8CxiLK9/3b7lu63fmXQYAADBFu+27e+7wuLvPu4wVMwMIAAAwEmYAV8la+qsAAACwPpkBBAAAGAkBEAAAYCQEQAAAgJEQAAEAAEZCAAQAABiJuQTAqtqjqj5UVV8eft5xiT4HVNXHqurcqjqnqn5tHrUCAACsF/OaATw+yUe6++AkHxn2F7shyYu6+0eTPDDJ86rq0FWsEQAAYF2ZVwA8OslJw/ZJSR6/uEN3X9zdnx22r05ybpL9VqtAAACA9WZeAfAu3X1xMgl6Se68XOeqOjDJ/ZN8ZvalAQAArE+7zurEVfXhJHsvcei3t/M8t03y7iQv6O5vL9PvmCTHJMmGDRu25xIAAACjMLMA2N2P3taxqvpGVe3T3RdX1T5JLt1Gv1tkEv7e1t3vuZnrbUqyKUk2btzYO145AADA+lTdq5+VquoPk1ze3a+uquOT7NHdv7moT2Vyf+AV3f2C7Tz/ZUm+Oq16p2jPJN+cdxGsW8YXs2R8MWvGGLNkfDFLP6jj667dvdfixnkFwDsleWeSDUm+luTnu/uKqto3yZu7+zFV9ZAk/5TkrCQ3Dl99aXefuuoFT0lVbe7ujfOug/XJ+GKWjC9mzRhjlowvZmmtja+ZLQFdTndfnuRRS7RvTfKYYfsTSWqVSwMAAFi35vUUUAAAAFaZALi6Ns27ANY144tZMr6YNWOMWTK+mKU1Nb7mcg8gAAAAq88MIAAAwEgIgKugqo6sqvOr6oLhtRewXarqgKr6WFWdW1XnVNWvDe17VNWHqurLw887LvjObw1j7vyq+un5Vc9aUVW7VNXnqur9w77xxdRU1R2q6l1Vdd7w37IHGWNMS1W9cPj38eyqentV3cr4YmdU1YlVdWlVnb2gbbvHVFX9eFWdNRx7/fCqu7kSAGesqnZJ8oYkRyU5NMlTq+rQ+VbFGnRDkhd1948meWCS5w3j6PgkH+nug5N8ZNjPcOwpSe6V5MgkbxzGIizn15Kcu2Df+GKa/jTJB7v7kCT3zWSsGWPstKraL8nzk2zs7nsn2SWT8WN8sTPemsn4WGhHxtSfJzkmycHDZ/E5V50AOHuHJbmguy/s7uuSnJzk6DnXxBrT3Rd392eH7asz+T9O+2Uylk4aup2U5PHD9tFJTu7ua7v7K0kuyGQswpKqav8kj03y5gXNxhdTUVW3T/KwJH+ZJN19XXdfGWOM6dk1ya2ratckt0myNcYXO6G7P57kikXN2zWmqmqfJLfv7k/15MErf7XgO3MjAM7efkkuWrC/ZWiDHVJVBya5f5LPJLlLd1+cTEJikjsP3Yw7ttfrkvxmkhsXtBlfTMvdklyW5C3DMuM3V9XuMcaYgu7+epI/SvK1JBcnuaq7/z7GF9O3vWNqv2F7cftcCYCzt9Q6X49eZYdU1W2TvDvJC7r728t1XaLNuGNJVfUzSS7t7jNX+pUl2owvlrNrkgck+fPuvn+S72RYOrUNxhgrNtyHdXSSg5Lsm2T3qvql5b6yRJvxxc7Y1pj6gRxrAuDsbUlywIL9/TNZlgDbpapukUn4e1t3v2do/sawvCDDz0uHduOO7fHgJD9bVf+eyTL1n6yqv4nxxfRsSbKluz8z7L8rk0BojDENj07yle6+rLuvT/KeJIfH+GL6tndMbRm2F7fPlQA4e2ckObiqDqqq3TK5QfSUOdfEGjM8Meovk5zb3X+y4NApSZ4xbD8jyXsXtD+lqm5ZVQdlctPxv6xWvawt3f1b3b1/dx+YyX+jPtrdvxTjiynp7kuSXFRV9xyaHpXkizHGmI6vJXlgVd1m+PfyUZncK298MW3bNaaGZaJXV9UDh7H59AXfmZtd513AetfdN1TVcUlOz+SpVCd29zlzLou158FJfjnJWVX1+aHtpUleneSdVfWcTP4B/Pkk6e5zquqdmfwfrBuSPK+7v7fqVbPWGV9M068medvwx9ALkzwrkz9EG2PslO7+TFW9K8lnMxkvn0uyKcltY3yxg6rq7UkekWTPqtqS5OXZsX8XfyWTJ4reOslpw2euavJAGgAAANY7S0ABAABGQgAEAAAYCQEQAABgJARAAACAkRAAAQAARkIABGBUqupOVfX54XNJVX192L6mqt44g+vds6r+YbjGuVW1aWi/X1U9ZtrXA4DleA8gAKPS3ZcnuV+SVNUrklzT3X80w0u+Pslru/u9wzV/bGi/X5KNSU6d4bUB4PuYAQSAJFX1iKp6/7D9iqo6qar+vqr+vaqeUFV/UFVnVdUHq+oWQ78fr6p/rKozq+r0qtpniVPvk2TLTTvdfdbwMvTfTfLkYWbwyVW1e1WdWFVnVNXnquro4RrPrKr3Dtc9v6pePvv/NQBYrwRAAFja3ZM8NsnRSf4myce6+8eSfDfJY4cQ+D+TPKm7fzzJiUl+f4nzvDbJR6vqtKp6YVXdobuvS/KyJO/o7vt19zuS/HaSj3b3f0nyyCR/WFW7D+c4LMnTMpk1/Pmq2jij3xmAdc4SUABY2mndfX1VnZVklyQfHNrPSnJgknsmuXeSD1VVhj4XLz5Jd7+lqk5PcmQmYfK/VdV9l7jeTyX52ap68bB/qyQbhu0PDUtXU1XvSfKQJJt3+jcEYHQEQABY2rVJ0t03VtX13d1D+42Z/PtZSc7p7gfd3Im6e2smM4QnVtXZmQTHxSrJE7v7/O9rrPqJJL2o7+J9AFgRS0ABYMecn2SvqnpQklTVLarqXos7VdWRC+4Z3DvJnZJ8PcnVSW63oOvpSX61hunEqrr/gmNHVNUeVXXrJI9P8skZ/D4AjIAACAA7YLiP70lJXlNV/5rk80kOX6LrTyU5e+hzepLf6O5LknwsyaE3PQQmySuT3CLJF4ZZwlcuOMcnkvz1cI13d7flnwDskPrPFS0AwA+aqnpmko3dfdy8awFg7TMDCAAAMBJmAAEAAEbCDCAAAMBICIAAAAAjIQACAACMhAAIAAAwEgIgAADASAiAAAAAI/F/AbaCuJI4dUKSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAFNCAYAAABR3QEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiIUlEQVR4nO3deZxlZX3n8c93utmkRUCWhoYWNI2AG5oSicYVSWiMNhoTMS5onOmYiFt0hOAYNGYYyBgNZjRMB1EcDUjUDGBoCaLijjRu7IsYpeluVpFFZJHf/HEPsayprr7dde891D2f9+tVrzrnOU+d8yt4XhTf+zznnFQVkiRJkqTx95/aLkCSJEmSNBoGQEmSJEnqCAOgJEmSJHWEAVCSJEmSOsIAKEmSJEkdYQCUJEmSpI4wAEqS9BCW5JlJruyz73OSrB52TZKkucsAKEnqjCSV5DcequebTlV9taoeO4hzJflYkr8exLkkSXOTAVCSJEmSOsIAKEmac5Lsk+TLSW5LcmmSFzXtX07ynyf1e02SrzXbX2mav5/kziQve3DJZJKjk9yc5N+TvGLSz2/U+abUuGWSu5Ps0Oz/tyT3J9mm2f/rJH/XbG+R5H1JfpLkhiQnJtmqOfZryzqTPCXJd5PckeSfk3xq6qxekrcluTHJ2iSvbdqWA68A3tHUe9Ym/wuQJM1ZBkBJ0pySZDPgLODfgJ2ANwKfTDLjMsmqelaz+aSqWlBVn2r2FwI7AIuAw4EVGzrXBs734PFfABcCz26angX8GHjGpP3zm+3jgb2A/YDfaGr5y6nXTLI58C/Ax4DtgVOBF0/pthB4RHOO1wEfSrJdVa0APgn8TVPvCzf0O0qSxo8BUJI01xwALACOq6p7q+qLwOeAl8/inO+qqnuq6nzgX4E/HECd0At4z04yH3gi8MFmf0vgqcBXkwT4L8Bbq+rWqroDOBY4bJrzHQDMBz5YVfdV1WeBb0/pcx/wV83xs4E7gYHcQyhJmvvmt12AJEkbaVfguqp6YFLbj+nNeG2Kn1bVXVPOteumFjfF+cD7gacAFwPnAh+hF+Suqaqbk+wEPAy4qJcFAQgwb5rz7QpcX1U1qe26KX1uqar7J+3/nF5gliTJGUBJ0pyzBtg9yeS/YYuB64G76IWpBy3s43zbJdl6yrnWNNubcr7JvkFv9u3FwPlVdVlz/hfwq+WfNwN3A4+rqm2br0dU1XShbS2wKJOSIrD7RtRTG+4iSRpnBkBJ0lxzAb1g9o4kmyV5DvBC4DTge8BLkjyseT3D66b87A3Ao6c553uSbJ7kmcDvAf/ctG/q+QCoqp8DFwFv4FeB7xvAnzy438xk/iPwgWY2kCSLkvzuNKf8JvBL4Igk85MsA/Zf3/WnMWO9kqTxZwCUJM0pVXUv8CJgKb3Zsw8Dr66qK4APAPfSCzqn0HvoyWTvBk5pnh764H1+64Cf0pv1+yTw+uZcbOz5kixunrC5eFKf84HN+NW9eucDDwe+MqnPkcA1wLeS3A58gWnu22t+95fQC6K3Aa+kd//jPdP9s5rGR4B9m3r/b58/I0kaI/n12wgkSeqOZvbwE1W1W8ulbLIkFwAnVtVH265FkvTQ5wygJElzSJJnJ1nYLAE9nN7TRT/fdl2SpLnBp4BKkjS3PBY4nd6TPX8IvLSq1rZbkiRprnAJqCRJkiR1hEtAJUmSJKkjDICSJEmS1BFjeQ/gDjvsUHvssUfbZUiSJElSKy666KKbq2rHqe1jGQD32GMPVq1a1XYZkiRJktSKJD+ert0loJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR1hAJQkSZKkjjAASpIkSVJHGAAlSZIkqSMMgJIkSZLUEfPbLqAr1h17LPdcfkXbZUiSJEkaoC322ZuFRx/ddhl9cwZQkiRJkjrCGcARmUufCkiSJEkaT84ASpIkSVJHGAAlSZIkqSMMgJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR3hewBH5KPvPprb161puwxJkiRJA7TNwl157buPbbuMvjkDKEmSJEkd4QzgiMylTwUkSZIkjSdnACVJkiSpI1qdAUxyMHACMA84qaqOm3J8GfBe4AHgfuAtVfW1kRc6ALed9UPuXXNX22VIkiRJGqDNd92abV/4mLbL6FtrATDJPOBDwEHAauDCJGdW1WWTup0HnFlVleSJwOnA3qOvVpIkSZLmvjZnAPcHrqmqawGSnAYsA/4jAFbVnZP6bw3USCscoLn0qYAkSZKk8dTmPYCLgOsm7a9u2n5NkhcnuQL4V+CPR1SbJEmSJI2dNgNgpmn7/2b4qupfqmpv4FB69wNOf7JkeZJVSVbddNNNg6tSkiRJksZEmwFwNbD7pP3dgPW+Kb2qvgI8JskO6zm+oqomqmpixx13HGylkiRJkjQG2gyAFwJLkuyZZHPgMODMyR2S/EaSNNtPATYHbhl5pZIkSZI0Blp7CExV3Z/kCOAceq+BOLmqLk3y+ub4icDvA69Och9wN/CyqpqzD4KRJEmSpDZlHPPUxMRErVq1qu0yJEmSJKkVSS6qqomp7W0uAZUkSZIkjZABUJIkSZI6wgAoSZIkSR1hAJQkSZKkjjAASpIkSVJHGAAlSZIkqSMMgJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR1hAJQkSZKkjjAASpIkSVJHzG+7gK5YuXIl69ata7sMSZIkSQO0cOFCli5d2nYZfXMGUJIkSZI6whnAEZlLnwpIkiRJGk/OAEqSJElSRxgAJUmSJKkjDICSJEmS1BEGQEmSJEnqCAOgJEmSJHWEAVCSJEmSOsIAKEmSJEkdYQCUJEmSpI4wAEqSJElSR8xv8+JJDgZOAOYBJ1XVcVOOvwI4stm9E/jTqvr+aKscjHXHHss9l1/RdhmSJEmSBmiLffZm4dFHt11G31oLgEnmAR8CDgJWAxcmObOqLpvU7UfAs6vqp0mWAiuAp42+2tlb+6hv8fNHXdd2GZIkSZIG6GHcxsK2i9gIbc4A7g9cU1XXAiQ5DVgG/EcArKpvTOr/LWC3kVY4QFs/9ak8cOeCtsuQJEmSNEBbL9in7RI2SpsBcBEweUpsNTPP7r0OWDnUioZor73e1XYJkiRJkjquzQCYadpq2o7Jc+kFwN9e78mS5cBygMWLFw+iPkmSJEkaK20GwNXA7pP2dwPWTO2U5InAScDSqrplfSerqhX07hFkYmJi2iDZpvcd9y3uufkXbZchSZIkaYC22GFL3n7UAW2X0bc2XwNxIbAkyZ5JNgcOA86c3CHJYuCzwKuq6qoWapQkSZKksdHaDGBV3Z/kCOAceq+BOLmqLk3y+ub4icBfAo8EPpwE4P6qmmir5tmYS58KSJIkSRpPqXrIrZactYmJiVq1alXbZUiSJElSK5JcNN3kWZtLQCVJkiRJI2QAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjpiftsFdMXx3z6eK269ou0yJEmSJA3Q3tvvzZH7H9l2GX1zBlCSJEmSOsIZwBGZS58KSJIkSRpPzgBKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6oj5bRfQFV89/Spuvu7OtsuQJEmSNEA77L6AZ/7hXm2X0TdnACVJkiSpI1qdAUxyMHACMA84qaqOm3J8b+CjwFOAd1bV+0Zf5WDMpU8FJEmSJI2n1gJgknnAh4CDgNXAhUnOrKrLJnW7FXgTcOjoK5QkSZKk8dLmEtD9gWuq6tqquhc4DVg2uUNV3VhVFwL3tVGgJEmSJI2TNgPgIuC6SfurmzZJkiRJ0hC0GQAzTVtt8smS5UlWJVl10003zaIsSZIkSRpPbQbA1cDuk/Z3A9Zs6smqakVVTVTVxI477jjr4iRJkiRp3LT5FNALgSVJ9gSuBw4D/qjFeobqSx9bwY0/vrbtMiRJkiQN0E6PejTPfc3ytsvoW2sBsKruT3IEcA6910CcXFWXJnl9c/zEJAuBVcA2wANJ3gLsW1W3t1W3JEmSJM1Vqdrk2+4esiYmJmrVqlVtlyFJkiRJrUhyUVVNTG1v9UXwnbLyKFh3cdtVSJIkSRqkhU+Apce1XUXf2nwIjCRJkiRphPqeAUyydVXdNcxixtoc+lRAkiRJ0nja4AxgkqcnuQy4vNl/UpIPD70ySZIkSdJA9bME9APA7wK3AFTV94FnDbMoSZIkSdLg9XUPYFVdN6Xpl0OoRZIkSZI0RP3cA3hdkqcDlWRz4E00y0ElSZIkSXNHPzOArwfeACwCVgP7NfuSJEmSpDlkgzOAVXUz8IoR1CJJkiRJGqINBsAkHwVqantV/fFQKpIkSZIkDUU/9wB+btL2lsCLgTXDKUeSJEmSNCz9LAH9zOT9JKcCXxhaRWPqXVev5pI77267DEmSJEkD9PgFW/HeJbu1XUbf+noNxBRLgMWDLkSSJEmSNFz93AN4B717ANN8XwccOeS6xs5c+lRAkiRJ0njqZwnow0dRiCRJkiRpuNYbAJM8ZaYfrKrvDL4cSZIkSdKwzDQD+LczHCvgeQOuRZIkSZI0ROsNgFX13FEWIkmSJEkarn7eA0iSxwP70nsPIABV9fFhFSVJkiRJGrx+ngJ6DPAcegHwbGAp8DXAAChJkiRJc0g/7wF8KXAgsK6qXgs8CdhiqFVJkiRJkgaunwB4d1U9ANyfZBvgRuDRwy1LkiRJkjRo/dwDuCrJtsA/AhcBdwLfHmZRkiRJkqTBm+k9gP8L+Keq+rOm6cQknwe2qaofjKQ6SZIkSdLAzDQDeDXwt0l2AT4FnFpV3xtJVZIkSZKkgZvpPYAnACckeRRwGPDRJFsCpwKnVdVVs714koOBE4B5wElVddyU42mOHwL8HHhNVX1nttdtw3vOupTL1tzedhmSJEmSBmjfXbfhmBc+ru0y+rbBh8BU1Y+r6viqejLwR8CLgctne+Ek84AP0XutxL7Ay5PsO6XbUmBJ87Uc+IfZXleSJEmSuqqf9wBuBhxMbxbwQOB84D0DuPb+wDVVdW1zndOAZcBlk/osAz5eVQV8K8m2SXapqrUDuP5IzaVPBSRJkiSNp5keAnMQ8HLgBfSe+nkasLyq7hrQtRcB103aXw08rY8+i4A5FwBv+/uPc++t89ouQ5IkSdIAbb79L9n2ja9uu4y+zTQDeDTwT8Dbq+rWIVw707TVJvTpdUyW01smyuLFi2dX2RCsvf1utrp3y7bLkCRJkjRAt9z+C7Ztu4iNMNNDYJ475GuvBnaftL8bsGYT+gBQVSuAFQATExPThsQ2nf7E3/YhMJIkSdKY2XfXbTim7SI2Qj8vgh+WC4ElSfYErqd3j+EfTelzJnBEc3/g04CfzcX7/8B7ACVJkiS1r7UAWFX3JzkCOIfeayBOrqpLk7y+OX4icDa9V0BcQ+81EK9tq15JkiRJmuv6eQro8VV15IbaNkVVnU0v5E1uO3HSdgFvmO11JEmSJEl9vAcQOGiatqWDLkSSJEmSNFwzvQbiT4E/Ax6d5AeTDj0c+PqwC5MkSZIkDdZMS0D/CVgJ/A/gqEntdwzptRCSJEmSpCGa6TUQPwN+Brw8yTxg56b/giQLquonI6pRkiRJkjQA/TwE5gjg3cANwANNcwFPHF5ZkiRJkqRB6+c1EG8BHltVtwy5FkmSJEnSEPXzFNDr6C0FlSRJkiTNYTM9BfTPm81rgS8n+VfgngePV9X7h1ybJEmSJGmAZloC+vDm+0+ar82bL0mSJEnSHDTTU0DfM8pCJEmSJEnD1c9TQM+i99TPyX4GrAL+d1X9YhiFjZuvnn4VN193Z9tlSJIkSRqgHXZfwDP/cK+2y+hbP08BvRbYETi12X8ZvVdC7AX8I/Cq4ZQ2Xv753pP50SN+2HYZkiRJkgZoz3sfwzM5ru0y+tZPAHxyVT1r0v5ZSb5SVc9KcumwChs3i/bajjtuXdB2GZIkSZIGaNH227VdwkbpJwDumGRxVf0EIMliYIfm2L1Dq2zM7H/Zduzx453bLkOSJEnSAO30qO1g/7ar6F8/AfBtwNeS/BAIsCfwZ0m2Bk4ZZnGSJEmSpMFJ1dTnu0zTKdkC2JteALziof7gl4mJiVq1alXbZUiSJElSK5JcVFUTU9tnehH886rqi0leMuXQo5NQVZ8deJVj7F1Xr+aSO+9uuwxJkiRJA/T4BVvx3iW7tV1G32ZaAvps4IvAC6c5VoABUJIkSZLmkJleBH9M8/21oytnfM2lTwUkSZIkjaf/tKEOSXZO8pEkK5v9fZO8bvilSZIkSZIGaYMBEPgYcA6wa7N/FfCWIdUjSZIkSRqSfgLgDlV1OvAAQFXdD/xyqFVJkiRJkgaunwB4V5JH0nvwC0kOAH421KokSZIkSQPX74vgzwQek+TrwI7AS4dalSRJkiRp4GZ6D+BbgK8D36X3SojH0nsR/JVVdd9IqpMkSZIkDcxMS0B3A04AbgS+ALwCeBTw8NleNMn2Sc5NcnXzfbv19Ds5yY1JLpntNSVJkiSp69YbAKvq7VX1dGAhcDRwK/DHwCVJLpvldY8CzquqJcB5zf50PgYcPMtrSZIkSZLo7yEwWwHbAI9ovtYAF8zyusuAU5rtU4BDp+tUVV+hFzwlSZIkSbM00z2AK4DHAXfQC3zfAN5fVT8dwHV3rqq1AFW1NslOAzinJEmSJGkGMz0FdDGwBXA1cD2wGrit3xMn+QK95aNTvXMj6utbkuXAcoDFixcP4xKSJEmSNKetNwBW1cFJQm8W8On0Xgfx+CS3At+sqmNmOnFVPX99x5LckGSXZvZvF3oPmpmVqloBrACYmJio2Z5PkiRJksbNjPcAVs8lwNnASnqvhXgM8OZZXvdM4PBm+3DgjFmeT5IkSZK0ATPdA/gmejN/zwDuoxf+vgmcDFw8y+seB5ye5HXAT4A/aK65K3BSVR3S7J8KPAfYIclq4Jiq+sgsr92KlStXsm7durbLkCRJkjRACxcuZOnSpW2X0beZ7gHcA/g08NYHH9gyKFV1C3DgNO1rgEMm7b98kNeVJEmSpC6b6R7APx9lIeNuLn0qIEmSJGk8zTQDqAG67awfcu+au9ouQ5IkSdIAbb7r1mz7wse0XUbf+nkRvCRJkiRpDDgDOCJz6VMBSZIkSePJGUBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOaCUAJtk+yblJrm6+bzdNn92TfCnJ5UkuTfLmNmqVJEmSpHHR1gzgUcB5VbUEOK/Zn+p+4G1VtQ9wAPCGJPuOsEZJkiRJGittBcBlwCnN9inAoVM7VNXaqvpOs30HcDmwaFQFSpIkSdK4aSsA7lxVa6EX9ICdZuqcZA/gycAFwy9NkiRJksbT/GGdOMkXgIXTHHrnRp5nAfAZ4C1VdfsM/ZYDywEWL168MZeQJEmSpE4YWgCsquev71iSG5LsUlVrk+wC3LiefpvRC3+frKrPbuB6K4AVABMTE7XplUuSJEnSeGprCeiZwOHN9uHAGVM7JAnwEeDyqnr/CGuTJEmSpLHUVgA8DjgoydXAQc0+SXZNcnbT5xnAq4DnJfle83VIO+VKkiRJ0tw3tCWgM6mqW4ADp2lfAxzSbH8NyIhLkyRJkqSx1dYMoCRJkiRpxAyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpIwyAkiRJktQRBkBJkiRJ6ggDoCRJkiR1hAFQkiRJkjrCAChJkiRJHWEAlCRJkqSOMABKkiRJUkcYACVJkiSpI1oJgEm2T3Jukqub79tN02fLJN9O8v0klyZ5Txu1SpIkSdK4aGsG8CjgvKpaApzX7E91D/C8qnoSsB9wcJIDRleiJEmSJI2XtgLgMuCUZvsU4NCpHarnzmZ3s+arRlKdJEmSJI2htgLgzlW1FqD5vtN0nZLMS/I94Ebg3Kq6YHQlSpIkSdJ4mT+sEyf5ArBwmkPv7PccVfVLYL8k2wL/kuTxVXXJeq63HFgOsHjx4o0vWJIkSZLG3NACYFU9f33HktyQZJeqWptkF3ozfDOd67YkXwYOBqYNgFW1AlgBMDEx4VJRSZIkSZqirSWgZwKHN9uHA2dM7ZBkx2bmjyRbAc8HrhhVgZIkSZI0btoKgMcBByW5Gjio2SfJrknObvrsAnwpyQ+AC+ndA/i5VqqVJEmSpDEwtCWgM6mqW4ADp2lfAxzSbP8AePKIS5MkSZKksdXWDKAkSZIkacQMgJIkSZLUEQZASZIkSeoIA6AkSZIkdYQBUJIkSZI6opWngHbRumOP5Z7LfY2hJEmSNE622GdvFh59dNtl9M0ZQEmSJEnqCGcAR2QufSogSZIkaTw5AyhJkiRJHeEM4IhcddV7uePOy9suQ5IkSdIAPXzBPuy117vaLqNvzgBKkiRJUkc4Azgic+lTAUmSJEnjyRlASZIkSeoIA6AkSZIkdYQBUJIkSZI6wgAoSZIkSR3hQ2BG5PhvH88Vt17RdhmSJEmSBmjv7ffmyP2PbLuMvjkDKEmSJEkd4QzgiMylTwUkSZIkjSdnACVJkiSpI5wBHJWVR8G6i9uuQpIkSdIgLXwCLD2u7Sr65gygJEmSJHWEM4CjMoc+FZAkSZI0npwBlCRJkqSOMABKkiRJUke0EgCTbJ/k3CRXN9+3m6HvvCTfTfK5UdYoSZIkSeOmrRnAo4DzqmoJcF6zvz5vBi4fSVWSJEmSNMbaCoDLgFOa7VOAQ6frlGQ34AXASaMpS5IkSZLGV1sBcOeqWgvQfN9pPf3+DngH8MCI6pIkSZKksTW010Ak+QKwcJpD7+zz538PuLGqLkrynD76LweWAyxevLj/QiVJkiSpI4YWAKvq+es7luSGJLtU1dokuwA3TtPtGcCLkhwCbAlsk+QTVfXK9VxvBbACYGJiomb/G0iSJEnSeGlrCeiZwOHN9uHAGVM7VNVfVNVuVbUHcBjwxfWFP0mSJEnShrUVAI8DDkpyNXBQs0+SXZOc3VJNkiRJkjTWhrYEdCZVdQtw4DTta4BDpmn/MvDloRcmSZIkSWMsVeN3u1ySm4Aft13HNHYAbm67CI0tx5eGyfGlYXOMaZgcXxqmh+r4elRV7Ti1cSwD4ENVklVVNdF2HRpPji8Nk+NLw+YY0zA5vjRMc218tXUPoCRJkiRpxAyAkiRJktQRBsDRWtF2ARprji8Nk+NLw+YY0zA5vjRMc2p8eQ+gJEmSJHWEM4CSJEmS1BEGwBFIcnCSK5Nck+SotuvR3JNk9yRfSnJ5kkuTvLlp3z7JuUmubr5vN+ln/qIZc1cm+d32qtdckWReku8m+Vyz7/jSwCTZNsmnk1zR/LfstxxjGpQkb23+Pl6S5NQkWzq+NBtJTk5yY5JLJrVt9JhK8ptJLm6OfTBJRv27TGUAHLIk84APAUuBfYGXJ9m33ao0B90PvK2q9gEOAN7QjKOjgPOqaglwXrNPc+ww4HHAwcCHm7EozeTNwOWT9h1fGqQTgM9X1d7Ak+iNNceYZi3JIuBNwERVPR6YR2/8OL40Gx+jNz4m25Qx9Q/AcmBJ8zX1nCNnABy+/YFrquraqroXOA1Y1nJNmmOqam1VfafZvoPe/zgtojeWTmm6nQIc2mwvA06rqnuq6kfANfTGojStJLsBLwBOmtTs+NJAJNkGeBbwEYCqureqbsMxpsGZD2yVZD7wMGANji/NQlV9Bbh1SvNGjakkuwDbVNU3q/fglY9P+pnWGACHbxFw3aT91U2btEmS7AE8GbgA2Lmq1kIvJAI7Nd0cd9pYfwe8A3hgUpvjS4PyaOAm4KPNMuOTkmyNY0wDUFXXA+8DfgKsBX5WVf+G40uDt7FjalGzPbW9VQbA4Ztuna+PXtUmSbIA+Azwlqq6faau07Q57jStJL8H3FhVF/X7I9O0Ob40k/nAU4B/qKonA3fRLJ1aD8eY+tbch7UM2BPYFdg6yStn+pFp2hxfmo31jamH5FgzAA7famD3Sfu70VuWIG2UJJvRC3+frKrPNs03NMsLaL7f2LQ77rQxngG8KMm/01um/rwkn8DxpcFZDayuqgua/U/TC4SOMQ3C84EfVdVNVXUf8Fng6Ti+NHgbO6ZWN9tT21tlABy+C4ElSfZMsjm9G0TPbLkmzTHNE6M+AlxeVe+fdOhM4PBm+3DgjEnthyXZIsme9G46/vao6tXcUlV/UVW7VdUe9P4b9cWqeiWOLw1IVa0Drkvy2KbpQOAyHGMajJ8AByR5WPP38kB698o7vjRoGzWmmmWidyQ5oBmbr570M62Z33YB466q7k9yBHAOvadSnVxVl7ZcluaeZwCvAi5O8r2m7WjgOOD0JK+j9wfwDwCq6tIkp9P7H6z7gTdU1S9HXrXmOseXBumNwCebD0OvBV5L74Nox5hmpaouSPJp4Dv0xst3gRXAAhxf2kRJTgWeA+yQZDVwDJv2d/FP6T1RdCtgZfPVqvQeSCNJkiRJGncuAZUkSZKkjjAASpIkSVJHGAAlSZIkqSMMgJIkSZLUEQZASZIkSeoIA6AkqVOSPDLJ95qvdUmub7bvTPLhIVzvsUm+3Fzj8iQrmvb9khwy6OtJkjQT3wMoSeqUqroF2A8gybuBO6vqfUO85AeBD1TVGc01n9C07wdMAGcP8dqSJP0aZwAlSQKSPCfJ55rtdyc5Jcm/Jfn3JC9J8jdJLk7y+SSbNf1+M8n5SS5Kck6SXaY59S7A6gd3quri5mXofwW8rJkZfFmSrZOcnOTCJN9Nsqy5xmuSnNFc98okxwz/n4YkaVwZACVJmt5jgBcAy4BPAF+qqicAdwMvaELg3wMvrarfBE4G/vs05/kA8MUkK5O8Ncm2VXUv8JfAp6pqv6r6FPBO4ItV9VTgucD/TLJ1c479gVfQmzX8gyQTQ/qdJUljziWgkiRNb2VV3ZfkYmAe8Pmm/WJgD+CxwOOBc5PQ9Fk79SRV9dEk5wAH0wuTf5LkSdNc73eAFyV5e7O/JbC42T63WbpKks8Cvw2smvVvKEnqHAOgJEnTuwegqh5Icl9VVdP+AL2/nwEurarf2tCJqmoNvRnCk5NcQi84ThXg96vqyl9rTJ4G1JS+U/clSeqLS0AlSdo0VwI7JvktgCSbJXnc1E5JDp50z+BC4JHA9cAdwMMndT0HeGOa6cQkT5507KAk2yfZCjgU+PoQfh9JUgcYACVJ2gTNfXwvBY5P8n3ge8DTp+n6O8AlTZ9zgP9aVeuALwH7PvgQGOC9wGbAD5pZwvdOOsfXgP/TXOMzVeXyT0nSJsmvVrRIkqSHmiSvASaq6oi2a5EkzX3OAEqSJElSRzgDKEmSJEkd4QygJEmSJHWEAVCSJEmSOsIAKEmSJEkdYQCUJEmSpI4wAEqSJElSRxgAJUmSJKkj/h+nOuLJU/g8MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##x_range = (99998,100000) to view final weights\n",
    "lab.graph(diff=0,graph_together = False, plot_size = (15,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac518f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_line_graph(losses,window_size = 1000, plot_size = (15,5)) #window_size is the moving average window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
