{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a04cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b445af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NoiseKD import Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a11b24",
   "metadata": {},
   "source": [
    "First hurdle. the embedding layer.  It requires the ints as inputs, not one hot.  i need one hot.  i will also need to rewire the LLM i use to do the same.  hmm.  save the weights, load it into a model that has the same shapes, but accepts one hot arrays, not vocab_indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad448f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout),\n",
    "            num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "\n",
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_length, embedding_dim, class_num, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Define the transformer encoder\n",
    "        self.transformer_encoder = TransformerEncoder(embedding_dim, num_heads, hidden_dim, num_layers, dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(sequence_length*embedding_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        \n",
    "        self.output_layer = nn.Linear(500, class_num)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Input_data is of shape (batch_size, sequence_length)\n",
    "        # Apply embedding layer\n",
    "        #print(input_data.shape)\n",
    "        embedded = self.embedding(input_data)\n",
    "        #print(embedded.shape)\n",
    "        # Pass through the transformer encoder\n",
    "        transformed = self.transformer_encoder(embedded)\n",
    "        #print(transformed.shape) same as input duh: batch x sequence_length x embedding_dim\n",
    "        flattened_tensor = transformed.view(-1,sequence_length*embedding_dim)\n",
    "        f1 = nn.ReLU()(self.fc1(flattened_tensor))\n",
    "        f2 = nn.ReLU()(self.fc2(f1))\n",
    "        out = self.output_layer(f2)\n",
    "        # Apply the output layer\n",
    "        output = F.softmax(out,dim=1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca2a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "num_heads = 8\n",
    "hidden_dim  = 11\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "vocab_size = 80\n",
    "class_num = vocab_size\n",
    "batch_size = 23\n",
    "sequence_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b5a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLM = SimpleLanguageModel(vocab_size, sequence_length, embedding_dim, class_num, num_heads, hidden_dim, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fc6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLanguageModel(\n",
       "  (embedding): Embedding(80, 16)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=11, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=11, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=11, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=11, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=2560, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (output_layer): Linear(in_features=500, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85578ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randint(low=0, high=vocab_size, size=(batch_size, sequence_length))\n",
    "print(input_data.shape)\n",
    "SLM(input_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ba38e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3105922"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c613c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_slm = Teacher(SLM,(sequence_length,)) #don't specify batch!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a25b374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\n",
      "lets try ints!\n"
     ]
    }
   ],
   "source": [
    "teacher_slm.load_state_dict('good_teacher.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('model_state.pth'))\n",
    "#model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4db9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##some of these configs made for more diverse outputs in teachers:\n",
    "config_args = {\"dist_type\" : \"ints\" ##worked well\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 100\n",
    "                      , \"gen_epochs\" : 100\n",
    "                      , \"gen_lr\" : 0.001\n",
    "                      , \"random_shuffle\" : 0.1\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_high_epochs = {\"dist_type\" : \"ints\" ##okay, but not as well as config_args.\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 1000\n",
    "                      , \"gen_epochs\" : 100\n",
    "                      , \"gen_lr\" : 0.001\n",
    "                      , \"random_shuffle\" : 0.1\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_higher_lr = {\"dist_type\" : \"ints\" ##lower was worse.  raise it. 0.003 looks great.  this is the best.\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 2000\n",
    "                      , \"gen_epochs\" : 50\n",
    "                      , \"gen_lr\" :  0.003 ##0.003\n",
    "                      , \"random_shuffle\" : 0.8\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_less_data = {\"dist_type\" : \"ints\" ##worse\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 500\n",
    "                      , \"gen_epochs\" : 100\n",
    "                      , \"gen_lr\" : 0.003\n",
    "                      , \"random_shuffle\" : 0.1\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_high_shuffle = {\"dist_type\" : \"ints\" ##one bar..\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 10_000\n",
    "                      , \"gen_epochs\" : 10\n",
    "                      , \"gen_lr\" : 0.05\n",
    "                      , \"random_shuffle\" : 0.9\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_small_batch = {\"dist_type\" : \"ints\" ##this one was the first to do well.  not just one bar and the rest nearly zero.\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 10_000\n",
    "                      , \"gen_epochs\" : 10\n",
    "                      , \"gen_lr\" : 0.05\n",
    "                      , \"random_shuffle\" : 0.5\n",
    "                      , \"batch_size\" : 10\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_ab = {\"dist_type\" : \"ints\" ##worked well\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 5000\n",
    "                      , \"gen_epochs\" : 200\n",
    "                      , \"gen_lr\" : 0.005\n",
    "                      , \"random_shuffle\" : 0.0\n",
    "                      , \"out_type\" : \"one-hot\" \n",
    "                      , \"dist_type\" : 'hetero'\n",
    "                      , \"alpha\" : 1\n",
    "                      , \"beta\" : 4} #maybe increase epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_slm.configure(**config_ab) #this is dying.  might be time for colab!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f954d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating val data :: 100%|██████████████████| 200/200 [00:04<00:00, 48.19it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = { 'val_train' : \"val\"\n",
    "                      , 'n' : 10_000\n",
    "                      , 'dist_type' : 'ints'\n",
    "                      , 'm' : vocab_size\n",
    "                      , 'std': 1.0\n",
    "                      , 'alpha' : 1\n",
    "                      , 'beta' : 3\n",
    "        }\n",
    "teacher_slm.generate_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb63843",
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(teacher_slm.model.state_dict(), 'good_teacher.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ca1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5425419 ,  0.35136947, -0.03018094, ..., -0.15405135,\n",
       "         1.7438477 , -0.98630935],\n",
       "       [-1.6164193 , -1.8916837 , -0.8887659 , ..., -0.15044953,\n",
       "        -0.22066197, -1.287303  ],\n",
       "       [ 0.34314165,  0.25870025, -0.93632895, ...,  1.0878774 ,\n",
       "         0.89934933, -0.45346054],\n",
       "       ...,\n",
       "       [ 0.64084125, -1.4381758 ,  1.0926732 , ...,  2.0109196 ,\n",
       "         0.51697874, -0.04919771],\n",
       "       [-0.22420782,  1.1749339 ,  0.90297115, ...,  0.2145888 ,\n",
       "        -0.39479327,  0.79994994],\n",
       "       [-0.10181472, -0.19704515,  0.46629068, ..., -0.37408283,\n",
       "         1.2688403 , -0.0953627 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.model.embedding.weight.detach().numpy() #use this to make the matrix, just linear? not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #the code is right, i just need this to be a better dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c7711d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_slm.graph_dataset_dist(val_train = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8154cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(torch.all(teacher_slm.model(teacher_slm.in_test[i]) == teacher_slm.val_targets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6de08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(teacher_slm.model(teacher_slm.in_test[50:100]) == teacher_slm.val_targets[50:100]) ##okay, this is weird.  this works\n",
    "#in test is concatenated the same way as the outputs in KDNoise.  only difference.  doesn't appear to be different.  \n",
    "torch.all(teacher_slm.model(teacher_slm.val_inputs[50:100]) == teacher_slm.val_targets[50:100]) ##yeah, val_inputs and in_test appear to be the same.\n",
    "#torch.all(teacher_slm.model(teacher_slm.in_test[:49]) == teacher_slm.val_targets[:49]) ##this doesn't/.  huh???!!\n",
    "#torch.all(teacher_slm.model(teacher_slm.in_test[:50]) == teacher_slm.model(teacher_slm.val_inputs[:50])) ##okay, these match too\n",
    "#torch.all(teacher_slm.model(teacher_slm.in_test[223:409]) == teacher_slm.model(teacher_slm.val_inputs[223:409])) #these match.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_slm.val_inputs.shape, teacher_slm.val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(teacher_slm.model(teacher_slm.val_inputs[1]) ==  teacher_slm.val_targets[1]) ##torch.allclose doesn't work either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909987b0",
   "metadata": {},
   "source": [
    "so, it looks like it is predicting correctly, but there is something wrong with the batch? they match when you pass in 50, but more, or not at exactly the 50 marks, it doesn't all match.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added teacher_slm.in_test and teacher_slm.dataloader\n",
    "teacher_slm.data_loader\n",
    "x = None\n",
    "y = None\n",
    "for batch_samples in teacher_slm.data_loader:\n",
    "    # Perform inference on each batch\n",
    "    batch_outputs = teacher_slm.model(batch_samples[0])  # Assuming samples are in the first element of the batch\n",
    "    print(batch_samples[0])\n",
    "    x = batch_samples[0]\n",
    "    print(batch_outputs)\n",
    "    y = batch_outputs\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e63715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay, the first 50 match.  do they \n",
    "torch.all(x == teacher_slm.val_inputs[0:50]),torch.all(y == teacher_slm.val_targets[0:50]),torch.all(teacher_slm.model(x) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f7b2a",
   "metadata": {},
   "source": [
    "specify gen outputs.  we need one hots\n",
    "i can do this better than chat gpt lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this function works, it is in LABNET.  \n",
    "def one_hot_last_dim(tensor_shape):\n",
    "    num_classes = tensor_shape[-1]\n",
    "    random_idx = np.random.randint(1, num_classes + 1, size=tensor_shape[:-1])\n",
    "    zero_tensor = np.zeros(tensor_shape, dtype=int)\n",
    "    last_dim_indices = np.arange(num_classes)\n",
    "    zero_tensor[..., :, last_dim_indices] = (random_idx[..., np.newaxis] == last_dim_indices)\n",
    "    return zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fabd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_to_shuffle = 0\n",
    "\n",
    "# Shuffle the tensor along the specified axis\n",
    "shuffled_tensor = np.take(x, np.random.permutation(x.shape[0]), axis=0)\n",
    "\n",
    "print(shuffled_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    random_number = random.random()\n",
    "    print(random_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb166fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is to extract the parts.  we need to take out the embedding layer, make it linear, and then take out the layer before softmax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef060bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "def generate_heteroskedastic_ints(n, alpha, beta, total_classes):\n",
    "    # Generate random values from the beta distribution\n",
    "    values = np.random.beta(alpha, beta, n)\n",
    "    min_value = 0\n",
    "    max_value = total_classes\n",
    "    scaled_values = min_value + (max_value - min_value) * values\n",
    "    \n",
    "    # Round the scaled values to integers\n",
    "    ints = np.round(scaled_values).astype(int)\n",
    "    \n",
    "    return ints\n",
    "\n",
    "# Set your desired alpha and beta values\n",
    "alpha = 1  # Adjust this to control skewness\n",
    "beta = 10  # Adjust this to control skewness\n",
    "\n",
    "# Generate 100 random integers with the specified heteroskedasticity\n",
    "random_integers = generate_heteroskedastic_ints(10_000, alpha, beta, 100)\n",
    "\n",
    "# Print the generated integers\n",
    "print(random_integers)\n",
    "plt.hist(random_integers, bins=20, edgecolor='k')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Random Integers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87621b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heteroskedastic_ints(shape, alpha, beta, total_classes):\n",
    "    # Generate random values from the beta distribution\n",
    "    values = np.random.beta(alpha, beta, shape)\n",
    "    \n",
    "    # Scale the values to integers in the desired range (e.g., 0 to 100)\n",
    "    min_value = 0\n",
    "    max_value = total_classes\n",
    "    scaled_values = min_value + (max_value - min_value) * values\n",
    "    \n",
    "    # Round the scaled values to integers\n",
    "    ints = np.round(scaled_values).astype(int)\n",
    "    \n",
    "    return ints\n",
    "\n",
    "# Set your desired alpha and beta values\n",
    "alpha = 1  # Adjust this to control skewness\n",
    "beta = 1   # Adjust this to control skewness\n",
    "\n",
    "# Specify the shape of the tensor (e.g., b x 200)\n",
    "b = 5\n",
    "shape = (b, 200)\n",
    "\n",
    "# Generate a tensor of random integers with the specified heteroskedasticity\n",
    "random_integers_tensor = generate_heteroskedastic_ints(shape, alpha, beta,20)\n",
    "\n",
    "# Print the generated tensor\n",
    "random_integers_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e56b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
