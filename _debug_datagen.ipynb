{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a04cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b445af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NoiseKD import Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a11b24",
   "metadata": {},
   "source": [
    "First hurdle. the embedding layer.  It requires the ints as inputs, not one hot.  i need one hot.  i will also need to rewire the LLM i use to do the same.  hmm.  save the weights, load it into a model that has the same shapes, but accepts one hot arrays, not vocab_indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad448f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout, batch_first = True),\n",
    "            num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "\n",
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_length, embedding_dim, class_num, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Define the transformer encoder\n",
    "        self.transformer_encoder = TransformerEncoder(embedding_dim, num_heads, hidden_dim, num_layers, dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(sequence_length*embedding_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        \n",
    "        self.output_layer = nn.Linear(500, class_num)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Input_data is of shape (batch_size, sequence_length)\n",
    "        # Apply embedding layer\n",
    "        #print(input_data.shape)\n",
    "        embedded = self.embedding(input_data)\n",
    "        #print(embedded.shape)\n",
    "        # Pass through the transformer encoder\n",
    "        transformed = self.transformer_encoder(embedded)\n",
    "        #print(transformed.shape) #same as input duh: batch x sequence_length x embedding_dim\n",
    "        flattened_tensor = transformed.view(-1,sequence_length*embedding_dim)\n",
    "        f1 = F.relu(self.fc1(flattened_tensor))\n",
    "        \n",
    "        f2 = F.relu(self.fc2(f1))\n",
    "        out = self.output_layer(f2)\n",
    "        # Apply the output layer\n",
    "        output = F.softmax(out) # should be output = F.softmax(out,dim=-1) or output = F.softmax(out,dim=1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca2a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "num_heads = 8\n",
    "hidden_dim  = 11\n",
    "num_layers = 2\n",
    "dropout = 0.1 #tried with zero, same prob...\n",
    "vocab_size = 80\n",
    "class_num = vocab_size\n",
    "batch_size = 23\n",
    "sequence_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b5a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLM = SimpleLanguageModel(vocab_size, sequence_length, embedding_dim, class_num, num_heads, hidden_dim, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fc6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLanguageModel(\n",
       "  (embedding): Embedding(80, 16)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=11, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=11, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=11, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=11, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=2560, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (output_layer): Linear(in_features=500, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85578ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 160])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/zz_5zb251633yqqbh6076p782zzx8q/T/ipykernel_29234/1983935209.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(out) # should be output = F.softmax(out,dim=-1) or output = F.softmax(out,dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randint(low=0, high=vocab_size, size=(batch_size, sequence_length))\n",
    "print(input_data.shape)\n",
    "SLM(input_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ba38e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3105922"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c613c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_slm = Teacher(SLM,(sequence_length,)) #don't specify batch!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a25b374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\n",
      "lets try ints!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/zz_5zb251633yqqbh6076p782zzx8q/T/ipykernel_29234/1983935209.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(out) # should be output = F.softmax(out,dim=-1) or output = F.softmax(out,dim=1)\n"
     ]
    }
   ],
   "source": [
    "teacher_slm.load_state_dict('good_teacher.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('model_state.pth'))\n",
    "#model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4db9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##some of these configs made for more diverse outputs in teachers:\n",
    "config_args = {\"dist_type\" : \"ints\" ##worked well\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 100\n",
    "                      , \"gen_epochs\" : 100\n",
    "                      , \"gen_lr\" : 0.001\n",
    "                      , \"random_shuffle\" : 0.1\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_high_epochs = {\"dist_type\" : \"ints\" ##okay, but not as well as config_args.\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 1000\n",
    "                      , \"gen_epochs\" : 100\n",
    "                      , \"gen_lr\" : 0.001\n",
    "                      , \"random_shuffle\" : 0.1\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_higher_lr = {\"dist_type\" : \"ints\" ##lower was worse.  raise it. 0.003 looks great.  this is the best.\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 2000\n",
    "                      , \"gen_epochs\" : 50\n",
    "                      , \"gen_lr\" :  0.003 ##0.003\n",
    "                      , \"random_shuffle\" : 0.8\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_less_data = {\"dist_type\" : \"ints\" ##worse\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 500\n",
    "                      , \"gen_epochs\" : 100\n",
    "                      , \"gen_lr\" : 0.003\n",
    "                      , \"random_shuffle\" : 0.1\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_high_shuffle = {\"dist_type\" : \"ints\" ##one bar..\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 10_000\n",
    "                      , \"gen_epochs\" : 10\n",
    "                      , \"gen_lr\" : 0.05\n",
    "                      , \"random_shuffle\" : 0.9\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_args_small_batch = {\"dist_type\" : \"ints\" ##this one was the first to do well.  not just one bar and the rest nearly zero.\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 10_000\n",
    "                      , \"gen_epochs\" : 10\n",
    "                      , \"gen_lr\" : 0.05\n",
    "                      , \"random_shuffle\" : 0.5\n",
    "                      , \"batch_size\" : 10\n",
    "                      , \"out_type\" : \"one-hot\" }\n",
    "\n",
    "config_ab = {\"dist_type\" : \"ints\" ##worked well\n",
    "                      , \"gen_m\" : vocab_size\n",
    "                      , \"gen_n\" : 5000\n",
    "                      , \"gen_epochs\" : 200\n",
    "                      , \"gen_lr\" : 0.005\n",
    "                      , \"random_shuffle\" : 0.0\n",
    "                      , \"out_type\" : \"one-hot\" \n",
    "                      , \"dist_type\" : 'hetero'\n",
    "                      , \"alpha\" : 1\n",
    "                      , \"beta\" : 4} #maybe increase epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teacher_slm.configure(**config_ab) #this is dying.  might be time for colab!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f954d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating val data ::   0%|                            | 0/200 [00:00<?, ?it/s]/var/folders/hq/zz_5zb251633yqqbh6076p782zzx8q/T/ipykernel_29234/1983935209.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(out) # should be output = F.softmax(out,dim=-1) or output = F.softmax(out,dim=1)\n",
      "Generating val data ::   0%|                            | 0/200 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = { 'val_train' : \"val\"\n",
    "                      , 'n' : 10_000\n",
    "                      , 'dist_type' : 'ints'\n",
    "                      , 'm' : vocab_size\n",
    "                      , 'std': 1.0\n",
    "                      , 'alpha' : 1\n",
    "                      , 'beta' : 3\n",
    "                      , 'store_outputs' : True\n",
    "        }\n",
    "teacher_slm.generate_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb63843",
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(teacher_slm.model.state_dict(), 'good_teacher.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ca1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5425419 ,  0.35136947, -0.03018094, ..., -0.15405135,\n",
       "         1.7438477 , -0.98630935],\n",
       "       [-1.6164193 , -1.8916837 , -0.8887659 , ..., -0.15044953,\n",
       "        -0.22066197, -1.287303  ],\n",
       "       [ 0.34314165,  0.25870025, -0.93632895, ...,  1.0878774 ,\n",
       "         0.89934933, -0.45346054],\n",
       "       ...,\n",
       "       [ 0.64084125, -1.4381758 ,  1.0926732 , ...,  2.0109196 ,\n",
       "         0.51697874, -0.04919771],\n",
       "       [-0.22420782,  1.1749339 ,  0.90297115, ...,  0.2145888 ,\n",
       "        -0.39479327,  0.79994994],\n",
       "       [-0.10181472, -0.19704515,  0.46629068, ..., -0.37408283,\n",
       "         1.2688403 , -0.0953627 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.model.embedding.weight.detach().numpy() #use this to make the matrix, just linear? not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #the code is right, i just need this to be a better dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c7711d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_slm.graph_dataset_dist(val_train = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8154cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/zz_5zb251633yqqbh6076p782zzx8q/T/ipykernel_29234/1983935209.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(out) # should be output = F.softmax(out,dim=-1) or output = F.softmax(out,dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teacher_slm.model.eval() #irrelevant\n",
    "teacher_slm.model(teacher_slm.val_inputs[50:100])[0], teacher_slm.val_targets[50:60][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6de08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.all(teacher_slm.model(teacher_slm.val_inputs[:50]) == teacher_slm.val_targets[:50]))\n",
    "#in test is concatenated the same way as the outputs in KDNoise.  only difference.  doesn't appear to be different.  \n",
    "print(torch.all(teacher_slm.model(teacher_slm.val_inputs[50:100]) == teacher_slm.val_targets[50:100])) ##yeah, val_inputs and in_test appear to be the same.\n",
    "#torch.all(teacher_slm.model(teacher_slm.in_test[:49]) == teacher_slm.val_targets[:49]) ##this doesn't/.  huh???!!\n",
    "#torch.all(teacher_slm.model(teacher_slm.in_test[:50]) == teacher_slm.model(teacher_slm.val_inputs[:50])) ##okay, these match too\n",
    "#torch.all(teacher_slm.model(teacher_slm.in_test[223:409]) == teacher_slm.model(teacher_slm.val_inputs[223:409])) #these match.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_slm.val_inputs.shape, teacher_slm.val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(teacher_slm.model(teacher_slm.val_inputs[1]) ==  teacher_slm.val_targets[1]) ##torch.allclose doesn't work either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909987b0",
   "metadata": {},
   "source": [
    "so, it looks like it is predicting correctly, but there is something wrong with the batch? they match when you pass in 50, but more, or not at exactly the 50 marks, it doesn't all match.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added teacher_slm.in_test and teacher_slm.dataloader\n",
    "teacher_slm.data_loader\n",
    "x = None\n",
    "y = None\n",
    "for batch_samples in teacher_slm.data_loader:\n",
    "    # Perform inference on each batch\n",
    "    batch_outputs = teacher_slm.model(batch_samples[0])  # Assuming samples are in the first element of the batch\n",
    "    print(batch_samples[0])\n",
    "    x = batch_samples[0]\n",
    "    print(batch_outputs)\n",
    "    y = batch_outputs\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e63715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay, the first 50 match.  do they \n",
    "torch.all(x == teacher_slm.val_inputs[0:50]),torch.all(y == teacher_slm.val_targets[0:50]),torch.all(teacher_slm.model(x) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f7b2a",
   "metadata": {},
   "source": [
    "specify gen outputs.  we need one hots\n",
    "i can do this better than chat gpt lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this function works, it is in LABNET.  \n",
    "def one_hot_last_dim(tensor_shape):\n",
    "    num_classes = tensor_shape[-1]\n",
    "    random_idx = np.random.randint(1, num_classes + 1, size=tensor_shape[:-1])\n",
    "    zero_tensor = np.zeros(tensor_shape, dtype=int)\n",
    "    last_dim_indices = np.arange(num_classes)\n",
    "    zero_tensor[..., :, last_dim_indices] = (random_idx[..., np.newaxis] == last_dim_indices)\n",
    "    return zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fabd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_to_shuffle = 0\n",
    "\n",
    "# Shuffle the tensor along the specified axis\n",
    "shuffled_tensor = np.take(x, np.random.permutation(x.shape[0]), axis=0)\n",
    "\n",
    "print(shuffled_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    random_number = random.random()\n",
    "    print(random_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb166fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is to extract the parts.  we need to take out the embedding layer, make it linear, and then take out the layer before softmax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef060bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "def generate_heteroskedastic_ints(n, alpha, beta, total_classes):\n",
    "    # Generate random values from the beta distribution\n",
    "    values = np.random.beta(alpha, beta, n)\n",
    "    min_value = 0\n",
    "    max_value = total_classes\n",
    "    scaled_values = min_value + (max_value - min_value) * values\n",
    "    \n",
    "    # Round the scaled values to integers\n",
    "    ints = np.round(scaled_values).astype(int)\n",
    "    \n",
    "    return ints\n",
    "\n",
    "# Set your desired alpha and beta values\n",
    "alpha = 1  # Adjust this to control skewness\n",
    "beta = 10  # Adjust this to control skewness\n",
    "\n",
    "# Generate 100 random integers with the specified heteroskedasticity\n",
    "random_integers = generate_heteroskedastic_ints(10_000, alpha, beta, 100)\n",
    "\n",
    "# Print the generated integers\n",
    "print(random_integers)\n",
    "plt.hist(random_integers, bins=20, edgecolor='k')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Random Integers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87621b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heteroskedastic_ints(shape, alpha, beta, total_classes):\n",
    "    # Generate random values from the beta distribution\n",
    "    values = np.random.beta(alpha, beta, shape)\n",
    "    \n",
    "    # Scale the values to integers in the desired range (e.g., 0 to 100)\n",
    "    min_value = 0\n",
    "    max_value = total_classes\n",
    "    scaled_values = min_value + (max_value - min_value) * values\n",
    "    \n",
    "    # Round the scaled values to integers\n",
    "    ints = np.round(scaled_values).astype(int)\n",
    "    \n",
    "    return ints\n",
    "\n",
    "# Set your desired alpha and beta values\n",
    "alpha = 1  # Adjust this to control skewness\n",
    "beta = 1   # Adjust this to control skewness\n",
    "\n",
    "# Specify the shape of the tensor (e.g., b x 200)\n",
    "b = 5\n",
    "shape = (b, 200)\n",
    "\n",
    "# Generate a tensor of random integers with the specified heteroskedasticity\n",
    "random_integers_tensor = generate_heteroskedastic_ints(shape, alpha, beta,20)\n",
    "\n",
    "# Print the generated tensor\n",
    "random_integers_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e56b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Shape: torch.Size([23, 80])\n"
     ]
    }
   ],
   "source": [
    "class ToyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, hidden_dim, num_layers, dropout,sequence_length):\n",
    "        super(ToyTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout, batch_first=True),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc1 = nn.Linear(embedding_dim * sequence_length, vocab_size)  # Intermediate linear layer\n",
    "        self.fc2 = nn.Linear(vocab_size, vocab_size)  # Final linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten the output\n",
    "        x = F.relu(self.fc1(x))  # Apply the intermediate linear layer with ReLU activation\n",
    "        x = self.fc2(x)  # Apply the final linear layer\n",
    "        x = F.softmax(x, dim=1)  # Apply softmax activation\n",
    "        return x\n",
    "\n",
    "# Set the hyperparameters\n",
    "embedding_dim = 16\n",
    "num_heads = 8\n",
    "hidden_dim = 11\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "vocab_size = 80\n",
    "class_num = vocab_size\n",
    "batch_size = 23\n",
    "sequence_length = 160\n",
    "\n",
    "# Create an instance of the toy Transformer model\n",
    "model = ToyTransformer(vocab_size, embedding_dim, num_heads, hidden_dim, num_layers, dropout,sequence_length)\n",
    "\n",
    "# Generate random input data for testing\n",
    "input_data = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(input_data)\n",
    "\n",
    "print(\"Model Output Shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b66b46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TT = ToyTransformer(vocab_size, embedding_dim, num_heads, hidden_dim, num_layers, dropout,sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy = Teacher(TT,(sequence_length,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy.configure(**config_ab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = { 'val_train' : \"val\"\n",
    "                      , 'n' : 10_000\n",
    "                      , 'dist_type' : 'ints'\n",
    "                      , 'm' : vocab_size\n",
    "                      , 'std': 1.0\n",
    "                      , 'alpha' : 1\n",
    "                      , 'beta' : 3\n",
    "                      , 'store_outputs' : True\n",
    "        }\n",
    "teacher_toy.model.eval()\n",
    "teacher_toy.generate_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(teacher_toy.model.state_dict(), 'good_toy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy.model(teacher_toy.val_inputs[0:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a385b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy.load_state_dict('good_toy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56202d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT(teacher_toy.val_inputs[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy.val_targets[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_toy.val_inputs[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(teacher_toy.model(teacher_toy.val_inputs[i:i+1]), teacher_toy.val_targets[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader = DataLoader(TensorDataset(samples), batch_size=batch_size, shuffle=False)\n",
    "self.data_loader = data_loader\n",
    "outputs_list = []\n",
    "inputs_list = []\n",
    "\n",
    "total_batches = len(data_loader)\n",
    "\n",
    "if store_outputs:\n",
    "    if display_progress:\n",
    "        progress_bar = tqdm(total=total_batches, desc=f\"Generating {val_train} data :\")\n",
    "    self.model.eval()\n",
    "\n",
    "\n",
    "    for batch_samples in data_loader:\n",
    "        # Perform inference on each batch\n",
    "        batch_outputs = self.model(batch_samples[0])  # Assuming samples are in the first element of the batch\n",
    "        #inputs_list.append(batch_samples[0].detach())\n",
    "        outputs_list.append(batch_outputs.detach())\n",
    "        if display_progress:\n",
    "            progress_bar.update(1)\n",
    "outputs_return = torch.cat(outputs_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471186d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(torch.all(TT(teacher_toy.val_inputs[i:i+1]) == teacher_toy.val_targets[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT.load_state_dict(torch.load('good_toy.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gen_shape = (100, sequence_length)\n",
    "samples = np.random.randint(0, high=vocab_size, size=gen_shape)\n",
    "samples = torch.from_numpy(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = teacher_toy.val_inputs[0:100]\n",
    "#print(samples)\n",
    "TT(samples[20:30])[0:1]== TT(samples[20:22])[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT.eval()\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32  # You can adjust this as needed\n",
    "\n",
    "# Split samples into batches\n",
    "sample_batches = torch.split(samples, batch_size)\n",
    "\n",
    "# Create a list to store batched outputs\n",
    "outputs_list = []\n",
    "\n",
    "# Forward pass through the model in batches\n",
    "with torch.no_grad():  \n",
    "    for batch in sample_batches:\n",
    "        batch_outputs = TT(batch)\n",
    "        outputs_list.append(batch_outputs)\n",
    "\n",
    "# Stack the batched outputs\n",
    "stacked_outputs = torch.cat(outputs_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_outputs.shape, samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT(samples[0:10])[0:1], stacked_outputs[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a0d4123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215702"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214de29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
