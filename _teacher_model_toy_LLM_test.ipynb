{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a04cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b445af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NoiseKD import Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a11b24",
   "metadata": {},
   "source": [
    "First hurdle. the embedding layer.  It requires the ints as inputs, not one hot.  i need one hot.  i will also need to rewire the LLM i use to do the same.  hmm.  save the weights, load it into a model that has the same shapes, but accepts one hot arrays, not vocab_indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad448f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout),\n",
    "            num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "\n",
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_length, embedding_dim, class_num, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Define the transformer encoder\n",
    "        self.transformer_encoder = TransformerEncoder(embedding_dim, num_heads, hidden_dim, num_layers, dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(sequence_length*embedding_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        \n",
    "        self.output_layer = nn.Linear(500, class_num)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Input_data is of shape (batch_size, sequence_length)\n",
    "        # Apply embedding layer\n",
    "        #print(input_data.shape)\n",
    "        embedded = self.embedding(input_data)\n",
    "        #print(embedded.shape)\n",
    "        # Pass through the transformer encoder\n",
    "        transformed = self.transformer_encoder(embedded)\n",
    "        #print(transformed.shape) same as input duh: batch x sequence_length x embedding_dim\n",
    "        flattened_tensor = transformed.view(-1,sequence_length*embedding_dim)\n",
    "        f1 = nn.ReLU()(self.fc1(flattened_tensor))\n",
    "        f2 = nn.ReLU()(self.fc2(f1))\n",
    "        out = self.output_layer(f2)\n",
    "        # Apply the output layer\n",
    "        output = F.softmax(out,dim=1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca2a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "num_heads = 8\n",
    "hidden_dim  = 11\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "vocab_size = 80\n",
    "class_num = 14\n",
    "batch_size = 23\n",
    "sequence_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b5a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLM = SimpleLanguageModel(vocab_size, sequence_length, embedding_dim, class_num, num_heads, hidden_dim, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fc6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLanguageModel(\n",
       "  (embedding): Embedding(80, 16)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=11, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=11, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=11, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=11, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=2560, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (output_layer): Linear(in_features=500, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85578ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0688, 0.0667, 0.0741, 0.0779, 0.0660, 0.0802, 0.0652, 0.0688, 0.0800,\n",
       "         0.0653, 0.0632, 0.0763, 0.0732, 0.0741],\n",
       "        [0.0691, 0.0690, 0.0741, 0.0711, 0.0711, 0.0809, 0.0624, 0.0678, 0.0768,\n",
       "         0.0660, 0.0765, 0.0697, 0.0690, 0.0764],\n",
       "        [0.0759, 0.0805, 0.0741, 0.0721, 0.0611, 0.0771, 0.0616, 0.0676, 0.0725,\n",
       "         0.0666, 0.0636, 0.0816, 0.0643, 0.0813],\n",
       "        [0.0665, 0.0691, 0.0718, 0.0790, 0.0695, 0.0741, 0.0639, 0.0628, 0.0845,\n",
       "         0.0666, 0.0709, 0.0723, 0.0790, 0.0702],\n",
       "        [0.0774, 0.0607, 0.0723, 0.0716, 0.0680, 0.0749, 0.0660, 0.0702, 0.0808,\n",
       "         0.0648, 0.0636, 0.0740, 0.0725, 0.0831],\n",
       "        [0.0701, 0.0639, 0.0757, 0.0777, 0.0689, 0.0709, 0.0682, 0.0668, 0.0878,\n",
       "         0.0660, 0.0669, 0.0725, 0.0668, 0.0778],\n",
       "        [0.0643, 0.0649, 0.0725, 0.0727, 0.0724, 0.0676, 0.0673, 0.0702, 0.0841,\n",
       "         0.0663, 0.0708, 0.0736, 0.0804, 0.0729],\n",
       "        [0.0676, 0.0628, 0.0660, 0.0713, 0.0656, 0.0798, 0.0671, 0.0674, 0.0870,\n",
       "         0.0811, 0.0685, 0.0685, 0.0811, 0.0663],\n",
       "        [0.0710, 0.0631, 0.0750, 0.0760, 0.0600, 0.0786, 0.0641, 0.0691, 0.0853,\n",
       "         0.0713, 0.0680, 0.0746, 0.0674, 0.0767],\n",
       "        [0.0699, 0.0648, 0.0641, 0.0617, 0.0658, 0.0836, 0.0673, 0.0685, 0.0830,\n",
       "         0.0710, 0.0623, 0.0830, 0.0765, 0.0785],\n",
       "        [0.0668, 0.0638, 0.0671, 0.0745, 0.0697, 0.0757, 0.0665, 0.0685, 0.0788,\n",
       "         0.0668, 0.0737, 0.0733, 0.0758, 0.0791],\n",
       "        [0.0685, 0.0670, 0.0736, 0.0776, 0.0608, 0.0740, 0.0701, 0.0735, 0.0775,\n",
       "         0.0630, 0.0682, 0.0821, 0.0802, 0.0639],\n",
       "        [0.0692, 0.0718, 0.0783, 0.0654, 0.0741, 0.0790, 0.0662, 0.0677, 0.0819,\n",
       "         0.0694, 0.0672, 0.0750, 0.0695, 0.0655],\n",
       "        [0.0754, 0.0684, 0.0661, 0.0679, 0.0711, 0.0738, 0.0626, 0.0716, 0.0809,\n",
       "         0.0706, 0.0707, 0.0780, 0.0725, 0.0704],\n",
       "        [0.0710, 0.0700, 0.0735, 0.0791, 0.0680, 0.0747, 0.0642, 0.0663, 0.0844,\n",
       "         0.0609, 0.0735, 0.0696, 0.0741, 0.0708],\n",
       "        [0.0753, 0.0610, 0.0693, 0.0717, 0.0741, 0.0649, 0.0672, 0.0630, 0.0867,\n",
       "         0.0708, 0.0685, 0.0769, 0.0743, 0.0762],\n",
       "        [0.0657, 0.0631, 0.0737, 0.0745, 0.0663, 0.0779, 0.0649, 0.0760, 0.0831,\n",
       "         0.0696, 0.0664, 0.0706, 0.0748, 0.0735],\n",
       "        [0.0698, 0.0629, 0.0608, 0.0691, 0.0797, 0.0689, 0.0671, 0.0735, 0.0866,\n",
       "         0.0701, 0.0641, 0.0751, 0.0769, 0.0753],\n",
       "        [0.0680, 0.0638, 0.0802, 0.0628, 0.0665, 0.0790, 0.0623, 0.0657, 0.0774,\n",
       "         0.0648, 0.0711, 0.0817, 0.0816, 0.0749],\n",
       "        [0.0636, 0.0584, 0.0644, 0.0762, 0.0737, 0.0868, 0.0630, 0.0809, 0.0843,\n",
       "         0.0665, 0.0785, 0.0649, 0.0701, 0.0687],\n",
       "        [0.0686, 0.0710, 0.0646, 0.0716, 0.0732, 0.0767, 0.0676, 0.0682, 0.0764,\n",
       "         0.0708, 0.0650, 0.0710, 0.0789, 0.0763],\n",
       "        [0.0713, 0.0706, 0.0713, 0.0737, 0.0631, 0.0746, 0.0589, 0.0684, 0.0850,\n",
       "         0.0716, 0.0669, 0.0787, 0.0747, 0.0712],\n",
       "        [0.0735, 0.0621, 0.0632, 0.0712, 0.0679, 0.0847, 0.0677, 0.0703, 0.0749,\n",
       "         0.0717, 0.0684, 0.0746, 0.0784, 0.0714]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randint(low=0, high=vocab_size, size=(batch_size, sequence_length))\n",
    "SLM(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ba38e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072856"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c613c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_slm = Teacher(SLM,(sequence_length,)) #don't specify batch!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb0ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\n",
      "lets try ints!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuring Teacher:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:35<00:00,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Configured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "teacher_slm.configure(dist_type = \"ints\"\n",
    "                      , gen_m = vocab_size\n",
    "                      , gen_n = 10_000\n",
    "                      , gen_epochs = 10\n",
    "                      , gen_lr = 0.01\n",
    "                      , random_shuffle = 0.3\n",
    "                      , out_type = \"one-hot\" ) #this is dying.  might be time for colab!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77f954d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuring Teacher:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 40.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#this has a batch dim, but it isn't being ran in batches.  i think i need to do an append to self.inputs etc\n",
    "args = { 'val_train' : \"train\"\n",
    "                      , 'n' : 10_000\n",
    "                      , 'dist_type' : 'ints'\n",
    "                      , 'm' : vocab_size\n",
    "                      , 'std': 1.0\n",
    "        }\n",
    "teacher_slm.generate_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47234d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 14])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.model(teacher_slm.train_inputs[:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36c84643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.out_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2062e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 160])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3ca1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3016965 , -0.24368332,  1.584515  , ...,  0.45116335,\n",
       "         0.93156385, -0.5811422 ],\n",
       "       [ 1.1358676 , -0.9271309 ,  0.583345  , ...,  0.3191328 ,\n",
       "        -0.21009451, -2.265513  ],\n",
       "       [-0.25016376, -1.467522  , -0.8725965 , ..., -1.678036  ,\n",
       "         0.40563488, -0.15089063],\n",
       "       ...,\n",
       "       [-2.306779  , -0.18684156, -1.6040553 , ..., -0.43918175,\n",
       "         0.856878  ,  0.20695004],\n",
       "       [-0.4793628 ,  2.0016167 ,  0.10623812, ..., -1.420123  ,\n",
       "        -0.2950828 , -1.0309    ],\n",
       "       [ 0.5861007 , -1.0652558 ,  0.6993386 , ..., -0.9170168 ,\n",
       "         1.7089394 ,  0.6240984 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.model.embedding.weight.detach().numpy() #use this to make the matrix, just linear? not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "513eec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.argmax(teacher_slm.train_targets,axis = -1) #the code is write, i just need this to be a better dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "186719d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.train_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18b45d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_slm.out_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d724ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class_counts = [np.count_nonzero(test == i) for i in range(1, class_num + 1)]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(range(1, class_num + 1), class_counts, align='center')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of Class Counts')\n",
    "plt.xticks(range(1, class_num + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f7b2a",
   "metadata": {},
   "source": [
    "specify gen outputs.  we need one hots\n",
    "i can do this better than chat gpt lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5916bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this function works, it is in LABNET.  \n",
    "def one_hot_last_dim(tensor_shape):\n",
    "    num_classes = tensor_shape[-1]\n",
    "    random_idx = np.random.randint(1, num_classes + 1, size=tensor_shape[:-1])\n",
    "    zero_tensor = np.zeros(tensor_shape, dtype=int)\n",
    "    last_dim_indices = np.arange(num_classes)\n",
    "    zero_tensor[..., :, last_dim_indices] = (random_idx[..., np.newaxis] == last_dim_indices)\n",
    "    return zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf0a66d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fabd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_to_shuffle = 0\n",
    "\n",
    "# Shuffle the tensor along the specified axis\n",
    "shuffled_tensor = np.take(x, np.random.permutation(x.shape[0]), axis=0)\n",
    "\n",
    "print(shuffled_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    random_number = random.random()\n",
    "    print(random_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb166fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
