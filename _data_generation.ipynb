{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "627d1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b57878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        # Define the neural network layers\n",
    "        self.fc1 = nn.Linear(10, 16)  # First fully connected layer with 10 input features and 16 output features\n",
    "        self.fc2 = nn.Linear(16, 12)  # Second fully connected layer with 16 input features and 12 output features\n",
    "        self.fc3 = nn.Linear(12, 6)   # Third fully connected layer with 12 input features and 6 output features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))  # Apply ReLU activation after the first layer\n",
    "        x = nn.ReLU()(self.fc2(x))  # Apply ReLU activation after the second layer\n",
    "        x = self.fc3(x)             # No activation for the last layer\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c50cdb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 14 # You can change this value to your preferred batch size\n",
    "input_data = torch.randn(batch_size, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f3e3f295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 10]), torch.Size([14, 6]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape, model(input_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1ed6c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_folder = 'x'\n",
    "idx = 11\n",
    "#for idx, tensor in enumerate(dataloader0):\n",
    "torch.save(input_data, f\"{my_folder}/tensor{idx}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cb0569e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def store_generated_data(gen_model,folder_name,n): #might need to pass in input shape?\n",
    "    \"\"\"\n",
    "    gen_model is the teacher\n",
    "    folder_name is just where to put it\n",
    "    n is how many samples.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    inputs_file_path = os.path.join(folder_name, \"inputs\")\n",
    "    targets_file_path = os.path.join(folder_name, \"targets\")\n",
    "\n",
    "    if not os.path.exists(inputs_file_path):\n",
    "        os.makedirs(inputs_file_path)\n",
    "    if not os.path.exists(targets_file_path):\n",
    "        os.makedirs(targets_file_path)\n",
    "\n",
    "    ##get the max file number from each file.\n",
    "\n",
    "    files = os.listdir(inputs_file_path)\n",
    "    pattern = re.compile(r'input_(\\d+)')\n",
    "    integers = [int(match.group(1)) for file in files if (match := pattern.match(file))]\n",
    "    \n",
    "    if integers:\n",
    "        idx_last = max(integers) + 1\n",
    "    else:\n",
    "        idx_last = 1\n",
    "    \n",
    "    gen_model.eval()\n",
    "\n",
    "    for idx in range(n): #tqdm this?\n",
    "        #generate data, this will be a proper scheme\n",
    "        input_data = torch.randn(1, 10) #this is a batch_size of 1.  i will have to mess with llama to do this right. \n",
    "\n",
    "        #pass through model\n",
    "        target_data = gen_model(input_data)\n",
    "        torch.save(input_data, f\"{inputs_file_path}/input_{idx_last + idx}.pt\")\n",
    "        torch.save(target_data, f\"{targets_file_path}/target_{idx_last + idx}.pt\")\n",
    "    print(f'generate datapoints from {idx_last} to {idx_last + n - 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1cf09608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate datapoints from 81 to 100\n"
     ]
    }
   ],
   "source": [
    "n=20 #number of training points to make. \n",
    "folder_name = \"my_folder_1\"\n",
    "gen_model = model\n",
    "store_generated_data(gen_model,folder_name,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d5db43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FolderDataset(Dataset):\n",
    "    #assumes you used the above store_generated_data\n",
    "    def __init__(self, folder):\n",
    "        self.files = os.listdir(f\"{folder}/inputs\")\n",
    "        self.folder = folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the tensor\n",
    "        input_tensor = torch.load(f\"{self.folder}/inputs/{self.files[idx]}\")\n",
    "        \n",
    "        idx_match = re.search(r'input_(\\d+)', self.files[idx])\n",
    "        if idx_match:\n",
    "            target_idx = int(match.group(1))\n",
    "            target_tensor = torch.load(f\"{self.folder}/targets/target_{target_idx}.pt\")\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid filename format: {self.files[idx]}\")\n",
    "        \n",
    "        \n",
    "        return input_tensor.squeeze(), target_tensor.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5ca64354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = FolderDataset(folder_name)\n",
    "dataloader = DataLoader(dataset, batch_size=7, shuffle=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e15e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0019948857370764017\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0030165761709213257\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.000832923746202141\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0016743320738896728\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0017386144027113914\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013637410011142492\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0014175515389069915\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0011508219176903367\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0014936315128579736\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0020261285826563835\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0012276447378098965\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.002327363472431898\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0020057472866028547\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0018477445701137185\n",
      "torch.Size([2, 10]) torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "Loss: 0.002442870521917939\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0020198693964630365\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0018723529065027833\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013552146265283227\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0017292485572397709\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0012075919657945633\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013518339255824685\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0016546300612390041\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001624464406631887\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0034229543525725603\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0015702173113822937\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0020638853311538696\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0019944976083934307\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0007838825695216656\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001791889313608408\n",
      "torch.Size([2, 10]) torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "Loss: 0.00041500848601572216\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0017617761623114347\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0022665809374302626\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0018138180021196604\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001036013476550579\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013602679828181863\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0036599005106836557\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.002296209102496505\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0011174384271726012\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0009825797751545906\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001680827233940363\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0018836116651073098\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0012378885876387358\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013491376303136349\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0010686431778594851\n",
      "torch.Size([2, 10]) torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "Loss: 0.002920764498412609\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0017485391581431031\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001233440823853016\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001323003089055419\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013445240911096334\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0016018046298995614\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0023149517364799976\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0015416344394907355\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.002181884367018938\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013205663999542594\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013363683829084039\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0016814734553918242\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0014880363596603274\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0014101325068622828\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0021020816639065742\n",
      "torch.Size([2, 10]) torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "Loss: 0.005300629884004593\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0008504758006893098\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0015351965557783842\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0010850261896848679\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0021562092006206512\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.002349821850657463\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0018524609040468931\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.002118371892720461\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0014427247224375606\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0029898856300860643\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0014494310598820448\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.001403843518346548\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0017354132141917944\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0013012022245675325\n",
      "torch.Size([7, 10]) torch.Size([7, 6])\n",
      "torch.Size([7, 6])\n",
      "Loss: 0.0012550263199955225\n",
      "torch.Size([2, 10]) torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "Loss: 0.001428720890544355\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        # Here, 'data' is whatever is saved in the torch files in your folder.\n",
    "        # Assuming it's a tensor you want to use as input:\n",
    "        inputs, targets = data\n",
    "        print(inputs.shape, targets.shape)\n",
    "        outputs = model(inputs)\n",
    "        print(outputs.shape)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, targets)  # Mock loss for testing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06732d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
